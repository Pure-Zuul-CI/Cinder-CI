● np0000031958
    State: degraded
    Units: 459 loaded (incl. loaded aliases)
     Jobs: 0 queued
   Failed: 4 units
    Since: Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
  systemd: 255.4-1ubuntu8.10
   CGroup: /
           ├─init.scope
           │ └─1 /sbin/init nofb
           ├─system.slice
           │ ├─apache-htcacheclean.service
           │ │ └─12079 /usr/bin/htcacheclean -d 120 -p /var/cache/apache2/mod_cache_disk -l 300M -n
           │ ├─apache2.service
           │ │ ├─60135 /usr/sbin/apache2 -k start
           │ │ ├─60141 /usr/sbin/apache2 -k start
           │ │ └─60142 /usr/sbin/apache2 -k start
           │ ├─atd.service
           │ │ └─1007 /usr/sbin/atd -f
           │ ├─cron.service
           │ │ └─1005 /usr/sbin/cron -f -P
           │ ├─dbus.service
           │ │ └─521 @dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only
           │ ├─epmd.service
           │ │ └─17674 /usr/bin/epmd -systemd
           │ ├─haproxy.service
           │ │ ├─11224 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
           │ │ └─11226 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
           │ ├─haveged.service
           │ │ └─403 /usr/sbin/haveged --Foreground --verbose=1
           │ ├─iscsid.service
           │ │ ├─36013 /usr/sbin/iscsid
           │ │ └─36014 /usr/sbin/iscsid
           │ ├─ksmtuned.service
           │ │ ├─  5739 /bin/bash /usr/sbin/ksmtuned
           │ │ └─132319 sleep 60
           │ ├─libvirtd.service
           │ │ ├─34056 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
           │ │ ├─34057 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
           │ │ └─78152 /usr/sbin/libvirtd --timeout 120
           │ ├─memcached.service
           │ │ └─47620 /usr/bin/memcached -m 64 -p 11211 -u memcache -l 127.0.0.1 -l ::1 -P /var/run/memcached/memcached.pid
           │ ├─multipathd.service
           │ │ └─363 /sbin/multipathd -d -s
           │ ├─mysql.service
           │ │ └─44158 /usr/sbin/mysqld
           │ ├─ovn-controller-vtep.service
           │ │ └─67159 ovn-controller-vtep -vconsole:emer -vsyslog:err -vfile:info --vtep-db=/var/run/openvswitch/db.sock --ovnsb-db=/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-controller-vtep.log --pidfile=/var/run/ovn/ovn-controller-vtep.pid --detach
           │ ├─ovn-controller.service
           │ │ └─67808 ovn-controller unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --no-chdir --log-file=/var/log/ovn/ovn-controller.log --pidfile=/var/run/ovn/ovn-controller.pid --detach
           │ ├─ovn-northd.service
           │ │ └─67551 ovn-northd -vconsole:emer -vsyslog:err -vfile:info --ovnnb-db=unix:/var/run/ovn/ovnnb_db.sock --ovnsb-db=unix:/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-northd.log --pidfile=/var/run/ovn/ovn-northd.pid --detach
           │ ├─ovn-ovsdb-server-nb.service
           │ │ └─67478 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-nb.log --remote=punix:/var/run/ovn/ovnnb_db.sock --pidfile=/var/run/ovn/ovnnb_db.pid --unixctl=/var/run/ovn/ovnnb_db.ctl --remote=db:OVN_Northbound,NB_Global,connections --private-key=db:OVN_Northbound,SSL,private_key --certificate=db:OVN_Northbound,SSL,certificate --ca-cert=db:OVN_Northbound,SSL,ca_cert --ssl-protocols=db:OVN_Northbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Northbound,SSL,ssl_ciphers /var/lib/ovn/ovnnb_db.db
           │ ├─ovn-ovsdb-server-sb.service
           │ │ └─67479 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-sb.log --remote=punix:/var/run/ovn/ovnsb_db.sock --pidfile=/var/run/ovn/ovnsb_db.pid --unixctl=/var/run/ovn/ovnsb_db.ctl --remote=db:OVN_Southbound,SB_Global,connections --private-key=db:OVN_Southbound,SSL,private_key --certificate=db:OVN_Southbound,SSL,certificate --ca-cert=db:OVN_Southbound,SSL,ca_cert --ssl-protocols=db:OVN_Southbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Southbound,SSL,ssl_ciphers /var/lib/ovn/ovnsb_db.db
           │ ├─ovs-vswitchd.service
           │ │ └─67077 ovs-vswitchd unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --mlockall --no-chdir --log-file=/var/log/openvswitch/ovs-vswitchd.log --pidfile=/var/run/openvswitch/ovs-vswitchd.pid --detach
           │ ├─ovsdb-server.service
           │ │ └─66880 ovsdb-server /etc/openvswitch/conf.db -vconsole:emer -vsyslog:err -vfile:info --remote=punix:/var/run/openvswitch/db.sock --private-key=db:Open_vSwitch,SSL,private_key --certificate=db:Open_vSwitch,SSL,certificate --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert --no-chdir --log-file=/var/log/openvswitch/ovsdb-server.log --pidfile=/var/run/openvswitch/ovsdb-server.pid --detach
           │ ├─polkit.service
           │ │ └─1336 /usr/lib/polkit-1/polkitd --no-debug
           │ ├─pure-boot.service
           │ │ └─988 dhclient
           │ ├─rabbitmq-server.service
           │ │ ├─17789 /usr/lib/erlang/erts-13.2.2.5/bin/beam.smp -W w -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -pc unicode -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -sbwt none -sbwtdcpu none -sbwtdio none -- -root /usr/lib/erlang -bindir /usr/lib/erlang/erts-13.2.2.5/bin -progname erl -- -home /var/lib/rabbitmq -- -pa "" -noshell -noinput -s rabbit boot -boot start_sasl -syslog logger "[]" -syslog syslog_error_logger false -kernel prevent_overlapping_partitions false -enable-feature maybe_expr
           │ │ ├─17799 erl_child_setup 65536
           │ │ ├─17875 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
           │ │ ├─17876 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
           │ │ └─17879 /bin/sh -s rabbit_disk_monitor
           │ ├─rsyslog.service
           │ │ └─15219 /usr/sbin/rsyslogd -n -iNONE
           │ ├─ssh.service
           │ │ └─860 "sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups"
           │ ├─system-devstack.slice
           │ │ ├─devstack@c-api.service
           │ │ │ ├─78016 "cinder-apiuWSGI master"
           │ │ │ ├─78022 "cinder-apiuWSGI worker 1"
           │ │ │ └─78023 "cinder-apiuWSGI worker 2"
           │ │ ├─devstack@c-sch.service
           │ │ │ └─78804 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf
           │ │ ├─devstack@c-vol.service
           │ │ │ ├─79416 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
           │ │ │ ├─80100 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
           │ │ │ ├─91425 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context cinder.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmpk5wqr2on/privsep.sock
           │ │ │ └─91489 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmpohtseool/privsep.sock
           │ │ ├─devstack@etcd.service
           │ │ │ └─45936 /opt/stack/bin/etcd --name np0000031958 --data-dir /opt/stack/data/etcd --initial-cluster-state new --initial-cluster-token etcd-cluster-01 --initial-cluster np0000031958=http://192.168.1.104:2380 --initial-advertise-peer-urls http://192.168.1.104:2380 --advertise-client-urls http://192.168.1.104:2379 --listen-peer-urls http://0.0.0.0:2380 --listen-client-urls http://192.168.1.104:2379 --log-level=debug
           │ │ ├─devstack@file_tracker.service
           │ │ │ ├─ 45281 /bin/bash /opt/stack/devstack/tools/file_tracker.sh
           │ │ │ └─134026 sleep 20
           │ │ ├─devstack@g-api.service
           │ │ │ ├─80178 "glance-apiuWSGI master"
           │ │ │ ├─80179 "glance-apiuWSGI worker 1"
           │ │ │ └─80180 "glance-apiuWSGI worker 2"
           │ │ ├─devstack@keystone.service
           │ │ │ ├─47211 "keystoneuWSGI master"
           │ │ │ ├─47212 "keystoneuWSGI worker 1"
           │ │ │ └─47213 "keystoneuWSGI worker 2"
           │ │ ├─devstack@memory_tracker.service
           │ │ │ ├─ 44799 /bin/bash /opt/stack/devstack/tools/memory_tracker.sh
           │ │ │ └─132658 sleep 20
           │ │ ├─devstack@n-api-meta.service
           │ │ │ ├─74275 "nova-api-metauWSGI master"
           │ │ │ ├─74276 "nova-api-metauWSGI worker 1"
           │ │ │ ├─74277 "nova-api-metauWSGI worker 2"
           │ │ │ └─74278 "nova-api-metauWSGI http 1"
           │ │ ├─devstack@n-api.service
           │ │ │ ├─66388 "nova-apiuWSGI master"
           │ │ │ ├─66389 "nova-apiuWSGI worker 1"
           │ │ │ └─66390 "nova-apiuWSGI worker 2"
           │ │ ├─devstack@n-cond-cell1.service
           │ │ │ ├─76172 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
           │ │ │ ├─77282 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
           │ │ │ └─77283 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
           │ │ ├─devstack@n-cpu.service
           │ │ │ ├─77223 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-compute --config-file /etc/nova/nova-cpu.conf
           │ │ │ ├─87718 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context nova.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmps6_q_fui/privsep.sock
           │ │ │ ├─87756 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context vif_plug_ovs.privsep.vif_plug --privsep_sock_path /tmp/tmprul1wut5/privsep.sock
           │ │ │ └─88388 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmp9ppv4ep2/privsep.sock
           │ │ ├─devstack@n-novnc-cell1.service
           │ │ │ └─74890 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-novncproxy --config-file /etc/nova/nova_cell1.conf --web /usr/share/novnc
           │ │ ├─devstack@n-sch.service
           │ │ │ ├─73694 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
           │ │ │ ├─74771 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
           │ │ │ └─74773 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
           │ │ ├─devstack@n-super-cond.service
           │ │ │ ├─75663 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
           │ │ │ ├─77004 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
           │ │ │ └─77006 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
           │ │ ├─devstack@neutron-api.service
           │ │ │ ├─69264 "neutron-apiuWSGI master"
           │ │ │ ├─69265 "neutron-apiuWSGI worker 1"
           │ │ │ └─69266 "neutron-apiuWSGI worker 2"
           │ │ ├─devstack@neutron-ovn-maintenance-worker.service
           │ │ │ ├─70814 "neutron-ovn-maintenance-worker: master process [/opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
           │ │ │ └─71478 "neutron-server: maintenance worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
           │ │ ├─devstack@neutron-periodic-workers.service
           │ │ │ ├─70339 "neutron-periodic-workers: master process [/opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
           │ │ │ ├─70924 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
           │ │ │ ├─70940 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
           │ │ │ ├─70960 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
           │ │ │ └─70970 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
           │ │ ├─devstack@neutron-rpc-server.service
           │ │ │ ├─69866 "neutron-rpc-server: master process [/opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
           │ │ │ └─71411 "neutron-server: rpc worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
           │ │ ├─devstack@openstack-cli-server.service
           │ │ │ └─43414 /opt/stack/data/venv/bin/python3 /opt/stack/devstack/files/openstack-cli-server/openstack-cli-server
           │ │ ├─devstack@placement-api.service
           │ │ │ ├─71602 "placementuWSGI master"
           │ │ │ ├─71603 "placementuWSGI worker 1"
           │ │ │ └─71604 "placementuWSGI worker 2"
           │ │ └─devstack@q-ovn-agent.service
           │ │   ├─68291 "neutron-ovn-agent: master process [/opt/stack/data/venv/bin/neutron-ovn-agent --config-file /etc/neutron/plugins/ml2/ovn_agent.ini]"
           │ │   ├─69566 "neutron-ovn-agent: ServiceWrapper worker(0)"
           │ │   ├─69991 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.namespace_cmd --privsep_sock_path /tmp/tmp6pg930cl/privsep.sock
           │ │   ├─72437 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.default --privsep_sock_path /tmp/tmpoexj_vsa/privsep.sock
           │ │   ├─87902 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.link_cmd --privsep_sock_path /tmp/tmpdh3dhj4v/privsep.sock
           │ │   ├─87989 sudo /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
           │ │   └─87990 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
           │ ├─system-getty.slice
           │ │ └─getty@tty1.service
           │ │   └─1015 /sbin/agetty -o "-p -- \\u" --noclear - linux
           │ ├─system-glean.slice
           │ │ ├─glean@enp3s0.service
           │ │ │ └─704 dhclient -1 -4 -v -i -pf /run/dhclient.enp3s0.pid -lf /var/lib/dhcp/dhclient.enp3s0.leases -I -df /var/lib/dhcp/dhclient6.enp3s0.leases enp3s0
           │ │ └─glean@enp4s0.service
           │ │   └─703 dhclient -1 -4 -v -i -pf /run/dhclient.enp4s0.pid -lf /var/lib/dhcp/dhclient.enp4s0.leases -I -df /var/lib/dhcp/dhclient6.enp4s0.leases enp4s0
           │ ├─system-serial\x2dgetty.slice
           │ │ └─serial-getty@ttyS0.service
           │ │   └─1016 /sbin/agetty -o "-p -- \\u" --keep-baud 115200,57600,38400,9600 - vt220
           │ ├─systemd-journald.service
           │ │ └─16765 /usr/lib/systemd/systemd-journald
           │ ├─systemd-logind.service
           │ │ └─531 /usr/lib/systemd/systemd-logind
           │ ├─systemd-machined.service
           │ │ └─33939 /usr/lib/systemd/systemd-machined
           │ ├─systemd-networkd.service
           │ │ └─845 /usr/lib/systemd/systemd-networkd
           │ ├─systemd-resolved.service
           │ │ └─408 /usr/lib/systemd/systemd-resolved
           │ ├─systemd-timesyncd.service
           │ │ └─409 /usr/lib/systemd/systemd-timesyncd
           │ ├─systemd-udevd.service
           │ │ └─udev
           │ │   └─378 /usr/lib/systemd/systemd-udevd
           │ ├─virtlockd.service
           │ │ └─34172 /usr/sbin/virtlockd
           │ └─virtlogd.service
           │   └─40311 /usr/sbin/virtlogd
           └─user.slice
             └─user-1000.slice
               ├─session-12.scope
               │ ├─132488 "sshd: zuul [priv]"
               │ ├─132498 "sshd: zuul@notty"
               │ ├─134021 /bin/sh -c "sudo -H -S -n  -u root /bin/sh -c 'echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3' && sleep 0"
               │ ├─134022 sudo -H -S -n -u root /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
               │ ├─134023 /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
               │ ├─134024 /usr/bin/python3
               │ ├─134027 /bin/bash -c "sudo iptables-save > /home/zuul/iptables.txt\ndf -h > /home/zuul/df.txt\n\nfor py_ver in 2 3; do\n    if [[ \`which python\${py_ver}\` ]]; then\n        python\${py_ver} -m pip freeze > /home/zuul/pip\${py_ver}-freeze.txt\n    fi\ndone\n\nif [ \`command -v dpkg\` ]; then\n    dpkg -l> /home/zuul/dpkg-l.txt\nfi\nif [ \`command -v rpm\` ]; then\n    rpm -qa | sort > /home/zuul/rpm-qa.txt\nfi\n\n# Services status\nsudo systemctl status --all > services.txt 2>/dev/null\n\n# NOTE(kchamart) The 'audit.log' can be useful in cases when QEMU\n# failed to start due to denials from SELinux — useful for CentOS\n# and Fedora machines.  For Ubuntu (which runs AppArmor), DevStack\n# already captures the contents of /var/log/kern.log (via\n# \`journalctl -t kernel\` redirected into syslog.txt.gz), which\n# contains AppArmor-related messages.\nif [ -f /var/log/audit/audit.log ] ; then\n    sudo cp /var/log/audit/audit.log /home/zuul/audit.log &&\n    chmod +r /home/zuul/audit.log;\nfi\n\n# gzip and save any coredumps in /var/core\nif [ -d /var/core ]; then\n    sudo gzip -r /var/core\n    sudo cp -r /var/core /home/zuul/\nfi\n\nsudo ss -lntup | grep ':53' > /home/zuul/listen53.txt\n\n# NOTE(andreaf) Service logs are already in logs/ thanks for the\n# export-devstack-journal log. Apache logs are under apache/ thans to the\n# apache-logs-conf role.\ngrep -i deprecat /home/zuul/logs/*.txt /home/zuul/apache/*.log | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}\\.[0-9]{1,3}/ /g' | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}/ /g' | \\\n    sed -r 's/[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}/ /g' |\n    sed -r 's/\\[.*\\]/ /g' | \\\n    sed -r 's/\\s[0-9]+\\s/ /g' | \\\n    awk '{if (\$0 in seen) {seen[\$0]++} else {out[++n]=\$0;seen[\$0]=1}} END { for (i=1; i<=n; i++) print seen[out[i]]\" :: \" out[i] }' > /home/zuul/deprecations.log\n"
               │ ├─134038 sudo systemctl status --all
               │ └─134039 systemctl status --all
               ├─session-3.scope
               │ └─1747 /usr/bin/python3
               └─user@1000.service
                 └─init.scope
                   ├─1605 /usr/lib/systemd/systemd --user
                   └─1606 "(sd-pam)"

● proc-sys-fs-binfmt_misc.automount - Arbitrary Executable File Formats File System Automount Point
     Loaded: loaded (/usr/lib/systemd/system/proc-sys-fs-binfmt_misc.automount; static)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● proc-sys-fs-binfmt_misc.mount
      Where: /proc/sys/fs/binfmt_misc
       Docs: https://docs.kernel.org/admin-guide/binfmt-misc.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems

Jul 29 14:32:52 ubuntu systemd[1]: proc-sys-fs-binfmt_misc.automount: Got automount request for /proc/sys/fs/binfmt_misc, triggered by 390 (systemd-binfmt)
Notice: journal has been rotated since unit was started, output may be incomplete.

● dev-cdrom.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-disk-by\x2ddiskseq-11.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-disk-by\x2ddiskseq-9.device - /dev/disk/by-diskseq/9
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda

● dev-disk-by\x2ddiskseq-9\x2dpart1.device - /dev/disk/by-diskseq/9-part1
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● dev-disk-by\x2did-ata\x2dQEMU_DVD\x2dROM_QM00001.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-disk-by\x2did-dm\x2dname\x2d3624a9370730e7fa1d6f242bb001c88d9.device - /dev/disk/by-id/dm-name-3624a9370730e7fa1d6f242bb001c88d9
    Follows: unit currently follows state of sys-devices-virtual-block-dm\x2d1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 17:17:48 UTC; 15min ago
     Device: /sys/devices/virtual/block/dm-1

● dev-disk-by\x2did-dm\x2duuid\x2dmpath\x2d3624a9370730e7fa1d6f242bb001c88d9.device - /dev/disk/by-id/dm-uuid-mpath-3624a9370730e7fa1d6f242bb001c88d9
    Follows: unit currently follows state of sys-devices-virtual-block-dm\x2d1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 17:17:48 UTC; 15min ago
     Device: /sys/devices/virtual/block/dm-1

● dev-disk-by\x2did-scsi\x2d3624a9370730e7fa1d6f242bb001c88d9.device - /dev/disk/by-id/scsi-3624a9370730e7fa1d6f242bb001c88d9
    Follows: unit currently follows state of sys-devices-virtual-block-dm\x2d1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 17:17:48 UTC; 15min ago
     Device: /sys/devices/virtual/block/dm-1

● dev-disk-by\x2did-virtio\x2d0f7d6d34\x2da33d\x2d4f03\x2da.device - /dev/disk/by-id/virtio-0f7d6d34-a33d-4f03-a
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda

● dev-disk-by\x2did-virtio\x2d0f7d6d34\x2da33d\x2d4f03\x2da\x2dpart1.device - /dev/disk/by-id/virtio-0f7d6d34-a33d-4f03-a-part1
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● dev-disk-by\x2did-wwn\x2d0x624a9370730e7fa1d6f242bb001c88d9.device - /dev/disk/by-id/wwn-0x624a9370730e7fa1d6f242bb001c88d9
    Follows: unit currently follows state of sys-devices-virtual-block-dm\x2d1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 17:17:48 UTC; 15min ago
     Device: /sys/devices/virtual/block/dm-1

● dev-disk-by\x2dlabel-cloudimg\x2drootfs.device - /dev/disk/by-label/cloudimg-rootfs
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● dev-disk-by\x2dlabel-config\x2d2.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-disk-by\x2dpartuuid-d5ac101e\x2d01.device - /dev/disk/by-partuuid/d5ac101e-01
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● dev-disk-by\x2dpath-pci\x2d0000:00:1f.2\x2data\x2d1.0.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-disk-by\x2dpath-pci\x2d0000:00:1f.2\x2data\x2d1.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-disk-by\x2dpath-pci\x2d0000:05:00.0.device - /dev/disk/by-path/pci-0000:05:00.0
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda

● dev-disk-by\x2dpath-pci\x2d0000:05:00.0\x2dpart1.device - /dev/disk/by-path/pci-0000:05:00.0-part1
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● dev-disk-by\x2dpath-virtio\x2dpci\x2d0000:05:00.0.device - /dev/disk/by-path/virtio-pci-0000:05:00.0
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda

● dev-disk-by\x2dpath-virtio\x2dpci\x2d0000:05:00.0\x2dpart1.device - /dev/disk/by-path/virtio-pci-0000:05:00.0-part1
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● dev-disk-by\x2duuid-2025\x2d07\x2d29\x2d10\x2d32\x2d38\x2d00.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-disk-by\x2duuid-c40eface\x2dfd04\x2d470e\x2d9b13\x2d5e27ff5c3d42.device - /dev/disk/by-uuid/c40eface-fd04-470e-9b13-5e27ff5c3d42
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● dev-dm\x2d1.device - /dev/dm-1
    Follows: unit currently follows state of sys-devices-virtual-block-dm\x2d1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 17:17:48 UTC; 15min ago
     Device: /sys/devices/virtual/block/dm-1

● dev-mapper-3624a9370730e7fa1d6f242bb001c88d9.device - /dev/mapper/3624a9370730e7fa1d6f242bb001c88d9
    Follows: unit currently follows state of sys-devices-virtual-block-dm\x2d1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 17:17:48 UTC; 15min ago
     Device: /sys/devices/virtual/block/dm-1

● dev-rfkill.device - /dev/rfkill
    Follows: unit currently follows state of sys-devices-virtual-misc-rfkill.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/virtual/misc/rfkill

● dev-sr0.device - QEMU_DVD-ROM config-2
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● dev-ttyprintk.device - /dev/ttyprintk
    Follows: unit currently follows state of sys-devices-virtual-tty-ttyprintk.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/virtual/tty/ttyprintk

● dev-ttyS0.device - /dev/ttyS0
    Follows: unit currently follows state of sys-devices-pnp0-00:00-00:00:0-00:00:0.0-tty-ttyS0.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pnp0/00:00/00:00:0/00:00:0.0/tty/ttyS0

Jul 29 14:32:52 ubuntu systemd[1]: Found device dev-ttyS0.device - /dev/ttyS0.

● dev-ttyS1.device - /dev/ttyS1
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.1-tty-ttyS1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.1/tty/ttyS1

● dev-ttyS10.device - /dev/ttyS10
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.10-tty-ttyS10.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.10/tty/ttyS10

● dev-ttyS11.device - /dev/ttyS11
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.11-tty-ttyS11.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.11/tty/ttyS11

● dev-ttyS12.device - /dev/ttyS12
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.12-tty-ttyS12.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.12/tty/ttyS12

● dev-ttyS13.device - /dev/ttyS13
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.13-tty-ttyS13.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.13/tty/ttyS13

● dev-ttyS14.device - /dev/ttyS14
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.14-tty-ttyS14.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.14/tty/ttyS14

● dev-ttyS15.device - /dev/ttyS15
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.15-tty-ttyS15.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.15/tty/ttyS15

● dev-ttyS16.device - /dev/ttyS16
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.16-tty-ttyS16.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.16/tty/ttyS16

● dev-ttyS17.device - /dev/ttyS17
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.17-tty-ttyS17.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.17/tty/ttyS17

● dev-ttyS18.device - /dev/ttyS18
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.18-tty-ttyS18.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.18/tty/ttyS18

● dev-ttyS19.device - /dev/ttyS19
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.19-tty-ttyS19.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.19/tty/ttyS19

● dev-ttyS2.device - /dev/ttyS2
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.2-tty-ttyS2.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.2/tty/ttyS2

● dev-ttyS20.device - /dev/ttyS20
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.20-tty-ttyS20.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.20/tty/ttyS20

● dev-ttyS21.device - /dev/ttyS21
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.21-tty-ttyS21.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.21/tty/ttyS21

● dev-ttyS22.device - /dev/ttyS22
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.22-tty-ttyS22.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.22/tty/ttyS22

● dev-ttyS23.device - /dev/ttyS23
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.23-tty-ttyS23.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.23/tty/ttyS23

● dev-ttyS24.device - /dev/ttyS24
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.24-tty-ttyS24.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.24/tty/ttyS24

● dev-ttyS25.device - /dev/ttyS25
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.25-tty-ttyS25.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.25/tty/ttyS25

● dev-ttyS26.device - /dev/ttyS26
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.26-tty-ttyS26.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.26/tty/ttyS26

● dev-ttyS27.device - /dev/ttyS27
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.27-tty-ttyS27.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.27/tty/ttyS27

● dev-ttyS28.device - /dev/ttyS28
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.28-tty-ttyS28.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.28/tty/ttyS28

● dev-ttyS29.device - /dev/ttyS29
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.29-tty-ttyS29.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.29/tty/ttyS29

● dev-ttyS3.device - /dev/ttyS3
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.3-tty-ttyS3.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.3/tty/ttyS3

● dev-ttyS30.device - /dev/ttyS30
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.30-tty-ttyS30.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.30/tty/ttyS30

● dev-ttyS31.device - /dev/ttyS31
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.31-tty-ttyS31.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.31/tty/ttyS31

● dev-ttyS4.device - /dev/ttyS4
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.4-tty-ttyS4.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.4/tty/ttyS4

● dev-ttyS5.device - /dev/ttyS5
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.5-tty-ttyS5.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.5/tty/ttyS5

● dev-ttyS6.device - /dev/ttyS6
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.6-tty-ttyS6.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.6/tty/ttyS6

● dev-ttyS7.device - /dev/ttyS7
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.7-tty-ttyS7.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.7/tty/ttyS7

● dev-ttyS8.device - /dev/ttyS8
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.8-tty-ttyS8.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.8/tty/ttyS8

● dev-ttyS9.device - /dev/ttyS9
    Follows: unit currently follows state of sys-devices-platform-serial8250-serial8250:0-serial8250:0.9-tty-ttyS9.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.9/tty/ttyS9

● dev-vda.device - /dev/vda
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda

● dev-vda1.device - /dev/vda1
    Follows: unit currently follows state of sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

Notice: journal has been rotated since unit was started, output may be incomplete.

● sys-devices-pci0000:00-0000:00:02.1-0000:03:00.0-virtio1-net-enp3s0.device - Virtio 1.0 network device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.1/0000:03:00.0/virtio1/net/enp3s0

Notice: journal has been rotated since unit was started, output may be incomplete.

● sys-devices-pci0000:00-0000:00:02.2-0000:04:00.0-virtio2-net-enp4s0.device - Virtio 1.0 network device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.2/0000:04:00.0/virtio2/net/enp4s0

Notice: journal has been rotated since unit was started, output may be incomplete.

● sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda-vda1.device - /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda/vda1

● sys-devices-pci0000:00-0000:00:02.3-0000:05:00.0-virtio3-block-vda.device - /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.3/0000:05:00.0/virtio3/block/vda

● sys-devices-pci0000:00-0000:00:1f.2-ata1-host0-target0:0:0-0:0:0:0-block-sr0.device - QEMU_DVD-ROM config-2
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0/block/sr0

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.1-tty-ttyS1.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.1/tty/ttyS1
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.1/tty/ttyS1

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.10-tty-ttyS10.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.10/tty/ttyS10
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.10/tty/ttyS10

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.11-tty-ttyS11.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.11/tty/ttyS11
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.11/tty/ttyS11

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.12-tty-ttyS12.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.12/tty/ttyS12
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.12/tty/ttyS12

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.13-tty-ttyS13.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.13/tty/ttyS13
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.13/tty/ttyS13

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.14-tty-ttyS14.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.14/tty/ttyS14
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.14/tty/ttyS14

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.15-tty-ttyS15.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.15/tty/ttyS15
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.15/tty/ttyS15

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.16-tty-ttyS16.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.16/tty/ttyS16
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.16/tty/ttyS16

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.17-tty-ttyS17.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.17/tty/ttyS17
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.17/tty/ttyS17

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.18-tty-ttyS18.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.18/tty/ttyS18
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.18/tty/ttyS18

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.19-tty-ttyS19.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.19/tty/ttyS19
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.19/tty/ttyS19

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.2-tty-ttyS2.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.2/tty/ttyS2
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.2/tty/ttyS2

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.20-tty-ttyS20.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.20/tty/ttyS20
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.20/tty/ttyS20

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.21-tty-ttyS21.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.21/tty/ttyS21
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.21/tty/ttyS21

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.22-tty-ttyS22.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.22/tty/ttyS22
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.22/tty/ttyS22

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.23-tty-ttyS23.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.23/tty/ttyS23
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.23/tty/ttyS23

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.24-tty-ttyS24.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.24/tty/ttyS24
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.24/tty/ttyS24

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.25-tty-ttyS25.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.25/tty/ttyS25
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.25/tty/ttyS25

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.26-tty-ttyS26.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.26/tty/ttyS26
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.26/tty/ttyS26

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.27-tty-ttyS27.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.27/tty/ttyS27
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.27/tty/ttyS27

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.28-tty-ttyS28.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.28/tty/ttyS28
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.28/tty/ttyS28

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.29-tty-ttyS29.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.29/tty/ttyS29
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.29/tty/ttyS29

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.3-tty-ttyS3.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.3/tty/ttyS3
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.3/tty/ttyS3

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.30-tty-ttyS30.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.30/tty/ttyS30
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.30/tty/ttyS30

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.31-tty-ttyS31.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.31/tty/ttyS31
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.31/tty/ttyS31

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.4-tty-ttyS4.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.4/tty/ttyS4
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.4/tty/ttyS4

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.5-tty-ttyS5.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.5/tty/ttyS5
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.5/tty/ttyS5

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.6-tty-ttyS6.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.6/tty/ttyS6
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.6/tty/ttyS6

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.7-tty-ttyS7.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.7/tty/ttyS7
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.7/tty/ttyS7

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.8-tty-ttyS8.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.8/tty/ttyS8
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.8/tty/ttyS8

● sys-devices-platform-serial8250-serial8250:0-serial8250:0.9-tty-ttyS9.device - /sys/devices/platform/serial8250/serial8250:0/serial8250:0.9/tty/ttyS9
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/platform/serial8250/serial8250:0/serial8250:0.9/tty/ttyS9

● sys-devices-pnp0-00:00-00:00:0-00:00:0.0-tty-ttyS0.device - /sys/devices/pnp0/00:00/00:00:0/00:00:0.0/tty/ttyS0
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pnp0/00:00/00:00:0/00:00:0.0/tty/ttyS0

● sys-devices-virtual-block-dm\x2d1.device - /sys/devices/virtual/block/dm-1
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 17:17:48 UTC; 15min ago
     Device: /sys/devices/virtual/block/dm-1

● sys-devices-virtual-misc-rfkill.device - /sys/devices/virtual/misc/rfkill
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/virtual/misc/rfkill

● sys-devices-virtual-net-br\x2dex.device - /sys/devices/virtual/net/br-ex
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:53:51 UTC; 39min ago
     Device: /sys/devices/virtual/net/br-ex

● sys-devices-virtual-net-br\x2dint.device - /sys/devices/virtual/net/br-int
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:46:32 UTC; 46min ago
     Device: /sys/devices/virtual/net/br-int

● sys-devices-virtual-net-lo.device - /sys/devices/virtual/net/lo
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/virtual/net/lo

Notice: journal has been rotated since unit was started, output may be incomplete.

● sys-devices-virtual-net-ovs\x2dsystem.device - /sys/devices/virtual/net/ovs-system
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:46:32 UTC; 46min ago
     Device: /sys/devices/virtual/net/ovs-system

● sys-devices-virtual-net-virbr0.device - /sys/devices/virtual/net/virbr0
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:51:26 UTC; 41min ago
     Device: /sys/devices/virtual/net/virbr0

● sys-devices-virtual-tty-ttyprintk.device - /sys/devices/virtual/tty/ttyprintk
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/virtual/tty/ttyprintk

● sys-module-configfs.device - /sys/module/configfs
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/module/configfs

● sys-module-fuse.device - /sys/module/fuse
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/module/fuse

● sys-subsystem-net-devices-br\x2dex.device - /sys/subsystem/net/devices/br-ex
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:53:51 UTC; 39min ago
     Device: /sys/devices/virtual/net/br-ex

● sys-subsystem-net-devices-br\x2dint.device - /sys/subsystem/net/devices/br-int
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:46:32 UTC; 46min ago
     Device: /sys/devices/virtual/net/br-int

● sys-subsystem-net-devices-enp3s0.device - Virtio 1.0 network device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.1/0000:03:00.0/virtio1/net/enp3s0

● sys-subsystem-net-devices-enp4s0.device - Virtio 1.0 network device
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
     Device: /sys/devices/pci0000:00/0000:00:02.2/0000:04:00.0/virtio2/net/enp4s0

● sys-subsystem-net-devices-ovs\x2dsystem.device - /sys/subsystem/net/devices/ovs-system
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:46:32 UTC; 46min ago
     Device: /sys/devices/virtual/net/ovs-system

● sys-subsystem-net-devices-virbr0.device - /sys/subsystem/net/devices/virbr0
     Loaded: loaded
     Active: active (plugged) since Tue 2025-07-29 16:51:26 UTC; 41min ago
     Device: /sys/devices/virtual/net/virbr0

● -.mount - Root Mount
     Loaded: loaded (/etc/fstab; generated)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Where: /
       What: /dev/vda1
       Docs: man:fstab(5)
             man:systemd-fstab-generator(8)

Notice: journal has been rotated since unit was started, output may be incomplete.

● dev-hugepages.mount - Huge Pages File System
     Loaded: loaded (/proc/self/mountinfo; static)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Where: /dev/hugepages
       What: hugetlbfs
       Docs: https://docs.kernel.org/admin-guide/mm/hugetlbpage.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
      Tasks: 0 (limit: 9444)
     Memory: 296.0K (peak: 1.0M)
        CPU: 2ms
     CGroup: /dev-hugepages.mount

Notice: journal has been rotated since unit was started, output may be incomplete.

● dev-mqueue.mount - POSIX Message Queue File System
     Loaded: loaded (/proc/self/mountinfo; static)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Where: /dev/mqueue
       What: mqueue
       Docs: man:mq_overview(7)
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
      Tasks: 0 (limit: 9444)
     Memory: 204.0K (peak: 1.8M)
        CPU: 4ms
     CGroup: /dev-mqueue.mount

Notice: journal has been rotated since unit was started, output may be incomplete.

● mnt-config.mount - /mnt/config
     Loaded: loaded (/proc/self/mountinfo)
     Active: active (mounted) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
      Where: /mnt/config
       What: /dev/sr0

● opt-stack-data-etcd.mount - /opt/stack/data/etcd
     Loaded: loaded (/proc/self/mountinfo)
     Active: active (mounted) since Tue 2025-07-29 16:44:51 UTC; 48min ago
      Where: /opt/stack/data/etcd
       What: tmpfs

● proc-sys-fs-binfmt_misc.mount - Arbitrary Executable File Formats File System
     Loaded: loaded (/proc/self/mountinfo; disabled; preset: disabled)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
TriggeredBy: ● proc-sys-fs-binfmt_misc.automount
      Where: /proc/sys/fs/binfmt_misc
       What: binfmt_misc
       Docs: https://docs.kernel.org/admin-guide/binfmt-misc.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
      Tasks: 0 (limit: 9444)
     Memory: 8.0K (peak: 1.7M)
        CPU: 4ms
     CGroup: /proc-sys-fs-binfmt_misc.mount

Jul 29 14:32:52 ubuntu systemd[1]: Mounting proc-sys-fs-binfmt_misc.mount - Arbitrary Executable File Formats File System...
Jul 29 14:32:52 ubuntu systemd[1]: Mounted proc-sys-fs-binfmt_misc.mount - Arbitrary Executable File Formats File System.

● run-netns.mount - /run/netns
     Loaded: loaded (/proc/self/mountinfo)
     Active: active (mounted) since Tue 2025-07-29 16:56:23 UTC; 36min ago
      Where: /run/netns
       What: tmpfs

● run-user-1000.mount - /run/user/1000
     Loaded: loaded (/proc/self/mountinfo)
     Active: active (mounted) since Tue 2025-07-29 16:38:24 UTC; 54min ago
      Where: /run/user/1000
       What: tmpfs

● sys-fs-fuse-connections.mount - FUSE Control File System
     Loaded: loaded (/proc/self/mountinfo; static)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Where: /sys/fs/fuse/connections
       What: fusectl
       Docs: https://docs.kernel.org/filesystems/fuse.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
      Tasks: 0 (limit: 9444)
     Memory: 4.0K (peak: 348.0K)
        CPU: 1ms
     CGroup: /sys-fs-fuse-connections.mount

Jul 29 14:32:52 ubuntu systemd[1]: Mounting sys-fs-fuse-connections.mount - FUSE Control File System...
Jul 29 14:32:52 ubuntu systemd[1]: Mounted sys-fs-fuse-connections.mount - FUSE Control File System.

● sys-kernel-config.mount - Kernel Configuration File System
     Loaded: loaded (/proc/self/mountinfo; static)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Where: /sys/kernel/config
       What: configfs
       Docs: https://docs.kernel.org/filesystems/configfs.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
      Tasks: 0 (limit: 9444)
     Memory: 4.0K (peak: 1.7M)
        CPU: 4ms
     CGroup: /sys-kernel-config.mount

Jul 29 14:32:52 ubuntu systemd[1]: Mounting sys-kernel-config.mount - Kernel Configuration File System...
Jul 29 14:32:52 ubuntu systemd[1]: Mounted sys-kernel-config.mount - Kernel Configuration File System.

● sys-kernel-debug.mount - Kernel Debug File System
     Loaded: loaded (/proc/self/mountinfo; static)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Where: /sys/kernel/debug
       What: debugfs
       Docs: https://docs.kernel.org/filesystems/debugfs.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
      Tasks: 0 (limit: 9444)
     Memory: 4.0K (peak: 1.7M)
        CPU: 4ms
     CGroup: /sys-kernel-debug.mount

Notice: journal has been rotated since unit was started, output may be incomplete.

● sys-kernel-tracing.mount - Kernel Trace File System
     Loaded: loaded (/proc/self/mountinfo; static)
     Active: active (mounted) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Where: /sys/kernel/tracing
       What: tracefs
       Docs: https://docs.kernel.org/trace/ftrace.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
      Tasks: 0 (limit: 9444)
     Memory: 4.0K (peak: 1.5M)
        CPU: 3ms
     CGroup: /sys-kernel-tracing.mount

Notice: journal has been rotated since unit was started, output may be incomplete.

○ var-lib-machines.mount - Virtual Machine and Container Storage (Compatibility)
     Loaded: loaded (/usr/lib/systemd/system/var-lib-machines.mount; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 16:51:26 UTC; 41min ago
      Where: /var/lib/machines
       What: /var/lib/machines.raw

Jul 29 16:51:24 np0000031958 systemd[1]: var-lib-machines.mount - Virtual Machine and Container Storage (Compatibility) was skipped because of an unmet condition check (ConditionPathExists=/var/lib/machines.raw).
Jul 29 16:51:26 np0000031958 systemd[1]: var-lib-machines.mount - Virtual Machine and Container Storage (Compatibility) was skipped because of an unmet condition check (ConditionPathExists=/var/lib/machines.raw).

● acpid.path - ACPI Events Check
     Loaded: loaded (/usr/lib/systemd/system/acpid.path; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Triggers: ● acpid.service

Jul 29 14:32:53 ubuntu systemd[1]: Started acpid.path - ACPI Events Check.

● systemd-ask-password-console.path - Dispatch Password Requests to Console Directory Watch
     Loaded: loaded (/usr/lib/systemd/system/systemd-ask-password-console.path; static)
     Active: active (waiting) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-ask-password-console.service
       Docs: man:systemd-ask-password-console.path(8)

Notice: journal has been rotated since unit was started, output may be incomplete.

● systemd-ask-password-wall.path - Forward Password Requests to Wall Directory Watch
     Loaded: loaded (/usr/lib/systemd/system/systemd-ask-password-wall.path; static)
     Active: active (waiting) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-ask-password-wall.service
       Docs: man:systemd-ask-password-wall.path(8)

Notice: journal has been rotated since unit was started, output may be incomplete.

● init.scope - System and Service Manager
     Loaded: loaded
  Transient: yes
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd(1)
      Tasks: 1 (limit: 9444)
     Memory: 10.6M (peak: 21.0M swap: 16.0K swap peak: 16.0K zswap: 1.2K)
        CPU: 25.164s
     CGroup: /init.scope
             └─1 /sbin/init nofb

Jul 29 17:31:51 np0000031958 systemd[1]: machine-qemu\x2d80\x2dinstance\x2d00000038.scope: Consumed 22.288s CPU time.
Jul 29 17:32:00 np0000031958 systemd[1]: machine-qemu\x2d79\x2dinstance\x2d00000037.scope: Deactivated successfully.
Jul 29 17:32:00 np0000031958 systemd[1]: machine-qemu\x2d79\x2dinstance\x2d00000037.scope: Consumed 21.857s CPU time.
Jul 29 17:32:00 np0000031958 systemd[1]: run-netns-ovnmeta\x2d0656be21\x2d9f8e\x2d413a\x2d861a\x2dbe5cee277270.mount: Deactivated successfully.
Jul 29 17:32:19 np0000031958 systemd[1]: session-9.scope: Deactivated successfully.
Jul 29 17:32:19 np0000031958 systemd[1]: session-9.scope: Consumed 6min 46.096s CPU time, 3.8G memory peak, 0B memory swap peak.
Jul 29 17:32:20 np0000031958 systemd[1]: Started session-11.scope - Session 11 of User zuul.
Jul 29 17:32:47 np0000031958 systemd[1]: session-11.scope: Deactivated successfully.
Jul 29 17:32:47 np0000031958 systemd[1]: session-11.scope: Consumed 19.132s CPU time.
Jul 29 17:32:47 np0000031958 systemd[1]: Started session-12.scope - Session 12 of User zuul.

● session-12.scope - Session 12 of User zuul
     Loaded: loaded (/run/systemd/transient/session-12.scope; transient)
  Transient: yes
     Active: active (running) since Tue 2025-07-29 17:32:47 UTC; 29s ago
      Tasks: 10
     Memory: 245.3M (peak: 272.2M)
        CPU: 31.925s
     CGroup: /user.slice/user-1000.slice/session-12.scope
             ├─132488 "sshd: zuul [priv]"
             ├─132498 "sshd: zuul@notty"
             ├─134021 /bin/sh -c "sudo -H -S -n  -u root /bin/sh -c 'echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3' && sleep 0"
             ├─134022 sudo -H -S -n -u root /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
             ├─134023 /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
             ├─134024 /usr/bin/python3
             ├─134027 /bin/bash -c "sudo iptables-save > /home/zuul/iptables.txt\ndf -h > /home/zuul/df.txt\n\nfor py_ver in 2 3; do\n    if [[ \`which python\${py_ver}\` ]]; then\n        python\${py_ver} -m pip freeze > /home/zuul/pip\${py_ver}-freeze.txt\n    fi\ndone\n\nif [ \`command -v dpkg\` ]; then\n    dpkg -l> /home/zuul/dpkg-l.txt\nfi\nif [ \`command -v rpm\` ]; then\n    rpm -qa | sort > /home/zuul/rpm-qa.txt\nfi\n\n# Services status\nsudo systemctl status --all > services.txt 2>/dev/null\n\n# NOTE(kchamart) The 'audit.log' can be useful in cases when QEMU\n# failed to start due to denials from SELinux — useful for CentOS\n# and Fedora machines.  For Ubuntu (which runs AppArmor), DevStack\n# already captures the contents of /var/log/kern.log (via\n# \`journalctl -t kernel\` redirected into syslog.txt.gz), which\n# contains AppArmor-related messages.\nif [ -f /var/log/audit/audit.log ] ; then\n    sudo cp /var/log/audit/audit.log /home/zuul/audit.log &&\n    chmod +r /home/zuul/audit.log;\nfi\n\n# gzip and save any coredumps in /var/core\nif [ -d /var/core ]; then\n    sudo gzip -r /var/core\n    sudo cp -r /var/core /home/zuul/\nfi\n\nsudo ss -lntup | grep ':53' > /home/zuul/listen53.txt\n\n# NOTE(andreaf) Service logs are already in logs/ thanks for the\n# export-devstack-journal log. Apache logs are under apache/ thans to the\n# apache-logs-conf role.\ngrep -i deprecat /home/zuul/logs/*.txt /home/zuul/apache/*.log | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}\\.[0-9]{1,3}/ /g' | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}/ /g' | \\\n    sed -r 's/[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}/ /g' |\n    sed -r 's/\\[.*\\]/ /g' | \\\n    sed -r 's/\\s[0-9]+\\s/ /g' | \\\n    awk '{if (\$0 in seen) {seen[\$0]++} else {out[++n]=\$0;seen[\$0]=1}} END { for (i=1; i<=n; i++) print seen[out[i]]\" :: \" out[i] }' > /home/zuul/deprecations.log\n"
             ├─134038 sudo systemctl status --all
             └─134039 systemctl status --all

Jul 29 17:33:15 np0000031958 python3[134015]: ansible-ansible.legacy.command Invoked with _raw_params=cp -pRL /etc/openstack /home/zuul/etc/ zuul_log_id=fa163e4d-f4e4-406c-fe2b-00000000002f-1-controller zuul_ansible_split_streams=False _uses_shell=False warn=False stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
Jul 29 17:33:15 np0000031958 sudo[134013]: pam_unix(sudo:session): session closed for user root
Jul 29 17:33:16 np0000031958 sudo[134022]:     zuul : PWD=/home/zuul ; USER=root ; COMMAND=/bin/sh -c 'echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3'
Jul 29 17:33:16 np0000031958 sudo[134022]: pam_unix(sudo:session): session opened for user root(uid=0) by zuul(uid=1000)
Jul 29 17:33:16 np0000031958 python3[134024]: ansible-ansible.legacy.command Invoked with executable=/bin/bash _raw_params=sudo iptables-save > /home/zuul/iptables.txt
                                              df -h > /home/zuul/df.txt
                                              
                                              for py_ver in 2 3; do
                                                  if [[ `which python${py_ver}` ]]; then
                                                      python${py_ver} -m pip freeze > /home/zuul/pip${py_ver}-freeze.txt
                                                  fi
                                              done
                                              
                                              if [ `command -v dpkg` ]; then
                                                  dpkg -l> /home/zuul/dpkg-l.txt
                                              fi
                                              if [ `command -v rpm` ]; then
                                                  rpm -qa | sort > /home/zuul/rpm-qa.txt
                                              fi
                                              
                                              # Services status
                                              sudo systemctl status --all > services.txt 2>/dev/null
                                              
                                              # NOTE(kchamart) The 'audit.log' can be useful in cases when QEMU
                                              # failed to start due to denials from SELinux — useful for CentOS
                                              # and Fedora machines.  For Ubuntu (which runs AppArmor), DevStack
                                              # already captures the contents of /var/log/kern.log (via
                                              # `journalctl -t kernel` redirected into syslog.txt.gz), which
                                              # contains AppArmor-related messages.
                                              if [ -f /var/log/audit/audit.log ] ; then
                                                  sudo cp /var/log/audit/audit.log /home/zuul/audit.log &&
                                                  chmod +r /home/zuul/audit.log;
                                              fi
                                              
                                              # gzip and save any coredumps in /var/core
                                              if [ -d /var/core ]; then
                                                  sudo gzip -r /var/core
                                                  sudo cp -r /var/core /home/zuul/
                                              fi
                                              
                                              sudo ss -lntup | grep ':53' > /home/zuul/listen53.txt
                                              
                                              # NOTE(andreaf) Service logs are already in logs/ thanks for the
                                              # export-devstack-journal log. Apache logs are under apache/ thans to the
                                              # apache-logs-conf role.
                                              grep -i deprecat /home/zuul/logs/*.txt /home/zuul/apache/*.log | \
                                                  sed -r 's/[0-9]{1,2}\:[0-9]{1,2}\:[0-9]{1,2}\.[0-9]{1,3}/ /g' | \
                                                  sed -r 's/[0-9]{1,2}\:[0-9]{1,2}\:[0-9]{1,2}/ /g' | \
                                                  sed -r 's/[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}/ /g' |
                                                  sed -r 's/\[.*\]/ /g' | \
                                                  sed -r 's/\s[0-9]+\s/ /g' | \
                                                  awk '{if ($0 in seen) {seen[$0]++} else {out[++n]=$0;seen[$0]=1}} END { for (i=1; i<=n; i++) print seen[out[i]]" :: " out[i] }' > /home/zuul/deprecations.log
                                               _uses_shell=True zuul_log_id=fa163e4d-f4e4-406c-fe2b-000000000033-1-controller zuul_ansible_split_streams=False warn=False stdin_add_newline=True strip_empty_ends=True argv=None chdir=None creates=None removes=None stdin=None
Jul 29 17:33:16 np0000031958 sudo[134029]:     root : PWD=/home/zuul ; USER=root ; COMMAND=/usr/sbin/iptables-save
Jul 29 17:33:16 np0000031958 sudo[134029]: pam_unix(sudo:session): session opened for user root(uid=0) by zuul(uid=0)
Jul 29 17:33:16 np0000031958 sudo[134029]: pam_unix(sudo:session): session closed for user root
Jul 29 17:33:16 np0000031958 sudo[134038]:     root : PWD=/home/zuul ; USER=root ; COMMAND=/usr/bin/systemctl status --all
Jul 29 17:33:16 np0000031958 sudo[134038]: pam_unix(sudo:session): session opened for user root(uid=0) by zuul(uid=0)

● session-3.scope - Session 3 of User zuul
     Loaded: loaded (/run/systemd/transient/session-3.scope; transient)
  Transient: yes
     Active: active (abandoned) since Tue 2025-07-29 16:38:24 UTC; 54min ago
      Tasks: 4
     Memory: 17.4M (peak: 54.7M swap: 4.7M swap peak: 4.7M zswap: 1.4M)
        CPU: 2min 47.078s
     CGroup: /user.slice/user-1000.slice/session-3.scope
             └─1747 /usr/bin/python3

Jul 29 16:38:24 np0000031958 systemd[1]: Started session-3.scope - Session 3 of User zuul.
Jul 29 16:38:25 np0000031958 ansible-setup[1634]: Invoked with gather_subset=['!all'] gather_timeout=10 filter=[] fact_path=/etc/ansible/facts.d
Jul 29 16:38:26 np0000031958 ansible-ansible.legacy.setup[1670]: Invoked with gather_subset=['all'] gather_timeout=10 filter=[] fact_path=/etc/ansible/facts.d
Jul 29 16:38:29 np0000031958 ansible-zuul_console[1745]: Invoked with path=/tmp/console-{log_uuid}.log port=19885 state=present
Jul 29 16:38:30 np0000031958 ansible-setup[1750]: Invoked with gather_subset=['all'] gather_timeout=10 filter=[] fact_path=/etc/ansible/facts.d
Jul 29 16:38:31 np0000031958 ansible-zuul_debug_info[1826]: Invoked with ipv4_route_required=False ipv6_route_required=False image_manifest_files=['/etc/dib-builddate.txt', '/etc/image-hostname.txt'] image_manifest=None traceroute_host=None
Jul 29 16:38:31 np0000031958 ansible-zuul_console[1837]: Invoked with path=/tmp/console-{log_uuid}.log port=19885 state=present
Jul 29 16:39:31 np0000031958 sshd[1626]: Received disconnect from 192.168.1.141 port 39580:11: disconnected by user
Jul 29 16:39:31 np0000031958 sshd[1626]: Disconnected from user zuul 192.168.1.141 port 39580
Jul 29 16:39:31 np0000031958 sshd[1600]: pam_unix(sshd:session): session closed for user zuul

○ acpid.service - ACPI event daemon
     Loaded: loaded (/usr/lib/systemd/system/acpid.service; disabled; preset: enabled)
     Active: inactive (dead)
TriggeredBy: ● acpid.path
             ● acpid.socket
       Docs: man:acpid(8)

● apache-htcacheclean.service - Disk Cache Cleaning Daemon for Apache HTTP Server
     Loaded: loaded (/usr/lib/systemd/system/apache-htcacheclean.service; disabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:43:17 UTC; 49min ago
       Docs: https://httpd.apache.org/docs/2.4/programs/htcacheclean.html
   Main PID: 12079 (htcacheclean)
      Tasks: 1 (limit: 9444)
     Memory: 300.0K (peak: 868.0K)
        CPU: 47ms
     CGroup: /system.slice/apache-htcacheclean.service
             └─12079 /usr/bin/htcacheclean -d 120 -p /var/cache/apache2/mod_cache_disk -l 300M -n

Jul 29 16:43:17 np0000031958 systemd[1]: Starting apache-htcacheclean.service - Disk Cache Cleaning Daemon for Apache HTTP Server...
Jul 29 16:43:17 np0000031958 systemd[1]: Started apache-htcacheclean.service - Disk Cache Cleaning Daemon for Apache HTTP Server.

● apache2.service - The Apache HTTP Server
     Loaded: loaded (/usr/lib/systemd/system/apache2.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:08 UTC; 40min ago
       Docs: https://httpd.apache.org/docs/2.4/
   Main PID: 60135 (apache2)
      Tasks: 69 (limit: 9444)
     Memory: 26.2M (peak: 45.3M swap: 2.5M swap peak: 2.5M zswap: 597.5K)
        CPU: 33.344s
     CGroup: /system.slice/apache2.service
             ├─60135 /usr/sbin/apache2 -k start
             ├─60141 /usr/sbin/apache2 -k start
             └─60142 /usr/sbin/apache2 -k start

Jul 29 16:53:08 np0000031958 systemd[1]: Starting apache2.service - The Apache HTTP Server...
Jul 29 16:53:08 np0000031958 apachectl[60134]: AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.0.1. Set the 'ServerName' directive globally to suppress this message
Jul 29 16:53:08 np0000031958 systemd[1]: Started apache2.service - The Apache HTTP Server.

○ apt-daily-upgrade.service - Daily apt upgrade and clean activities
     Loaded: loaded (/usr/lib/systemd/system/apt-daily-upgrade.service; static)
     Active: inactive (dead)
TriggeredBy: ● apt-daily-upgrade.timer
       Docs: man:apt(8)

○ apt-daily.service - Daily apt download activities
     Loaded: loaded (/usr/lib/systemd/system/apt-daily.service; static)
     Active: inactive (dead)
TriggeredBy: ● apt-daily.timer
       Docs: man:apt(8)

● atd.service - Deferred execution scheduler
     Loaded: loaded (/usr/lib/systemd/system/atd.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:atd(8)
   Main PID: 1007 (atd)
      Tasks: 1 (limit: 9444)
     Memory: 300.0K (peak: 1.6M)
        CPU: 7ms
     CGroup: /system.slice/atd.service
             └─1007 /usr/sbin/atd -f

Jul 29 14:34:55 np0000031958 systemd[1]: Starting atd.service - Deferred execution scheduler...
Jul 29 14:34:55 np0000031958 systemd[1]: Started atd.service - Deferred execution scheduler.

● blk-availability.service - Availability of block devices
     Loaded: loaded (/usr/lib/systemd/system/blk-availability.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:43:19 UTC; 49min ago

Jul 29 16:43:19 np0000031958 systemd[1]: Finished blk-availability.service - Availability of block devices.

● cron.service - Regular background program processing daemon
     Loaded: loaded (/usr/lib/systemd/system/cron.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:cron(8)
   Main PID: 1005 (cron)
      Tasks: 1 (limit: 9444)
     Memory: 540.0K (peak: 1.9M)
        CPU: 25ms
     CGroup: /system.slice/cron.service
             └─1005 /usr/sbin/cron -f -P

Jul 29 14:34:55 np0000031958 cron[1005]: (CRON) INFO (Running @reboot jobs)
Jul 29 15:17:01 np0000031958 CRON[1584]: pam_unix(cron:session): session opened for user root(uid=0) by root(uid=0)
Jul 29 15:17:01 np0000031958 CRON[1585]: (root) CMD (cd / && run-parts --report /etc/cron.hourly)
Jul 29 15:17:01 np0000031958 CRON[1584]: pam_unix(cron:session): session closed for user root
Jul 29 16:17:01 np0000031958 CRON[1594]: pam_unix(cron:session): session opened for user root(uid=0) by root(uid=0)
Jul 29 16:17:01 np0000031958 CRON[1595]: (root) CMD (cd / && run-parts --report /etc/cron.hourly)
Jul 29 16:17:01 np0000031958 CRON[1594]: pam_unix(cron:session): session closed for user root
Jul 29 17:17:01 np0000031958 CRON[120371]: pam_unix(cron:session): session opened for user root(uid=0) by root(uid=0)
Jul 29 17:17:01 np0000031958 CRON[120372]: (root) CMD (cd / && run-parts --report /etc/cron.hourly)
Jul 29 17:17:01 np0000031958 CRON[120371]: pam_unix(cron:session): session closed for user root

● dbus.service - D-Bus System Message Bus
     Loaded: loaded (/usr/lib/systemd/system/dbus.service; static)
     Active: active (running) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
TriggeredBy: ● dbus.socket
       Docs: man:dbus-daemon(1)
   Main PID: 521 (dbus-daemon)
      Tasks: 1 (limit: 9444)
     Memory: 1.5M (peak: 2.4M)
        CPU: 3.565s
     CGroup: /system.slice/dbus.service
             └─521 @dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only

Jul 29 16:43:00 np0000031958 dbus-daemon[521]: Unknown username "dnsmasq" in message bus configuration file
Jul 29 16:43:00 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:43:19 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:51:21 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:51:21 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:51:21 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:51:21 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:51:21 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:51:21 np0000031958 dbus-daemon[521]: [system] Reloaded configuration
Jul 29 16:51:28 np0000031958 dbus-daemon[521]: [system] Reloaded configuration

● devstack@c-api.service - Devstack devstack@c-api.service
     Loaded: loaded (/etc/systemd/system/devstack@c-api.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:20 UTC; 38min ago
   Main PID: 78016 (uwsgi)
     Status: "uWSGI is ready"
      Tasks: 11 (limit: 9444)
     Memory: 284.3M (peak: 284.8M swap: 25.8M swap peak: 25.9M zswap: 6.4M)
        CPU: 1min 8.657s
     CGroup: /system.slice/system-devstack.slice/devstack@c-api.service
             ├─78016 "cinder-apiuWSGI master"
             ├─78022 "cinder-apiuWSGI worker 1"
             └─78023 "cinder-apiuWSGI worker 2"

Jul 29 17:32:16 np0000031958 devstack@c-api.service[78023]: INFO cinder.api.openstack.wsgi [[01;36mNone req-87ebf141-e26f-4de2-992e-9be79fa42cdf [00;36mtempest-CreateVolumesFromImageTest-996366964 tempest-CreateVolumesFromImageTest-996366964-project-member] [01;35mhttps://192.168.1.104/volume/v3/volumes/c4c6886a-3558-4f47-a374-9a29abd40d65 returned with HTTP 200[00m
Jul 29 17:32:16 np0000031958 devstack@c-api.service[78023]: [pid: 78023|app: 0|req: 1776/3621] 192.168.1.104 () {66 vars in 1361 bytes} [Tue Jul 29 17:32:16 2025] GET /volume/v3/volumes/c4c6886a-3558-4f47-a374-9a29abd40d65 => generated 968 bytes in 12 msecs (HTTP/1.1 200) 7 headers in 285 bytes (1 switches on core 0)
Jul 29 17:32:17 np0000031958 devstack@c-api.service[78022]: DEBUG cinder.api.middleware.request_id [[01;36mNone req-b4bc4bc4-b087-4ba1-9c2d-f96b87e3d88c [00;36mNone None] [01;35mRequestId filter calling following filter/app[00m [00;33m{{(pid=78022) _context_setter /opt/stack/cinder/cinder/api/middleware/request_id.py:62}}[00m
Jul 29 17:32:17 np0000031958 devstack@c-api.service[78022]: INFO cinder.api.openstack.wsgi [[01;36mNone req-b4bc4bc4-b087-4ba1-9c2d-f96b87e3d88c [00;36mtempest-CreateVolumesFromImageTest-996366964 tempest-CreateVolumesFromImageTest-996366964-project-member] [01;35mGET https://192.168.1.104/volume/v3/volumes/c4c6886a-3558-4f47-a374-9a29abd40d65[00m
Jul 29 17:32:17 np0000031958 devstack@c-api.service[78022]: DEBUG cinder.api.openstack.wsgi [[01;36mNone req-b4bc4bc4-b087-4ba1-9c2d-f96b87e3d88c [00;36mtempest-CreateVolumesFromImageTest-996366964 tempest-CreateVolumesFromImageTest-996366964-project-member] [01;35mEmpty body provided in request[00m [00;33m{{(pid=78022) get_body /opt/stack/cinder/cinder/api/openstack/wsgi.py:715}}[00m
Jul 29 17:32:17 np0000031958 devstack@c-api.service[78022]: DEBUG cinder.api.openstack.wsgi [[01;36mNone req-b4bc4bc4-b087-4ba1-9c2d-f96b87e3d88c [00;36mtempest-CreateVolumesFromImageTest-996366964 tempest-CreateVolumesFromImageTest-996366964-project-member] [01;35mCalling method 'show'[00m [00;33m{{(pid=78022) _process_stack /opt/stack/cinder/cinder/api/openstack/wsgi.py:868}}[00m
Jul 29 17:32:17 np0000031958 devstack@c-api.service[78022]: INFO cinder.api.openstack.wsgi [[01;36mNone req-b4bc4bc4-b087-4ba1-9c2d-f96b87e3d88c [00;36mtempest-CreateVolumesFromImageTest-996366964 tempest-CreateVolumesFromImageTest-996366964-project-member] [01;35mhttps://192.168.1.104/volume/v3/volumes/c4c6886a-3558-4f47-a374-9a29abd40d65 returned with HTTP 404[00m
Jul 29 17:32:17 np0000031958 devstack@c-api.service[78022]: [pid: 78022|app: 0|req: 1846/3622] 192.168.1.104 () {66 vars in 1361 bytes} [Tue Jul 29 17:32:17 2025] GET /volume/v3/volumes/c4c6886a-3558-4f47-a374-9a29abd40d65 => generated 109 bytes in 7 msecs (HTTP/1.1 404) 7 headers in 292 bytes (1 switches on core 0)
Jul 29 17:32:26 np0000031958 devstack@c-api.service[78023]: DEBUG dbcounter [[00;36m-] [01;35m[78023] Writing DB stats cinder:SELECT=137,cinder:UPDATE=46,cinder:INSERT=25[00m [00;33m{{(pid=78023) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:27 np0000031958 devstack@c-api.service[78022]: DEBUG dbcounter [[00;36m-] [01;35m[78022] Writing DB stats cinder:SELECT=100,cinder:UPDATE=33,cinder:INSERT=17[00m [00;33m{{(pid=78022) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@c-sch.service - Devstack devstack@c-sch.service
     Loaded: loaded (/etc/systemd/system/devstack@c-sch.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:23 UTC; 38min ago
   Main PID: 78804 (cinder-schedule)
      Tasks: 1 (limit: 9444)
     Memory: 126.7M (peak: 127.2M swap: 76.3M swap peak: 76.5M zswap: 20.8M)
        CPU: 9.785s
     CGroup: /system.slice/system-devstack.slice/devstack@c-sch.service
             └─78804 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf

Jul 29 17:32:11 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.manager [[01;36mNone req-7d3935f9-d222-401c-9438-f8962e2c7691 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mTask 'cinder.scheduler.flows.create_volume.ScheduleCreateVolumeTask;volume:create' (3044201d-af19-4d2d-9920-8d94fccee458) transitioned into state 'SUCCESS' from state 'RUNNING' with result 'None'[00m [00;33m{{(pid=78804) _task_receiver /opt/stack/data/venv/lib/python3.12/site-packages/taskflow/listeners/logging.py:182}}[00m
Jul 29 17:32:11 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.manager [[01;36mNone req-7d3935f9-d222-401c-9438-f8962e2c7691 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mFlow 'volume_create_scheduler' (7c99601b-1b11-4124-8205-e1445f820bc4) transitioned into state 'SUCCESS' from state 'RUNNING'[00m [00;33m{{(pid=78804) _flow_receiver /opt/stack/data/venv/lib/python3.12/site-packages/taskflow/listeners/logging.py:145}}[00m
Jul 29 17:32:13 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.host_manager [[01;36mNone req-9a7cf1e2-8e2b-4aaa-a8f5-076ad0f6b4e0 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mReceived volume service update from Cluster: pure-cluster-1@puredriver-1 - Host:  np0000031958@puredriver-1: {'volume_backend_name': 'puredriver-1', 'vendor_name': 'Pure Storage', 'driver_version': '21.0.iscsi', 'storage_protocol': 'iSCSI', 'consistencygroup_support': True, 'thin_provisioning_support': True, 'multiattach': True, 'consistent_group_replication_enabled': True, 'consistent_group_snapshot_enabled': True, 'QoS_support': True, 'total_capacity_gb': 23990.484375, 'free_capacity_gb': 23990.479012914002, 'reserved_percentage': 0, 'provisioned_capacity': 9193.0, 'max_over_subscription_ratio': 20.0, 'filter_function': None, 'goodness_function': None, 'total_volumes': 9197, 'total_snapshots': 25, 'total_hosts': 55, 'total_pgroups': 0, 'writes_per_sec': 1, 'reads_per_sec': 18, 'input_per_sec': 16530, 'output_per_sec': 451514, 'usec_per_read_op': 62, 'usec_per_write_op': 234, 'queue_depth': 0, 'queue_usec_per_mirrored_write_op': 0, 'queue_usec_per_read_op': 3, 'queue_usec_per_write_op': 9, 'replication_capability': 'sync', 'replication_enabled': False, 'replication_type': [], 'replication_count': 0, 'replication_targets': [], 'allocated_capacity_gb': 27, 'cacheable': True}Cluster: pure-cluster-1@puredriver-1 - Host: [00m [00;33m{{(pid=78804) update_service_capabilities /opt/stack/cinder/cinder/scheduler/host_manager.py:627}}[00m
Jul 29 17:32:15 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.host_manager [[01;36mNone req-4b255f2a-eddc-455e-9d45-9a55bdeb04b7 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mReceived volume service update from Cluster: pure-cluster-1@puredriver-1 - Host:  np0000031958@puredriver-1: {'volume_backend_name': 'puredriver-1', 'vendor_name': 'Pure Storage', 'driver_version': '21.0.iscsi', 'storage_protocol': 'iSCSI', 'consistencygroup_support': True, 'thin_provisioning_support': True, 'multiattach': True, 'consistent_group_replication_enabled': True, 'consistent_group_snapshot_enabled': True, 'QoS_support': True, 'total_capacity_gb': 23990.484375, 'free_capacity_gb': 23990.479012914002, 'reserved_percentage': 0, 'provisioned_capacity': 9193.0, 'max_over_subscription_ratio': 20.0, 'filter_function': None, 'goodness_function': None, 'total_volumes': 9196, 'total_snapshots': 25, 'total_hosts': 55, 'total_pgroups': 0, 'writes_per_sec': 1, 'reads_per_sec': 18, 'input_per_sec': 16530, 'output_per_sec': 451514, 'usec_per_read_op': 62, 'usec_per_write_op': 234, 'queue_depth': 0, 'queue_usec_per_mirrored_write_op': 0, 'queue_usec_per_read_op': 3, 'queue_usec_per_write_op': 9, 'replication_capability': 'sync', 'replication_enabled': False, 'replication_type': [], 'replication_count': 0, 'replication_targets': [], 'allocated_capacity_gb': 26, 'cacheable': True}Cluster: pure-cluster-1@puredriver-1 - Host: [00m [00;33m{{(pid=78804) update_service_capabilities /opt/stack/cinder/cinder/scheduler/host_manager.py:627}}[00m
Jul 29 17:32:16 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.host_manager [[01;36mNone req-d2478589-2d74-46e5-a2b9-12fa27c2fb7e [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mReceived volume service update from Cluster: pure-cluster-1@puredriver-1 - Host:  np0000031958@puredriver-1: {'volume_backend_name': 'puredriver-1', 'vendor_name': 'Pure Storage', 'driver_version': '21.0.iscsi', 'storage_protocol': 'iSCSI', 'consistencygroup_support': True, 'thin_provisioning_support': True, 'multiattach': True, 'consistent_group_replication_enabled': True, 'consistent_group_snapshot_enabled': True, 'QoS_support': True, 'total_capacity_gb': 23990.484375, 'free_capacity_gb': 23990.479012914002, 'reserved_percentage': 0, 'provisioned_capacity': 9193.0, 'max_over_subscription_ratio': 20.0, 'filter_function': None, 'goodness_function': None, 'total_volumes': 9195, 'total_snapshots': 25, 'total_hosts': 55, 'total_pgroups': 0, 'writes_per_sec': 1, 'reads_per_sec': 18, 'input_per_sec': 16530, 'output_per_sec': 451514, 'usec_per_read_op': 62, 'usec_per_write_op': 234, 'queue_depth': 0, 'queue_usec_per_mirrored_write_op': 0, 'queue_usec_per_read_op': 3, 'queue_usec_per_write_op': 9, 'replication_capability': 'sync', 'replication_enabled': False, 'replication_type': [], 'replication_count': 0, 'replication_targets': [], 'allocated_capacity_gb': 24, 'cacheable': True}Cluster: pure-cluster-1@puredriver-1 - Host: [00m [00;33m{{(pid=78804) update_service_capabilities /opt/stack/cinder/cinder/scheduler/host_manager.py:627}}[00m
Jul 29 17:32:17 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.host_manager [[01;36mNone req-c12f1f95-d582-4260-b5f2-03d7cff828b0 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mReceived volume service update from Cluster: pure-cluster-1@puredriver-1 - Host:  np0000031958@puredriver-1: {'volume_backend_name': 'puredriver-1', 'vendor_name': 'Pure Storage', 'driver_version': '21.0.iscsi', 'storage_protocol': 'iSCSI', 'consistencygroup_support': True, 'thin_provisioning_support': True, 'multiattach': True, 'consistent_group_replication_enabled': True, 'consistent_group_snapshot_enabled': True, 'QoS_support': True, 'total_capacity_gb': 23990.484375, 'free_capacity_gb': 23990.479012914002, 'reserved_percentage': 0, 'provisioned_capacity': 9193.0, 'max_over_subscription_ratio': 20.0, 'filter_function': None, 'goodness_function': None, 'total_volumes': 9194, 'total_snapshots': 25, 'total_hosts': 55, 'total_pgroups': 0, 'writes_per_sec': 1, 'reads_per_sec': 18, 'input_per_sec': 16530, 'output_per_sec': 451514, 'usec_per_read_op': 62, 'usec_per_write_op': 234, 'queue_depth': 0, 'queue_usec_per_mirrored_write_op': 0, 'queue_usec_per_read_op': 3, 'queue_usec_per_write_op': 9, 'replication_capability': 'sync', 'replication_enabled': False, 'replication_type': [], 'replication_count': 0, 'replication_targets': [], 'allocated_capacity_gb': 23, 'cacheable': True}Cluster: pure-cluster-1@puredriver-1 - Host: [00m [00;33m{{(pid=78804) update_service_capabilities /opt/stack/cinder/cinder/scheduler/host_manager.py:627}}[00m
Jul 29 17:32:18 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.host_manager [[01;36mNone req-69412f76-5066-4b24-85c7-d241f7449a13 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mReceived volume service update from Cluster: pure-cluster-1@puredriver-1 - Host:  np0000031958@puredriver-1: {'volume_backend_name': 'puredriver-1', 'vendor_name': 'Pure Storage', 'driver_version': '21.0.iscsi', 'storage_protocol': 'iSCSI', 'consistencygroup_support': True, 'thin_provisioning_support': True, 'multiattach': True, 'consistent_group_replication_enabled': True, 'consistent_group_snapshot_enabled': True, 'QoS_support': True, 'total_capacity_gb': 23990.484375, 'free_capacity_gb': 23990.479012914002, 'reserved_percentage': 0, 'provisioned_capacity': 9193.0, 'max_over_subscription_ratio': 20.0, 'filter_function': None, 'goodness_function': None, 'total_volumes': 9193, 'total_snapshots': 25, 'total_hosts': 55, 'total_pgroups': 0, 'writes_per_sec': 1, 'reads_per_sec': 18, 'input_per_sec': 16530, 'output_per_sec': 451514, 'usec_per_read_op': 62, 'usec_per_write_op': 234, 'queue_depth': 0, 'queue_usec_per_mirrored_write_op': 0, 'queue_usec_per_read_op': 3, 'queue_usec_per_write_op': 9, 'replication_capability': 'sync', 'replication_enabled': False, 'replication_type': [], 'replication_count': 0, 'replication_targets': [], 'allocated_capacity_gb': 23, 'cacheable': True}Cluster: pure-cluster-1@puredriver-1 - Host: [00m [00;33m{{(pid=78804) update_service_capabilities /opt/stack/cinder/cinder/scheduler/host_manager.py:627}}[00m
Jul 29 17:32:21 np0000031958 cinder-scheduler[78804]: DEBUG dbcounter [[00;36m-] [01;35m[78804] Writing DB stats cinder:SELECT=20,cinder:UPDATE=10[00m [00;33m{{(pid=78804) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:39 np0000031958 cinder-scheduler[78804]: DEBUG dbcounter [[00;36m-] [01;35m[78804] Writing DB stats cinder:SELECT=1,cinder:UPDATE=1[00m [00;33m{{(pid=78804) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:46 np0000031958 cinder-scheduler[78804]: DEBUG cinder.scheduler.host_manager [[01;36mNone req-3bd4eca8-e120-42b8-8ad9-88ff96d2cddf [00;36mNone None] [01;35mReceived volume service update from Cluster: pure-cluster-1@puredriver-1 - Host:  np0000031958@puredriver-1: {'volume_backend_name': 'puredriver-1', 'vendor_name': 'Pure Storage', 'driver_version': '21.0.iscsi', 'storage_protocol': 'iSCSI', 'consistencygroup_support': True, 'thin_provisioning_support': True, 'multiattach': True, 'consistent_group_replication_enabled': True, 'consistent_group_snapshot_enabled': True, 'QoS_support': True, 'total_capacity_gb': 23990.484375, 'free_capacity_gb': 23990.479012914002, 'reserved_percentage': 0, 'provisioned_capacity': 9193.0, 'max_over_subscription_ratio': 20.0, 'filter_function': None, 'goodness_function': None, 'total_volumes': 9194, 'total_snapshots': 25, 'total_hosts': 56, 'total_pgroups': 0, 'writes_per_sec': 2, 'reads_per_sec': 17, 'input_per_sec': 39564, 'output_per_sec': 331914, 'usec_per_read_op': 74, 'usec_per_write_op': 247, 'queue_depth': 0, 'queue_usec_per_mirrored_write_op': 0, 'queue_usec_per_read_op': 3, 'queue_usec_per_write_op': 5, 'replication_capability': 'sync', 'replication_enabled': False, 'replication_type': [], 'replication_count': 0, 'replication_targets': [], 'allocated_capacity_gb': 23, 'cacheable': True}Cluster: pure-cluster-1@puredriver-1 - Host: [00m [00;33m{{(pid=78804) update_service_capabilities /opt/stack/cinder/cinder/scheduler/host_manager.py:627}}[00m

● devstack@c-vol.service - Devstack devstack@c-vol.service
     Loaded: loaded (/etc/systemd/system/devstack@c-vol.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:24 UTC; 38min ago
   Main PID: 79416 (cinder-volume)
      Tasks: 33 (limit: 9444)
     Memory: 325.7M (peak: 1.0G swap: 129.5M swap peak: 130.1M zswap: 41.2M)
        CPU: 3min 39.455s
     CGroup: /system.slice/system-devstack.slice/devstack@c-vol.service
             ├─79416 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             ├─80100 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             ├─91425 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context cinder.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmpk5wqr2on/privsep.sock
             └─91489 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmpohtseool/privsep.sock

Jul 29 17:32:18 np0000031958 cinder-volume[80100]: INFO cinder.volume.manager [[01;36mNone req-69412f76-5066-4b24-85c7-d241f7449a13 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mDeleted volume successfully.[00m
Jul 29 17:32:18 np0000031958 cinder-volume[80100]: DEBUG cinder.coordination [[01;36mNone req-69412f76-5066-4b24-85c7-d241f7449a13 [00;36mtempest-CreateVolumesFromImageTest-996366964 None] [01;35mLock "cinder-c4c6886a-3558-4f47-a374-9a29abd40d65-delete_volume" released by "delete_volume" :: held 1.818s[00m [00;33m{{(pid=80100) __release /opt/stack/cinder/cinder/coordination.py:157}}[00m
Jul 29 17:32:26 np0000031958 cinder-volume[80100]: DEBUG dbcounter [[00;36m-] [01;35m[80100] Writing DB stats cinder:SELECT=78,cinder:INSERT=24,cinder:UPDATE=89,cinder:DELETE=3[00m [00;33m{{(pid=80100) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:28 np0000031958 cinder-volume[80100]: DEBUG dbcounter [[00;36m-] [01;35m[80100] Writing DB stats cinder:SELECT=87,cinder:UPDATE=88,cinder:INSERT=21,cinder:DELETE=10[00m [00;33m{{(pid=80100) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:40 np0000031958 cinder-volume[80100]: DEBUG dbcounter [[00;36m-] [01;35m[80100] Writing DB stats cinder:SELECT=1[00m [00;33m{{(pid=80100) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:40 np0000031958 cinder-volume[80100]: DEBUG dbcounter [[00;36m-] [01;35m[80100] Writing DB stats cinder:UPDATE=1[00m [00;33m{{(pid=80100) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:45 np0000031958 cinder-volume[80100]: DEBUG oslo_service.periodic_task [[01;36mNone req-196f9592-6965-4a2e-b1a6-2b53c3fb1b9a [00;36mNone None] [01;35mRunning periodic task VolumeManager.publish_service_capabilities[00m [00;33m{{(pid=80100) run_periodic_tasks /opt/stack/data/venv/lib/python3.12/site-packages/oslo_service/periodic_task.py:210}}[00m
Jul 29 17:32:45 np0000031958 cinder-volume[80100]: DEBUG cinder.volume.drivers.pure [[01;36mNone req-196f9592-6965-4a2e-b1a6-2b53c3fb1b9a [00;36mNone None] [01;35m[puredriver-1] Enter PureISCSIDriver._update_volume_stats, args=(<cinder.volume.drivers.pure.PureISCSIDriver object at 0x7762ccff7ce0>,), kwargs={}[00m [00;33m{{(pid=80100) wrapper /opt/stack/cinder/cinder/volume/drivers/pure.py:207}}[00m
Jul 29 17:32:46 np0000031958 cinder-volume[80100]: DEBUG cinder.volume.drivers.pure [[01;36mNone req-196f9592-6965-4a2e-b1a6-2b53c3fb1b9a [00;36mNone None] [01;35m[puredriver-1] Leave PureISCSIDriver._update_volume_stats, ret=None[00m [00;33m{{(pid=80100) wrapper /opt/stack/cinder/cinder/volume/drivers/pure.py:216}}[00m
Jul 29 17:32:46 np0000031958 cinder-volume[80100]: DEBUG cinder.manager [[01;36mNone req-196f9592-6965-4a2e-b1a6-2b53c3fb1b9a [00;36mNone None] [01;35mNotifying Schedulers of capabilities ...[00m [00;33m{{(pid=80100) _publish_service_capabilities /opt/stack/cinder/cinder/manager.py:202}}[00m

● devstack@etcd.service - Devstack devstack@etcd.service
     Loaded: loaded (/etc/systemd/system/devstack@etcd.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:52:17 UTC; 40min ago
   Main PID: 45936 (etcd)
      Tasks: 13 (limit: 9444)
     Memory: 21.5M (peak: 132.6M swap: 121.5M swap peak: 121.6M)
        CPU: 7.939s
     CGroup: /system.slice/system-devstack.slice/devstack@etcd.service
             └─45936 /opt/stack/bin/etcd --name np0000031958 --data-dir /opt/stack/data/etcd --initial-cluster-state new --initial-cluster-token etcd-cluster-01 --initial-cluster np0000031958=http://192.168.1.104:2380 --initial-advertise-peer-urls http://192.168.1.104:2380 --advertise-client-urls http://192.168.1.104:2379 --listen-peer-urls http://0.0.0.0:2380 --listen-client-urls http://192.168.1.104:2379 --log-level=debug

Jul 29 17:32:15 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:15.173791486 +0000 UTC m=+2398.103681311, time spent = 152.058µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.Lease/LeaseGrant, request count = -1, request size = -1, response count = -1, response size = -1, request content = 
Jul 29 17:32:15 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:15.175122468 +0000 UTC m=+2398.105012284, time spent = 1.437357ms, remote = 192.168.1.104:40564, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 100, response count = 0, response size = 40, request content = compare:<target:CREATE key:"/tooz/lockscinder-42bc7749-5d1c-427d-804a-91673f52fd09-delete_volume" create_revision:0 > success:<request_put:<key:"/tooz/lockscinder-42bc7749-5d1c-427d-804a-91673f52fd09-delete_volume" value_size:16 lease:826578031477673032 >> failure:<request_range:<key:"/tooz/lockscinder-42bc7749-5d1c-427d-804a-91673f52fd09-delete_volume" > >
Jul 29 17:32:15 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:15.222203855 +0000 UTC m=+2398.152093670, time spent = 170.319µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 72, response count = 0, response size = 42, request content = compare:<target:VALUE key:"/tooz/lockscinder-acfd37cc-2a69-4b0c-83bf-45f35b810a96-delete_volume" value_size:16 > success:<request_delete_range:<key:"/tooz/lockscinder-acfd37cc-2a69-4b0c-83bf-45f35b810a96-delete_volume" > > failure:<>
Jul 29 17:32:15 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:15.779693213 +0000 UTC m=+2398.709583027, time spent = 188.264µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.Lease/LeaseGrant, request count = -1, request size = -1, response count = -1, response size = -1, request content = 
Jul 29 17:32:15 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:15.781245414 +0000 UTC m=+2398.711135212, time spent = 141.969µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 100, response count = 0, response size = 40, request content = compare:<target:CREATE key:"/tooz/lockscinder-bc932e16-ade9-4bb8-938d-d522095dff97-delete_volume" create_revision:0 > success:<request_put:<key:"/tooz/lockscinder-bc932e16-ade9-4bb8-938d-d522095dff97-delete_volume" value_size:16 lease:826578031477673036 >> failure:<request_range:<key:"/tooz/lockscinder-bc932e16-ade9-4bb8-938d-d522095dff97-delete_volume" > >
Jul 29 17:32:16 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:16.491825387 +0000 UTC m=+2399.421715201, time spent = 193.526µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 72, response count = 0, response size = 42, request content = compare:<target:VALUE key:"/tooz/lockscinder-42bc7749-5d1c-427d-804a-91673f52fd09-delete_volume" value_size:16 > success:<request_delete_range:<key:"/tooz/lockscinder-42bc7749-5d1c-427d-804a-91673f52fd09-delete_volume" > > failure:<>
Jul 29 17:32:16 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:16.836982849 +0000 UTC m=+2399.766872663, time spent = 188.075µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.Lease/LeaseGrant, request count = -1, request size = -1, response count = -1, response size = -1, request content = 
Jul 29 17:32:16 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:16.839209784 +0000 UTC m=+2399.769099599, time spent = 136.504µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 100, response count = 0, response size = 40, request content = compare:<target:CREATE key:"/tooz/lockscinder-c4c6886a-3558-4f47-a374-9a29abd40d65-delete_volume" create_revision:0 > success:<request_put:<key:"/tooz/lockscinder-c4c6886a-3558-4f47-a374-9a29abd40d65-delete_volume" value_size:16 lease:826578031477673040 >> failure:<request_range:<key:"/tooz/lockscinder-c4c6886a-3558-4f47-a374-9a29abd40d65-delete_volume" > >
Jul 29 17:32:17 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:17.561733444 +0000 UTC m=+2400.491623243, time spent = 212.553µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 72, response count = 0, response size = 42, request content = compare:<target:VALUE key:"/tooz/lockscinder-bc932e16-ade9-4bb8-938d-d522095dff97-delete_volume" value_size:16 > success:<request_delete_range:<key:"/tooz/lockscinder-bc932e16-ade9-4bb8-938d-d522095dff97-delete_volume" > > failure:<>
Jul 29 17:32:18 np0000031958 etcd[45936]: start time = 2025-07-29 17:32:18.656670527 +0000 UTC m=+2401.586560337, time spent = 182.078µs, remote = 192.168.1.104:40564, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 72, response count = 0, response size = 42, request content = compare:<target:VALUE key:"/tooz/lockscinder-c4c6886a-3558-4f47-a374-9a29abd40d65-delete_volume" value_size:16 > success:<request_delete_range:<key:"/tooz/lockscinder-c4c6886a-3558-4f47-a374-9a29abd40d65-delete_volume" > > failure:<>

● devstack@file_tracker.service - Devstack devstack@file_tracker.service
     Loaded: loaded (/etc/systemd/system/devstack@file_tracker.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:52:16 UTC; 41min ago
   Main PID: 45281 (file_tracker.sh)
      Tasks: 2 (limit: 9444)
     Memory: 556.0K (peak: 1.4M swap: 120.0K swap peak: 120.0K zswap: 24.2K)
        CPU: 271ms
     CGroup: /system.slice/system-devstack.slice/devstack@file_tracker.service
             ├─ 45281 /bin/bash /opt/stack/devstack/tools/file_tracker.sh
             └─134026 sleep 20

Jul 29 17:30:16 np0000031958 file_tracker.sh[131048]: 6240	0	9223372036854775807
Jul 29 17:30:36 np0000031958 file_tracker.sh[131088]: 6272	0	9223372036854775807
Jul 29 17:30:56 np0000031958 file_tracker.sh[131109]: 6272	0	9223372036854775807
Jul 29 17:31:16 np0000031958 file_tracker.sh[131547]: 6400	0	9223372036854775807
Jul 29 17:31:36 np0000031958 file_tracker.sh[131585]: 6368	0	9223372036854775807
Jul 29 17:31:56 np0000031958 file_tracker.sh[131846]: 6208	0	9223372036854775807
Jul 29 17:32:16 np0000031958 file_tracker.sh[132080]: 6016	0	9223372036854775807
Jul 29 17:32:36 np0000031958 file_tracker.sh[132397]: 6016	0	9223372036854775807
Jul 29 17:32:56 np0000031958 file_tracker.sh[132652]: 5920	0	9223372036854775807
Jul 29 17:33:16 np0000031958 file_tracker.sh[134025]: 5888	0	9223372036854775807

● devstack@g-api.service - Devstack devstack@g-api.service
     Loaded: loaded (/etc/systemd/system/devstack@g-api.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:26 UTC; 38min ago
   Main PID: 80178 (uwsgi)
     Status: "uWSGI is ready"
      Tasks: 13 (limit: 9444)
     Memory: 168.0M (peak: 841.0M swap: 111.3M swap peak: 111.5M zswap: 39.4M)
        CPU: 19.940s
     CGroup: /system.slice/system-devstack.slice/devstack@g-api.service
             ├─80178 "glance-apiuWSGI master"
             ├─80179 "glance-apiuWSGI worker 1"
             └─80180 "glance-apiuWSGI worker 2"

Jul 29 17:31:58 np0000031958 devstack@g-api.service[80179]: WARNING glance.api.v2.images [[01;36mNone req-fdf38ae3-5419-4751-b2f6-23cb1b01f786 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mFailed to find image 09411fa5-9f28-459d-8446-580be97f5b69 to delete[00m: glance.common.exception.ImageNotFound: No image found with ID 09411fa5-9f28-459d-8446-580be97f5b69
Jul 29 17:31:58 np0000031958 devstack@g-api.service[80179]: [pid: 80179|app: 0|req: 416/838] 127.0.0.1 () {40 vars in 855 bytes} [Tue Jul 29 17:31:58 2025] DELETE /v2/images/09411fa5-9f28-459d-8446-580be97f5b69 => generated 147 bytes in 9 msecs (HTTP/1.1 404) 4 headers in 164 bytes (1 switches on core 0)
Jul 29 17:31:58 np0000031958 devstack@g-api.service[80180]: DEBUG glance.api.middleware.version_negotiation [[01;36mNone req-83ce825e-d782-459b-b602-01d8505e0d59 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mDetermining version of request: GET /v2/images/09411fa5-9f28-459d-8446-580be97f5b69 Accept: application/json[00m [00;33m{{(pid=80180) process_request /opt/stack/glance/glance/api/middleware/version_negotiation.py:44}}[00m
Jul 29 17:31:58 np0000031958 devstack@g-api.service[80180]: DEBUG glance.api.middleware.version_negotiation [[01;36mNone req-83ce825e-d782-459b-b602-01d8505e0d59 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mUsing url versioning[00m [00;33m{{(pid=80180) process_request /opt/stack/glance/glance/api/middleware/version_negotiation.py:57}}[00m
Jul 29 17:31:58 np0000031958 devstack@g-api.service[80180]: DEBUG glance.api.middleware.version_negotiation [[01;36mNone req-83ce825e-d782-459b-b602-01d8505e0d59 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mMatched version: v2[00m [00;33m{{(pid=80180) process_request /opt/stack/glance/glance/api/middleware/version_negotiation.py:69}}[00m
Jul 29 17:31:58 np0000031958 devstack@g-api.service[80180]: DEBUG glance.api.middleware.version_negotiation [[01;36mNone req-83ce825e-d782-459b-b602-01d8505e0d59 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mnew path /v2/images/09411fa5-9f28-459d-8446-580be97f5b69[00m [00;33m{{(pid=80180) process_request /opt/stack/glance/glance/api/middleware/version_negotiation.py:70}}[00m
Jul 29 17:31:58 np0000031958 devstack@g-api.service[80180]: DEBUG glance.db.sqlalchemy.api [[01;36mNone req-9ccc1b6f-9163-4514-8626-5841d7a0cc3c [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mNo image found with ID 09411fa5-9f28-459d-8446-580be97f5b69[00m [00;33m{{(pid=80180) _image_get /opt/stack/glance/glance/db/sqlalchemy/api.py:308}}[00m
Jul 29 17:31:58 np0000031958 devstack@g-api.service[80180]: [pid: 80180|app: 0|req: 423/839] 127.0.0.1 () {40 vars in 852 bytes} [Tue Jul 29 17:31:58 2025] GET /v2/images/09411fa5-9f28-459d-8446-580be97f5b69 => generated 139 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 164 bytes (1 switches on core 0)
Jul 29 17:32:08 np0000031958 devstack@g-api.service[80179]: DEBUG dbcounter [[00;36m-] [01;35m[80179] Writing DB stats glance:SELECT=27,glance:UPDATE=22[00m [00;33m{{(pid=80179) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:08 np0000031958 devstack@g-api.service[80180]: DEBUG dbcounter [[00;36m-] [01;35m[80180] Writing DB stats glance:SELECT=2[00m [00;33m{{(pid=80180) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@keystone.service - Devstack devstack@keystone.service
     Loaded: loaded (/etc/systemd/system/devstack@keystone.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:52:26 UTC; 40min ago
   Main PID: 47211 (uwsgi)
     Status: "uWSGI is ready"
      Tasks: 5 (limit: 9444)
     Memory: 267.5M (peak: 268.1M swap: 129.4M swap peak: 129.4M zswap: 39.3M)
        CPU: 1min 21.335s
     CGroup: /system.slice/system-devstack.slice/devstack@keystone.service
             ├─47211 "keystoneuWSGI master"
             ├─47212 "keystoneuWSGI worker 1"
             └─47213 "keystoneuWSGI worker 2"

Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: DEBUG keystone.common.rbac_enforcer.enforcer [[01;36mNone req-dd03139d-de9a-4fff-a248-167160e934cb [00;36madmin admin] [01;35mRBAC: Authorization granted[00m [00;33m{{(pid=47212) enforce_call /opt/stack/keystone/keystone/common/rbac_enforcer/enforcer.py:505}}[00m
Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: DEBUG keystone.notifications [[01;36mNone req-dd03139d-de9a-4fff-a248-167160e934cb [00;36madmin admin] [01;35mInvoking callback _project_callback for event identity project deleted for {'resource_info': 'a0fb74487dad46adbafbc09ce046cf1c', 'request_id': 'req-dd03139d-de9a-4fff-a248-167160e934cb'}[00m [00;33m{{(pid=47212) notify_event_callbacks /opt/stack/keystone/keystone/notifications.py:478}}[00m
Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: DEBUG keystone.notifications [[01;36mNone req-dd03139d-de9a-4fff-a248-167160e934cb [00;36madmin admin] [01;35mInvoking callback _unset_default_project for event identity project deleted for {'resource_info': 'a0fb74487dad46adbafbc09ce046cf1c', 'request_id': 'req-dd03139d-de9a-4fff-a248-167160e934cb'}[00m [00;33m{{(pid=47212) notify_event_callbacks /opt/stack/keystone/keystone/notifications.py:478}}[00m
Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: DEBUG keystone.notifications [[01;36mNone req-dd03139d-de9a-4fff-a248-167160e934cb [00;36madmin admin] [01;35mInvoking callback _on_project_or_endpoint_delete for event identity project deleted for {'resource_info': 'a0fb74487dad46adbafbc09ce046cf1c', 'request_id': 'req-dd03139d-de9a-4fff-a248-167160e934cb'}[00m [00;33m{{(pid=47212) notify_event_callbacks /opt/stack/keystone/keystone/notifications.py:478}}[00m
Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: DEBUG keystone.notifications [[01;36mNone req-dd03139d-de9a-4fff-a248-167160e934cb [00;36madmin admin] [01;35mThe token cache is being invalidate because project a0fb74487dad46adbafbc09ce046cf1c was deleted. Authorization will be recalculated and enforced accordingly the next time users authenticate or validate a token.[00m [00;33m{{(pid=47212) invalidate_token_cache_notification /opt/stack/keystone/keystone/notifications.py:341}}[00m
Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: DEBUG keystone.notifications [[01;36mNone req-dd03139d-de9a-4fff-a248-167160e934cb [00;36madmin admin] [01;35mInvoking callback _drop_receipt_cache for event identity invalidate_token_cache internal for {'resource_info': None}[00m [00;33m{{(pid=47212) notify_event_callbacks /opt/stack/keystone/keystone/notifications.py:478}}[00m
Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: DEBUG keystone.notifications [[01;36mNone req-dd03139d-de9a-4fff-a248-167160e934cb [00;36madmin admin] [01;35mInvoking callback _drop_token_cache for event identity invalidate_token_cache internal for {'resource_info': None}[00m [00;33m{{(pid=47212) notify_event_callbacks /opt/stack/keystone/keystone/notifications.py:478}}[00m
Jul 29 17:32:18 np0000031958 devstack@keystone.service[47212]: [pid: 47212|app: 0|req: 1418/2833] 192.168.1.104 () {66 vars in 1361 bytes} [Tue Jul 29 17:32:18 2025] DELETE /identity/v3/projects/a0fb74487dad46adbafbc09ce046cf1c => generated 0 bytes in 37 msecs (HTTP/1.1 204) 3 headers in 132 bytes (0 switches on core 0)
Jul 29 17:32:28 np0000031958 devstack@keystone.service[47213]: DEBUG dbcounter [[00;36m-] [01;35m[47213] Writing DB stats keystone:SELECT=137,keystone:DELETE=27,keystone:INSERT=4,keystone:UPDATE=1[00m [00;33m{{(pid=47213) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:28 np0000031958 devstack@keystone.service[47212]: DEBUG dbcounter [[00;36m-] [01;35m[47212] Writing DB stats keystone:SELECT=155,keystone:DELETE=24,keystone:INSERT=7[00m [00;33m{{(pid=47212) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@memory_tracker.service - Devstack devstack@memory_tracker.service
     Loaded: loaded (/etc/systemd/system/devstack@memory_tracker.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:52:15 UTC; 41min ago
   Main PID: 44799 (memory_tracker.)
      Tasks: 2 (limit: 9444)
     Memory: 5.3M (peak: 13.4M swap: 100.0K swap peak: 100.0K zswap: 22.5K)
        CPU: 4.645s
     CGroup: /system.slice/system-devstack.slice/devstack@memory_tracker.service
             ├─ 44799 /bin/bash /opt/stack/devstack/tools/memory_tracker.sh
             └─132658 sleep 20

Jul 29 17:29:59 np0000031958 memory_tracker.sh[130617]:   "^VmLck:\s+(?P<locked>[\d]+)\s+kB", re.MULTILINE)
Jul 29 17:29:59 np0000031958 memory_tracker.sh[130617]: [iscsid (pid:36014)]=15536KB; [multipathd (pid:363)]=420872KB; [ovs-vswitchd (pid:67077)]=905324KB
Jul 29 17:30:00 np0000031958 memory_tracker.sh[44799]: ]]]
Jul 29 17:32:20 np0000031958 memory_tracker.sh[44799]: [[[
Jul 29 17:32:20 np0000031958 memory_tracker.sh[132087]: Tue Jul 29 17:32:20 UTC 2025
Jul 29 17:32:20 np0000031958 memory_tracker.sh[44799]: ---
Jul 29 17:32:20 np0000031958 memory_tracker.sh[132089]: /opt/stack/devstack/tools/mlock_report.py:9: SyntaxWarning: invalid escape sequence '\s'
Jul 29 17:32:20 np0000031958 memory_tracker.sh[132089]:   "^VmLck:\s+(?P<locked>[\d]+)\s+kB", re.MULTILINE)
Jul 29 17:32:20 np0000031958 memory_tracker.sh[132089]: [iscsid (pid:36014)]=14236KB; [multipathd (pid:363)]=420872KB; [ovs-vswitchd (pid:67077)]=905324KB
Jul 29 17:32:20 np0000031958 memory_tracker.sh[44799]: ]]]

● devstack@n-api-meta.service - Devstack devstack@n-api-meta.service
     Loaded: loaded (/etc/systemd/system/devstack@n-api-meta.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:14 UTC; 39min ago
   Main PID: 74275 (uwsgi)
     Status: "uWSGI is ready"
      Tasks: 4 (limit: 9444)
     Memory: 127.5M (peak: 221.6M swap: 151.7M swap peak: 151.7M zswap: 51.5M)
        CPU: 7.281s
     CGroup: /system.slice/system-devstack.slice/devstack@n-api-meta.service
             ├─74275 "nova-api-metauWSGI master"
             ├─74276 "nova-api-metauWSGI worker 1"
             ├─74277 "nova-api-metauWSGI worker 2"
             └─74278 "nova-api-metauWSGI http 1"

Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74276]: [pid: 74276|app: 0|req: 434/866] 192.168.1.104 () {40 vars in 709 bytes} [Tue Jul 29 17:31:28 2025] GET /2009-04-04/meta-data/block-device-mapping/ebs0 => generated 8 bytes in 1 msecs (HTTP/1.1 200) 3 headers in 98 bytes (1 switches on core 0)
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74277]: DEBUG nova.api.metadata.handler [[01;36mNone req-c7eceafb-2b72-495f-9325-713b2bb429e7 [00;36mNone None] [01;35mMetadata request headers: {'Host': '192.168.1.104:8775', 'User-Agent': 'python-requests/2.32.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'X-Forwarded-For': '10.1.0.3', 'X-Instance-Id': '00405f44-2c6f-44e4-854c-6b4e54ad627e', 'X-Tenant-Id': 'f97ac8eac3594ae29831275989e0577b', 'X-Instance-Id-Signature': '69d09b9314a01a9a9391cdfb95ea15ab9b0dd942df8501dd27ed10b9aa3c4dd7'}[00m [00;33m{{(pid=74277) __call__ /opt/stack/nova/nova/api/metadata/handler.py:109}}[00m
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74277]: DEBUG nova.api.metadata.handler [[01;36mNone req-c7eceafb-2b72-495f-9325-713b2bb429e7 [00;36mNone None] [01;35mUsing cached metadata for instance 00405f44-2c6f-44e4-854c-6b4e54ad627e[00m [00;33m{{(pid=74277) get_metadata_by_instance_id /opt/stack/nova/nova/api/metadata/handler.py:84}}[00m
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74277]: [pid: 74277|app: 0|req: 433/867] 192.168.1.104 () {40 vars in 709 bytes} [Tue Jul 29 17:31:28 2025] GET /2009-04-04/meta-data/block-device-mapping/root => generated 8 bytes in 1 msecs (HTTP/1.1 200) 3 headers in 98 bytes (1 switches on core 0)
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74276]: DEBUG nova.api.metadata.handler [[01;36mNone req-75dfd8a6-5a7b-4232-8f5b-7f38c01e7be1 [00;36mNone None] [01;35mMetadata request headers: {'Host': '192.168.1.104:8775', 'User-Agent': 'python-requests/2.32.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'X-Forwarded-For': '10.1.0.3', 'X-Instance-Id': '00405f44-2c6f-44e4-854c-6b4e54ad627e', 'X-Tenant-Id': 'f97ac8eac3594ae29831275989e0577b', 'X-Instance-Id-Signature': '69d09b9314a01a9a9391cdfb95ea15ab9b0dd942df8501dd27ed10b9aa3c4dd7'}[00m [00;33m{{(pid=74276) __call__ /opt/stack/nova/nova/api/metadata/handler.py:109}}[00m
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74276]: DEBUG nova.api.metadata.handler [[01;36mNone req-75dfd8a6-5a7b-4232-8f5b-7f38c01e7be1 [00;36mNone None] [01;35mUsing cached metadata for instance 00405f44-2c6f-44e4-854c-6b4e54ad627e[00m [00;33m{{(pid=74276) get_metadata_by_instance_id /opt/stack/nova/nova/api/metadata/handler.py:84}}[00m
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74276]: [pid: 74276|app: 0|req: 435/868] 192.168.1.104 () {40 vars in 689 bytes} [Tue Jul 29 17:31:28 2025] GET /2009-04-04/meta-data/public-hostname => generated 50 bytes in 1 msecs (HTTP/1.1 200) 3 headers in 99 bytes (1 switches on core 0)
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74277]: DEBUG nova.api.metadata.handler [[01;36mNone req-c7eceafb-2b72-495f-9325-713b2bb429e7 [00;36mNone None] [01;35mMetadata request headers: {'Host': '192.168.1.104:8775', 'User-Agent': 'python-requests/2.32.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'X-Forwarded-For': '10.1.0.3', 'X-Instance-Id': '00405f44-2c6f-44e4-854c-6b4e54ad627e', 'X-Tenant-Id': 'f97ac8eac3594ae29831275989e0577b', 'X-Instance-Id-Signature': '69d09b9314a01a9a9391cdfb95ea15ab9b0dd942df8501dd27ed10b9aa3c4dd7'}[00m [00;33m{{(pid=74277) __call__ /opt/stack/nova/nova/api/metadata/handler.py:109}}[00m
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74277]: DEBUG nova.api.metadata.handler [[01;36mNone req-c7eceafb-2b72-495f-9325-713b2bb429e7 [00;36mNone None] [01;35mUsing cached metadata for instance 00405f44-2c6f-44e4-854c-6b4e54ad627e[00m [00;33m{{(pid=74277) get_metadata_by_instance_id /opt/stack/nova/nova/api/metadata/handler.py:84}}[00m
Jul 29 17:31:28 np0000031958 devstack@n-api-meta.service[74277]: [pid: 74277|app: 0|req: 434/869] 192.168.1.104 () {40 vars in 713 bytes} [Tue Jul 29 17:31:28 2025] GET /2009-04-04/meta-data/placement/availability-zone => generated 4 bytes in 1 msecs (HTTP/1.1 200) 3 headers in 98 bytes (1 switches on core 0)

● devstack@n-api.service - Devstack devstack@n-api.service
     Loaded: loaded (/etc/systemd/system/devstack@n-api.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:44 UTC; 39min ago
   Main PID: 66388 (uwsgi)
     Status: "uWSGI is ready"
      Tasks: 43 (limit: 9444)
     Memory: 316.3M (peak: 318.0M swap: 96.3M swap peak: 96.5M zswap: 29.2M)
        CPU: 1min 27.598s
     CGroup: /system.slice/system-devstack.slice/devstack@n-api.service
             ├─66388 "nova-apiuWSGI master"
             ├─66389 "nova-apiuWSGI worker 1"
             └─66390 "nova-apiuWSGI worker 2"

Jul 29 17:32:06 np0000031958 devstack@n-api.service[66389]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-dd072d10-ebba-4a47-bec4-37a5a3234697 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mAcquiring lock "22e7a237-3daa-41b2-9f56-f2a74b627e16" by "nova.context.set_target_cell.<locals>.get_or_set_cached_cell_and_set_connections"[00m [00;33m{{(pid=66389) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:405}}[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66389]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-dd072d10-ebba-4a47-bec4-37a5a3234697 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mLock "22e7a237-3daa-41b2-9f56-f2a74b627e16" acquired by "nova.context.set_target_cell.<locals>.get_or_set_cached_cell_and_set_connections" :: waited 0.000s[00m [00;33m{{(pid=66389) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:410}}[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66389]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-dd072d10-ebba-4a47-bec4-37a5a3234697 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mLock "22e7a237-3daa-41b2-9f56-f2a74b627e16" "released" by "nova.context.set_target_cell.<locals>.get_or_set_cached_cell_and_set_connections" :: held 0.000s[00m [00;33m{{(pid=66389) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:424}}[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66389]: INFO nova.api.openstack.wsgi [[01;36mNone req-dd072d10-ebba-4a47-bec4-37a5a3234697 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mHTTP exception thrown: Instance 0a917914-5ea3-46e9-9914-2a812c302bb5 could not be found.[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66389]: DEBUG nova.api.openstack.wsgi [[01;36mNone req-dd072d10-ebba-4a47-bec4-37a5a3234697 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mReturning 404 to user: Instance 0a917914-5ea3-46e9-9914-2a812c302bb5 could not be found.[00m [00;33m{{(pid=66389) __call__ /opt/stack/nova/nova/api/openstack/wsgi.py:909}}[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66389]: INFO nova.api.openstack.requestlog [[01;36mNone req-dd072d10-ebba-4a47-bec4-37a5a3234697 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35m192.168.1.104 "GET /compute/v2.1/servers/0a917914-5ea3-46e9-9914-2a812c302bb5" status: 404 len: 111 microversion: 2.1 time: 0.011832[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66389]: [pid: 66389|app: 0|req: 1572/3155] 192.168.1.104 () {66 vars in 1367 bytes} [Tue Jul 29 17:32:06 2025] GET /compute/v2.1/servers/0a917914-5ea3-46e9-9914-2a812c302bb5 => generated 111 bytes in 12 msecs (HTTP/1.1 404) 9 headers in 379 bytes (1 switches on core 0)
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66390]: DEBUG nova.api.openstack.wsgi [[01;36mNone req-4178b21d-3360-4e76-8806-de8cb645f568 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mCalling method '<bound method KeypairController.delete of <nova.api.openstack.compute.keypairs.KeypairController object at 0x789ed21ebf50>>'[00m [00;33m{{(pid=66390) _process_stack /opt/stack/nova/nova/api/openstack/wsgi.py:552}}[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66390]: INFO nova.api.openstack.requestlog [[01;36mNone req-4178b21d-3360-4e76-8806-de8cb645f568 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35m192.168.1.104 "DELETE /compute/v2.1/os-keypairs/tempest-keypair-1802667070" status: 202 len: 0 microversion: 2.1 time: 0.011963[00m
Jul 29 17:32:06 np0000031958 devstack@n-api.service[66390]: [pid: 66390|app: 0|req: 1584/3156] 192.168.1.104 () {66 vars in 1352 bytes} [Tue Jul 29 17:32:06 2025] DELETE /compute/v2.1/os-keypairs/tempest-keypair-1802667070 => generated 0 bytes in 12 msecs (HTTP/1.1 202) 9 headers in 361 bytes (1 switches on core 0)

● devstack@n-cond-cell1.service - Devstack devstack@n-cond-cell1.service
     Loaded: loaded (/etc/systemd/system/devstack@n-cond-cell1.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:16 UTC; 39min ago
   Main PID: 76172 (nova-conductor)
      Tasks: 3 (limit: 9444)
     Memory: 128.8M (peak: 179.3M swap: 105.4M swap peak: 105.4M zswap: 34.5M)
        CPU: 50.651s
     CGroup: /system.slice/system-devstack.slice/devstack@n-cond-cell1.service
             ├─76172 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             ├─77282 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             └─77283 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf

Jul 29 17:30:23 np0000031958 nova-conductor[77283]: DEBUG dbcounter [[00;36m-] [01;35m[77283] Writing DB stats nova_cell1:SELECT=33,nova_cell1:UPDATE=14,nova_cell1:DELETE=1,nova_cell1:SAVEPOINT=2,nova_cell1:RELEASE=2,nova_cell1:INSERT=7[00m [00;33m{{(pid=77283) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:30:43 np0000031958 nova-conductor[77283]: DEBUG dbcounter [[00;36m-] [01;35m[77283] Writing DB stats nova_cell1:SELECT=2[00m [00;33m{{(pid=77283) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:30:47 np0000031958 nova-conductor[77282]: DEBUG dbcounter [[00;36m-] [01;35m[77282] Writing DB stats nova_cell1:SELECT=41,nova_cell1:UPDATE=19,nova_cell1:INSERT=4,nova_cell1:SAVEPOINT=1,nova_cell1:RELEASE=1,nova_cell1:DELETE=1[00m [00;33m{{(pid=77282) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:31:23 np0000031958 nova-conductor[77283]: DEBUG dbcounter [[00;36m-] [01;35m[77283] Writing DB stats nova_cell1:SELECT=34,nova_cell1:UPDATE=12,nova_cell1:INSERT=2,nova_cell1:SAVEPOINT=1,nova_cell1:RELEASE=1,nova_cell1:DELETE=1[00m [00;33m{{(pid=77283) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:31:47 np0000031958 nova-conductor[77282]: DEBUG dbcounter [[00;36m-] [01;35m[77282] Writing DB stats nova_cell1:SELECT=48,nova_cell1:UPDATE=26,nova_cell1:INSERT=10,nova_cell1:SAVEPOINT=3,nova_cell1:RELEASE=3[00m [00;33m{{(pid=77282) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:22 np0000031958 nova-conductor[77282]: DEBUG dbcounter [[00;36m-] [01;35m[77282] Writing DB stats nova_cell1:SELECT=30,nova_cell1:UPDATE=38,nova_cell1:DELETE=5,nova_cell1:INSERT=2,nova_cell1:SAVEPOINT=2,nova_cell1:RELEASE=2[00m [00;33m{{(pid=77282) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:24 np0000031958 nova-conductor[77283]: DEBUG dbcounter [[00;36m-] [01;35m[77283] Writing DB stats nova_cell1:SELECT=37,nova_cell1:UPDATE=23,nova_cell1:INSERT=3,nova_cell1:SAVEPOINT=3,nova_cell1:RELEASE=3,nova_cell1:DELETE=4[00m [00;33m{{(pid=77283) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:42 np0000031958 nova-conductor[77282]: DEBUG dbcounter [[00;36m-] [01;35m[77282] Writing DB stats nova_cell1:SELECT=2,nova_cell1:UPDATE=2[00m [00;33m{{(pid=77282) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:04 np0000031958 nova-conductor[77283]: DEBUG dbcounter [[00;36m-] [01;35m[77283] Writing DB stats nova_cell1:SELECT=7,nova_cell1:UPDATE=1[00m [00;33m{{(pid=77283) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:14 np0000031958 nova-conductor[77283]: DEBUG dbcounter [[00;36m-] [01;35m[77283] Writing DB stats nova_cell1:SELECT=1[00m [00;33m{{(pid=77283) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@n-cpu.service - Devstack devstack@n-cpu.service
     Loaded: loaded (/etc/systemd/system/devstack@n-cpu.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:18 UTC; 38min ago
   Main PID: 77223 (nova-compute)
      Tasks: 36 (limit: 9444)
     Memory: 1.0G (peak: 2.1G swap: 109.8M swap peak: 110.5M zswap: 26.8M)
        CPU: 1min 37.294s
     CGroup: /system.slice/system-devstack.slice/devstack@n-cpu.service
             ├─77223 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-compute --config-file /etc/nova/nova-cpu.conf
             ├─87718 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context nova.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmps6_q_fui/privsep.sock
             ├─87756 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context vif_plug_ovs.privsep.vif_plug --privsep_sock_path /tmp/tmprul1wut5/privsep.sock
             └─88388 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmp9ppv4ep2/privsep.sock

Jul 29 17:33:05 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35mtcp:127.0.0.1:6640: entering IDLE[00m [00;33m{{(pid=77223) _transition /opt/stack/data/venv/lib/python3.12/site-packages/ovs/reconnect.py:519}}[00m
Jul 29 17:33:05 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35mtcp:127.0.0.1:6640: entering ACTIVE[00m [00;33m{{(pid=77223) _transition /opt/stack/data/venv/lib/python3.12/site-packages/ovs/reconnect.py:519}}[00m
Jul 29 17:33:05 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35m[POLLIN] on fd 23[00m [00;33m{{(pid=77223) __log_wakeup /opt/stack/data/venv/lib/python3.12/site-packages/ovs/poller.py:263}}[00m
Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35m4999-ms timeout[00m [00;33m{{(pid=77223) __log_wakeup /opt/stack/data/venv/lib/python3.12/site-packages/ovs/poller.py:248}}[00m
Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35m[POLLIN] on fd 23[00m [00;33m{{(pid=77223) __log_wakeup /opt/stack/data/venv/lib/python3.12/site-packages/ovs/poller.py:263}}[00m
Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35mtcp:127.0.0.1:6640: idle 5001 ms, sending inactivity probe[00m [00;33m{{(pid=77223) run /opt/stack/data/venv/lib/python3.12/site-packages/ovs/reconnect.py:117}}[00m
Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35mtcp:127.0.0.1:6640: entering IDLE[00m [00;33m{{(pid=77223) _transition /opt/stack/data/venv/lib/python3.12/site-packages/ovs/reconnect.py:519}}[00m
Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35mtcp:127.0.0.1:6640: entering ACTIVE[00m [00;33m{{(pid=77223) _transition /opt/stack/data/venv/lib/python3.12/site-packages/ovs/reconnect.py:519}}[00m
Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35m[POLLIN] on fd 23[00m [00;33m{{(pid=77223) __log_wakeup /opt/stack/data/venv/lib/python3.12/site-packages/ovs/poller.py:263}}[00m
Jul 29 17:33:15 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35m[POLLIN] on fd 23[00m [00;33m{{(pid=77223) __log_wakeup /opt/stack/data/venv/lib/python3.12/site-packages/ovs/poller.py:263}}[00m

● devstack@n-novnc-cell1.service - Devstack devstack@n-novnc-cell1.service
     Loaded: loaded (/etc/systemd/system/devstack@n-novnc-cell1.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:15 UTC; 39min ago
   Main PID: 74890 (nova-novncproxy)
      Tasks: 8 (limit: 9444)
     Memory: 30.7M (peak: 105.2M swap: 89.3M swap peak: 89.3M zswap: 13.4M)
        CPU: 2.020s
     CGroup: /system.slice/system-devstack.slice/devstack@n-novnc-cell1.service
             └─74890 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-novncproxy --config-file /etc/nova/nova_cell1.conf --web /usr/share/novnc

Jul 29 16:54:15 np0000031958 systemd[1]: Started devstack@n-novnc-cell1.service - Devstack devstack@n-novnc-cell1.service.
Jul 29 16:54:16 np0000031958 nova-novncproxy[74890]: INFO nova.console.websocketproxy [[00;36m-] [01;35mWebSocket server settings:[00m
Jul 29 16:54:16 np0000031958 nova-novncproxy[74890]: INFO nova.console.websocketproxy [[00;36m-] [01;35m  - Listen on 0.0.0.0:6080[00m
Jul 29 16:54:16 np0000031958 nova-novncproxy[74890]: INFO nova.console.websocketproxy [[00;36m-] [01;35m  - Web server (no directory listings). Web root: /usr/share/novnc[00m
Jul 29 16:54:16 np0000031958 nova-novncproxy[74890]: INFO nova.console.websocketproxy [[00;36m-] [01;35m  - No SSL/TLS support (no cert file)[00m
Jul 29 16:54:16 np0000031958 nova-novncproxy[74890]: INFO nova.console.websocketproxy [[00;36m-] [01;35m  - proxying from 0.0.0.0:6080 to None:None[00m

● devstack@n-sch.service - Devstack devstack@n-sch.service
     Loaded: loaded (/etc/systemd/system/devstack@n-sch.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:13 UTC; 39min ago
   Main PID: 73694 (nova-scheduler)
      Tasks: 3 (limit: 9444)
     Memory: 104.5M (peak: 172.0M swap: 108.4M swap peak: 108.5M zswap: 26.7M)
        CPU: 14.211s
     CGroup: /system.slice/system-devstack.slice/devstack@n-sch.service
             ├─73694 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             ├─74771 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             └─74773 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf

Jul 29 17:30:49 np0000031958 nova-scheduler[74773]: DEBUG nova.scheduler.manager [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mFiltered [(np0000031958, np0000031958) ram: 7042MB disk: 59392MB io_ops: 1 instances: 2, allocation_candidates: 1][00m [00;33m{{(pid=74773) _get_sorted_hosts /opt/stack/nova/nova/scheduler/manager.py:720}}[00m
Jul 29 17:30:49 np0000031958 nova-scheduler[74773]: DEBUG nova.scheduler.manager [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mWeighed [WeighedHost [host: (np0000031958, np0000031958) ram: 7042MB disk: 59392MB io_ops: 1 instances: 2, allocation_candidates: 1, weight: 0.0]][00m [00;33m{{(pid=74773) _get_sorted_hosts /opt/stack/nova/nova/scheduler/manager.py:742}}[00m
Jul 29 17:30:49 np0000031958 nova-scheduler[74773]: DEBUG nova.scheduler.utils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mAttempting to claim resources in the placement API for instance 00405f44-2c6f-44e4-854c-6b4e54ad627e[00m [00;33m{{(pid=74773) claim_resources /opt/stack/nova/nova/scheduler/utils.py:1296}}[00m
Jul 29 17:30:49 np0000031958 nova-scheduler[74773]: DEBUG nova.scheduler.manager [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35m[instance: 00405f44-2c6f-44e4-854c-6b4e54ad627e] Selected host: (np0000031958, np0000031958) ram: 7042MB disk: 59392MB io_ops: 1 instances: 2, allocation_candidates: 1[00m [00;33m{{(pid=74773) _consume_selected_host /opt/stack/nova/nova/scheduler/manager.py:602}}[00m
Jul 29 17:30:49 np0000031958 nova-scheduler[74773]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mAcquiring lock "('np0000031958', 'np0000031958')" by "nova.scheduler.host_manager.HostState.consume_from_request.<locals>._locked"[00m [00;33m{{(pid=74773) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:405}}[00m
Jul 29 17:30:49 np0000031958 nova-scheduler[74773]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mLock "('np0000031958', 'np0000031958')" acquired by "nova.scheduler.host_manager.HostState.consume_from_request.<locals>._locked" :: waited 0.000s[00m [00;33m{{(pid=74773) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:410}}[00m
Jul 29 17:30:49 np0000031958 nova-scheduler[74773]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mLock "('np0000031958', 'np0000031958')" "released" by "nova.scheduler.host_manager.HostState.consume_from_request.<locals>._locked" :: held 0.000s[00m [00;33m{{(pid=74773) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:424}}[00m
Jul 29 17:30:59 np0000031958 nova-scheduler[74773]: DEBUG dbcounter [[00;36m-] [01;35m[74773] Writing DB stats nova_cell1:SELECT=3[00m [00;33m{{(pid=74773) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:29 np0000031958 nova-scheduler[74771]: DEBUG dbcounter [[00;36m-] [01;35m[74771] Writing DB stats nova_cell0:SELECT=1,nova_cell0:UPDATE=1[00m [00;33m{{(pid=74771) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:29 np0000031958 nova-scheduler[74773]: DEBUG dbcounter [[00;36m-] [01;35m[74773] Writing DB stats nova_cell0:SELECT=1[00m [00;33m{{(pid=74773) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@n-super-cond.service - Devstack devstack@n-super-cond.service
     Loaded: loaded (/etc/systemd/system/devstack@n-super-cond.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:16 UTC; 39min ago
   Main PID: 75663 (nova-conductor)
      Tasks: 3 (limit: 9444)
     Memory: 126.7M (peak: 177.6M swap: 110.8M swap peak: 110.8M zswap: 32.1M)
        CPU: 17.392s
     CGroup: /system.slice/system-devstack.slice/devstack@n-super-cond.service
             ├─75663 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             ├─77004 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             └─77006 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf

Jul 29 17:30:50 np0000031958 nova-conductor[77004]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mLock "22e7a237-3daa-41b2-9f56-f2a74b627e16" "released" by "nova.context.set_target_cell.<locals>.get_or_set_cached_cell_and_set_connections" :: held 0.000s[00m [00;33m{{(pid=77004) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:424}}[00m
Jul 29 17:30:50 np0000031958 nova-conductor[77004]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mAcquiring lock "22e7a237-3daa-41b2-9f56-f2a74b627e16" by "nova.context.set_target_cell.<locals>.get_or_set_cached_cell_and_set_connections"[00m [00;33m{{(pid=77004) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:405}}[00m
Jul 29 17:30:50 np0000031958 nova-conductor[77004]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mLock "22e7a237-3daa-41b2-9f56-f2a74b627e16" acquired by "nova.context.set_target_cell.<locals>.get_or_set_cached_cell_and_set_connections" :: waited 0.000s[00m [00;33m{{(pid=77004) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:410}}[00m
Jul 29 17:30:50 np0000031958 nova-conductor[77004]: DEBUG oslo_concurrency.lockutils [[01;36mNone req-c1143b03-0784-4120-8572-7ae4bfc22695 [00;36mtempest-TestVolumeBootPatternV346-781348182 tempest-TestVolumeBootPatternV346-781348182-project-member] [01;35mLock "22e7a237-3daa-41b2-9f56-f2a74b627e16" "released" by "nova.context.set_target_cell.<locals>.get_or_set_cached_cell_and_set_connections" :: held 0.000s[00m [00;33m{{(pid=77004) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:424}}[00m
Jul 29 17:31:00 np0000031958 nova-conductor[77004]: DEBUG dbcounter [[00;36m-] [01;35m[77004] Writing DB stats nova_cell0:SELECT=1[00m [00;33m{{(pid=77004) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:31:00 np0000031958 nova-conductor[77004]: DEBUG dbcounter [[00;36m-] [01;35m[77004] Writing DB stats nova_cell0:SELECT=3[00m [00;33m{{(pid=77004) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:31:00 np0000031958 nova-conductor[77004]: DEBUG dbcounter [[00;36m-] [01;35m[77004] Writing DB stats nova_cell1:SELECT=3,nova_cell1:INSERT=15[00m [00;33m{{(pid=77004) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:31:00 np0000031958 nova-conductor[77004]: DEBUG dbcounter [[00;36m-] [01;35m[77004] Writing DB stats nova_api:SELECT=12,nova_api:UPDATE=1,nova_api:DELETE=1[00m [00;33m{{(pid=77004) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:32 np0000031958 nova-conductor[77006]: DEBUG dbcounter [[00;36m-] [01;35m[77006] Writing DB stats nova_cell0:SELECT=1,nova_cell0:UPDATE=1[00m [00;33m{{(pid=77006) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:32 np0000031958 nova-conductor[77004]: DEBUG dbcounter [[00;36m-] [01;35m[77004] Writing DB stats nova_cell0:SELECT=1[00m [00;33m{{(pid=77004) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@neutron-api.service - Devstack devstack@neutron-api.service
     Loaded: loaded (/etc/systemd/system/devstack@neutron-api.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:55 UTC; 39min ago
   Main PID: 69264 (uwsgi)
     Status: "uWSGI is ready"
      Tasks: 103 (limit: 9444)
     Memory: 467.7M (peak: 483.3M swap: 20.5M swap peak: 20.6M zswap: 5.5M)
        CPU: 8min 11.319s
     CGroup: /system.slice/system-devstack.slice/devstack@neutron-api.service
             ├─69264 "neutron-apiuWSGI master"
             ├─69265 "neutron-apiuWSGI worker 1"
             └─69266 "neutron-apiuWSGI worker 2"

Jul 29 17:33:00 np0000031958 devstack@neutron-api.service[69265]: DEBUG futurist.periodics [[00;36m-] [01;35mSubmitting periodic callback 'neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance.HashRingHealthCheckPeriodics.touch_hash_ring_node'[00m [00;33m{{(pid=69265) _process_scheduled /opt/stack/data/venv/lib/python3.12/site-packages/futurist/periodics.py:638}}[00m
Jul 29 17:33:00 np0000031958 devstack@neutron-api.service[69265]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[00;36m-] [01;35mTouching Hash Ring node "74a6ae93e9d5577a97b6a02e06fd970f" from periodic health check thread[00m [00;33m{{(pid=69265) touch_hash_ring_node /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:1216}}[00m
Jul 29 17:33:00 np0000031958 devstack@neutron-api.service[69266]: DEBUG futurist.periodics [[00;36m-] [01;35mSubmitting periodic callback 'neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance.HashRingHealthCheckPeriodics.touch_hash_ring_node'[00m [00;33m{{(pid=69266) _process_scheduled /opt/stack/data/venv/lib/python3.12/site-packages/futurist/periodics.py:638}}[00m
Jul 29 17:33:00 np0000031958 devstack@neutron-api.service[69266]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[00;36m-] [01;35mTouching Hash Ring node "5886061116525e5ca5ebe31d9d6781d4" from periodic health check thread[00m [00;33m{{(pid=69266) touch_hash_ring_node /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:1216}}[00m
Jul 29 17:33:10 np0000031958 devstack@neutron-api.service[69265]: DEBUG dbcounter [[00;36m-] [01;35m[69265] Writing DB stats neutron:UPDATE=1,neutron:SELECT=1[00m [00;33m{{(pid=69265) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:10 np0000031958 devstack@neutron-api.service[69266]: DEBUG dbcounter [[00;36m-] [01;35m[69266] Writing DB stats neutron:UPDATE=1,neutron:SELECT=1[00m [00;33m{{(pid=69266) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69265]: DEBUG futurist.periodics [[00;36m-] [01;35mSubmitting periodic callback 'neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance.HashRingHealthCheckPeriodics.touch_hash_ring_node'[00m [00;33m{{(pid=69265) _process_scheduled /opt/stack/data/venv/lib/python3.12/site-packages/futurist/periodics.py:638}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69265]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[00;36m-] [01;35mTouching Hash Ring node "74a6ae93e9d5577a97b6a02e06fd970f" from periodic health check thread[00m [00;33m{{(pid=69265) touch_hash_ring_node /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:1216}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69266]: DEBUG futurist.periodics [[00;36m-] [01;35mSubmitting periodic callback 'neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance.HashRingHealthCheckPeriodics.touch_hash_ring_node'[00m [00;33m{{(pid=69266) _process_scheduled /opt/stack/data/venv/lib/python3.12/site-packages/futurist/periodics.py:638}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69266]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[00;36m-] [01;35mTouching Hash Ring node "5886061116525e5ca5ebe31d9d6781d4" from periodic health check thread[00m [00;33m{{(pid=69266) touch_hash_ring_node /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:1216}}[00m

● devstack@neutron-ovn-maintenance-worker.service - Devstack devstack@neutron-ovn-maintenance-worker.service
     Loaded: loaded (/etc/systemd/system/devstack@neutron-ovn-maintenance-worker.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:58 UTC; 39min ago
   Main PID: 70814 (neutron-ovn-mai)
      Tasks: 41 (limit: 9444)
     Memory: 195.2M (peak: 258.5M swap: 241.7M swap peak: 241.7M zswap: 33.1M)
        CPU: 13.800s
     CGroup: /system.slice/system-devstack.slice/devstack@neutron-ovn-maintenance-worker.service
             ├─70814 "neutron-ovn-maintenance-worker: master process [/opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             └─71478 "neutron-server: maintenance worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"

Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mMaintenance task: Fixing resource 165f3cd3-0400-474a-ae54-bdf4423d35d1 (type: router_ports) at delete[00m [00;33m{{(pid=71478) check_for_inconsistencies /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:419}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.db.ovn_revision_numbers_db [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mdelete_revision(165f3cd3-0400-474a-ae54-bdf4423d35d1)[00m [00;33m{{(pid=71478) delete_revision /opt/stack/neutron/neutron/db/ovn_revision_numbers_db.py:112}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mMaintenance task: Fixing resource 4986672f-edea-45eb-8b2e-13b3e2489b29 (type: router_ports) at delete[00m [00;33m{{(pid=71478) check_for_inconsistencies /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:419}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.db.ovn_revision_numbers_db [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mdelete_revision(4986672f-edea-45eb-8b2e-13b3e2489b29)[00m [00;33m{{(pid=71478) delete_revision /opt/stack/neutron/neutron/db/ovn_revision_numbers_db.py:112}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mMaintenance task: Fixing resource 99390ff0-3dcd-405d-a433-fbf8646d92a1 (type: router_ports) at delete[00m [00;33m{{(pid=71478) check_for_inconsistencies /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:419}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.db.ovn_revision_numbers_db [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mdelete_revision(99390ff0-3dcd-405d-a433-fbf8646d92a1)[00m [00;33m{{(pid=71478) delete_revision /opt/stack/neutron/neutron/db/ovn_revision_numbers_db.py:112}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mMaintenance task: Fixing resource c9233673-c739-4931-aa6d-0b3c932326de (type: router_ports) at delete[00m [00;33m{{(pid=71478) check_for_inconsistencies /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:419}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG neutron.db.ovn_revision_numbers_db [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mdelete_revision(c9233673-c739-4931-aa6d-0b3c932326de)[00m [00;33m{{(pid=71478) delete_revision /opt/stack/neutron/neutron/db/ovn_revision_numbers_db.py:112}}[00m
Jul 29 17:29:21 np0000031958 neutron-ovn-maintenance-worker[71478]: INFO neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[01;36mNone req-9518c9d2-a20a-4249-aeb8-74fb41992848 [00;36mNone None] [01;35mMaintenance task: Synchronization completed (took 0.02 seconds)[00m
Jul 29 17:29:31 np0000031958 neutron-ovn-maintenance-worker[71478]: DEBUG dbcounter [[00;36m-] [01;35m[71478] Writing DB stats neutron:SELECT=6,neutron:DELETE=4[00m [00;33m{{(pid=71478) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@neutron-periodic-workers.service - Devstack devstack@neutron-periodic-workers.service
     Loaded: loaded (/etc/systemd/system/devstack@neutron-periodic-workers.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:57 UTC; 39min ago
   Main PID: 70339 (neutron-periodi)
      Tasks: 23 (limit: 9444)
     Memory: 97.8M (peak: 207.6M swap: 176.9M swap peak: 176.9M zswap: 46.2M)
        CPU: 3.348s
     CGroup: /system.slice/system-devstack.slice/devstack@neutron-periodic-workers.service
             ├─70339 "neutron-periodic-workers: master process [/opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             ├─70924 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             ├─70940 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             ├─70960 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             └─70970 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"

Jul 29 17:32:10 np0000031958 neutron-periodic-workers[70960]: DEBUG dbcounter [[00;36m-] [01;35m[70960] Writing DB stats neutron:DELETE=1[00m [00;33m{{(pid=70960) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:17 np0000031958 neutron-periodic-workers[70940]: DEBUG neutron.db.agents_db [[01;36mNone req-ca997b67-c3f3-4862-8801-3f6496205a83 [00;36mNone None] [01;35mAgent healthcheck: found 0 active agents[00m [00;33m{{(pid=70940) agent_health_check /opt/stack/neutron/neutron/db/agents_db.py:317}}[00m
Jul 29 17:32:17 np0000031958 neutron-periodic-workers[70940]: DEBUG oslo.service.backend.threading.loopingcall [[01;36mNone req-ca997b67-c3f3-4862-8801-3f6496205a83 [00;36mNone None] [01;35mFixed interval looping call 'neutron.plugins.ml2.plugin.AgentDbMixin.agent_health_check' sleeping for 37.00 seconds[00m [00;33m{{(pid=70940) _run_loop /opt/stack/data/venv/lib/python3.12/site-packages/oslo_service/backend/threading/loopingcall.py:165}}[00m
Jul 29 17:32:27 np0000031958 neutron-periodic-workers[70940]: DEBUG dbcounter [[00;36m-] [01;35m[70940] Writing DB stats neutron:SELECT=1[00m [00;33m{{(pid=70940) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:35 np0000031958 neutron-periodic-workers[70924]: DEBUG oslo.service.backend.threading.loopingcall [[01;36mNone req-6e6efc9b-335c-4529-b6e4-bb2825d16694 [00;36mNone None] [01;35mFixed interval looping call 'neutron.plugins.ml2.plugin.DhcpAgentSchedulerDbMixin.remove_networks_from_down_agents' sleeping for 36.99 seconds[00m [00;33m{{(pid=70924) _run_loop /opt/stack/data/venv/lib/python3.12/site-packages/oslo_service/backend/threading/loopingcall.py:165}}[00m
Jul 29 17:32:45 np0000031958 neutron-periodic-workers[70924]: DEBUG dbcounter [[00;36m-] [01;35m[70924] Writing DB stats neutron:SELECT=3[00m [00;33m{{(pid=70924) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:54 np0000031958 neutron-periodic-workers[70940]: DEBUG neutron.db.agents_db [[01;36mNone req-ca997b67-c3f3-4862-8801-3f6496205a83 [00;36mNone None] [01;35mAgent healthcheck: found 0 active agents[00m [00;33m{{(pid=70940) agent_health_check /opt/stack/neutron/neutron/db/agents_db.py:317}}[00m
Jul 29 17:32:54 np0000031958 neutron-periodic-workers[70940]: DEBUG oslo.service.backend.threading.loopingcall [[01;36mNone req-ca997b67-c3f3-4862-8801-3f6496205a83 [00;36mNone None] [01;35mFixed interval looping call 'neutron.plugins.ml2.plugin.AgentDbMixin.agent_health_check' sleeping for 37.00 seconds[00m [00;33m{{(pid=70940) _run_loop /opt/stack/data/venv/lib/python3.12/site-packages/oslo_service/backend/threading/loopingcall.py:165}}[00m
Jul 29 17:33:04 np0000031958 neutron-periodic-workers[70940]: DEBUG dbcounter [[00;36m-] [01;35m[70940] Writing DB stats neutron:SELECT=1[00m [00;33m{{(pid=70940) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:12 np0000031958 neutron-periodic-workers[70924]: DEBUG oslo.service.backend.threading.loopingcall [[01;36mNone req-6e6efc9b-335c-4529-b6e4-bb2825d16694 [00;36mNone None] [01;35mFixed interval looping call 'neutron.plugins.ml2.plugin.DhcpAgentSchedulerDbMixin.remove_networks_from_down_agents' sleeping for 37.00 seconds[00m [00;33m{{(pid=70924) _run_loop /opt/stack/data/venv/lib/python3.12/site-packages/oslo_service/backend/threading/loopingcall.py:165}}[00m

● devstack@neutron-rpc-server.service - Devstack devstack@neutron-rpc-server.service
     Loaded: loaded (/etc/systemd/system/devstack@neutron-rpc-server.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:56 UTC; 39min ago
   Main PID: 69866 (neutron-rpc-ser)
      Tasks: 16 (limit: 9444)
     Memory: 236.2M (peak: 236.7M swap: 160.2M swap peak: 160.2M zswap: 29.0M)
        CPU: 7.603s
     CGroup: /system.slice/system-devstack.slice/devstack@neutron-rpc-server.service
             ├─69866 "neutron-rpc-server: master process [/opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             └─71411 "neutron-server: rpc worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"

Jul 29 17:30:54 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.common.ovn.hash_ring_manager [[00;36m-] [01;35mHash Ring loaded. 2 active nodes. 0 offline nodes[00m [00;33m{{(pid=71411) _load_hash_ring /opt/stack/neutron/neutron/common/ovn/hash_ring_manager.py:102}}[00m
Jul 29 17:30:54 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.common.ovn.hash_ring_manager [[00;36m-] [01;35mHash Ring loaded. 2 active nodes. 0 offline nodes[00m [00;33m{{(pid=71411) _load_hash_ring /opt/stack/neutron/neutron/common/ovn/hash_ring_manager.py:102}}[00m
Jul 29 17:31:03 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.ovsdb_monitor [[00;36m-] [01;35mChassisAgentWriteEvent : Matched Chassis_Private, update, None None[00m [00;33m{{(pid=71411) matches /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py:65}}[00m
Jul 29 17:31:04 np0000031958 neutron-rpc-server[71411]: DEBUG dbcounter [[00;36m-] [01;35m[71411] Writing DB stats neutron:SELECT=4[00m [00;33m{{(pid=71411) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:31:08 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.ovsdb_monitor [[00;36m-] [01;35mChassisMetadataAgentWriteEvent : Matched Chassis_Private, update, None None[00m [00;33m{{(pid=71411) matches /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py:65}}[00m
Jul 29 17:31:51 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.ovsdb_monitor [[00;36m-] [01;35mChassisAgentWriteEvent : Matched Chassis_Private, update, None None[00m [00;33m{{(pid=71411) matches /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py:65}}[00m
Jul 29 17:31:51 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.ovsdb_monitor [[00;36m-] [01;35mChassisMetadataAgentWriteEvent : Matched Chassis_Private, update, None None[00m [00;33m{{(pid=71411) matches /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py:65}}[00m
Jul 29 17:31:56 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.common.ovn.hash_ring_manager [[00;36m-] [01;35mHash Ring loaded. 2 active nodes. 0 offline nodes[00m [00;33m{{(pid=71411) _load_hash_ring /opt/stack/neutron/neutron/common/ovn/hash_ring_manager.py:102}}[00m
Jul 29 17:32:00 np0000031958 neutron-rpc-server[71411]: DEBUG neutron.common.ovn.hash_ring_manager [[00;36m-] [01;35mHash Ring loaded. 2 active nodes. 0 offline nodes[00m [00;33m{{(pid=71411) _load_hash_ring /opt/stack/neutron/neutron/common/ovn/hash_ring_manager.py:102}}[00m
Jul 29 17:32:10 np0000031958 neutron-rpc-server[71411]: DEBUG dbcounter [[00;36m-] [01;35m[71411] Writing DB stats neutron:SELECT=4[00m [00;33m{{(pid=71411) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@openstack-cli-server.service - Devstack devstack@openstack-cli-server.service
     Loaded: loaded (/etc/systemd/system/devstack@openstack-cli-server.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:52:07 UTC; 41min ago
   Main PID: 43414 (python3)
      Tasks: 1 (limit: 9444)
     Memory: 30.9M (peak: 85.0M swap: 67.9M swap peak: 67.9M zswap: 14.2M)
        CPU: 7.511s
     CGroup: /system.slice/system-devstack.slice/devstack@openstack-cli-server.service
             └─43414 /opt/stack/data/venv/bin/python3 /opt/stack/devstack/files/openstack-cli-server/openstack-cli-server

Jul 29 16:54:53 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', 'project', 'list']
Jul 29 16:54:53 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', 'flavor', 'list']
Jul 29 16:54:53 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', 'image', 'show', '85b59897-1557-46b0-9d1f-15a398f486cd', '-c', 'size', '-f', 'value']
Jul 29 16:54:53 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', 'flavor', 'create', '--id', '42', '--ram', '192', '--disk', '1', '--vcpus', '1', '--property', 'hw_rng:allowed=True', 'm1.nano']
Jul 29 16:54:54 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', 'image', 'show', '58693232-4fd1-4a89-a891-81ab2c560d4a', '-c', 'size', '-f', 'value']
Jul 29 16:54:54 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', 'flavor', 'create', '--id', '84', '--ram', '256', '--disk', '1', '--vcpus', '1', '--property', 'hw_rng:allowed=True', 'm1.micro']
Jul 29 16:54:56 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', '--os-region', 'RegionOne', 'extension', 'list', '--network', '-c', 'Alias', '-f', 'value']
Jul 29 16:54:56 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', 'network', 'show', '-f', 'value', '-c', 'id', 'public']
Jul 29 16:54:56 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', '--os-region', 'RegionOne', 'network', 'create', '--share', 'shared']
Jul 29 16:54:56 np0000031958 python3[43414]: openstack ['--os-cloud', 'devstack-admin', '--os-region', 'RegionOne', 'subnet', 'create', '--description', 'shared-subnet', '--subnet-range', '192.168.233.0/24', '--network', 'shared', 'shared-subnet']

● devstack@placement-api.service - Devstack devstack@placement-api.service
     Loaded: loaded (/etc/systemd/system/devstack@placement-api.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:54:01 UTC; 39min ago
   Main PID: 71602 (uwsgi)
     Status: "uWSGI is ready"
      Tasks: 5 (limit: 9444)
     Memory: 123.2M (peak: 205.6M swap: 118.2M swap peak: 118.2M zswap: 39.6M)
        CPU: 12.705s
     CGroup: /system.slice/system-devstack.slice/devstack@placement-api.service
             ├─71602 "placementuWSGI master"
             ├─71603 "placementuWSGI worker 1"
             └─71604 "placementuWSGI worker 2"

Jul 29 17:32:21 np0000031958 devstack@placement-api.service[71604]: DEBUG dbcounter [[00;36m-] [01;35m[71604] Writing DB stats placement:SELECT=22,placement:DELETE=4[00m [00;33m{{(pid=71604) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:21 np0000031958 devstack@placement-api.service[71603]: DEBUG dbcounter [[00;36m-] [01;35m[71603] Writing DB stats placement:SELECT=22,placement:DELETE=2[00m [00;33m{{(pid=71603) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:32:51 np0000031958 devstack@placement-api.service[71604]: DEBUG placement.requestlog [[01;36mreq-c6612631-9763-4d43-8b2b-98aa28f2f75b req-d5409f39-edb2-4854-b8e1-52d5db439e06 [00;36mNone None] [01;35mStarting request: 192.168.1.104 "GET /placement/resource_providers/4dc4dd64-3ec2-45ab-9def-04370f25cd1e/allocations"[00m [00;33m{{(pid=71604) __call__ /opt/stack/placement/placement/requestlog.py:55}}[00m
Jul 29 17:32:51 np0000031958 devstack@placement-api.service[71604]: INFO placement.requestlog [[01;36mreq-c6612631-9763-4d43-8b2b-98aa28f2f75b req-d5409f39-edb2-4854-b8e1-52d5db439e06 [00;36mservice nova] [01;35m192.168.1.104 "GET /placement/resource_providers/4dc4dd64-3ec2-45ab-9def-04370f25cd1e/allocations" status: 200 len: 55 microversion: 1.0[00m
Jul 29 17:32:51 np0000031958 devstack@placement-api.service[71604]: [pid: 71604|app: 0|req: 629/1259] 192.168.1.104 () {66 vars in 1523 bytes} [Tue Jul 29 17:32:51 2025] GET /placement/resource_providers/4dc4dd64-3ec2-45ab-9def-04370f25cd1e/allocations => generated 55 bytes in 8 msecs (HTTP/1.1 200) 6 headers in 223 bytes (1 switches on core 0)
Jul 29 17:32:51 np0000031958 devstack@placement-api.service[71603]: DEBUG placement.requestlog [[01;36mreq-c6612631-9763-4d43-8b2b-98aa28f2f75b req-392bf9cd-bcfb-4a05-86ba-445cc938e47f [00;36mNone None] [01;35mStarting request: 192.168.1.104 "GET /placement/resource_providers/4dc4dd64-3ec2-45ab-9def-04370f25cd1e/allocations"[00m [00;33m{{(pid=71603) __call__ /opt/stack/placement/placement/requestlog.py:55}}[00m
Jul 29 17:32:51 np0000031958 devstack@placement-api.service[71603]: INFO placement.requestlog [[01;36mreq-c6612631-9763-4d43-8b2b-98aa28f2f75b req-392bf9cd-bcfb-4a05-86ba-445cc938e47f [00;36mservice nova] [01;35m192.168.1.104 "GET /placement/resource_providers/4dc4dd64-3ec2-45ab-9def-04370f25cd1e/allocations" status: 200 len: 55 microversion: 1.0[00m
Jul 29 17:32:51 np0000031958 devstack@placement-api.service[71603]: [pid: 71603|app: 0|req: 631/1260] 192.168.1.104 () {66 vars in 1523 bytes} [Tue Jul 29 17:32:51 2025] GET /placement/resource_providers/4dc4dd64-3ec2-45ab-9def-04370f25cd1e/allocations => generated 55 bytes in 9 msecs (HTTP/1.1 200) 6 headers in 223 bytes (1 switches on core 0)
Jul 29 17:33:01 np0000031958 devstack@placement-api.service[71604]: DEBUG dbcounter [[00;36m-] [01;35m[71604] Writing DB stats placement:SELECT=2[00m [00;33m{{(pid=71604) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:01 np0000031958 devstack@placement-api.service[71603]: DEBUG dbcounter [[00;36m-] [01;35m[71603] Writing DB stats placement:SELECT=2[00m [00;33m{{(pid=71603) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m

● devstack@q-ovn-agent.service - Devstack devstack@q-ovn-agent.service
     Loaded: loaded (/etc/systemd/system/devstack@q-ovn-agent.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:54 UTC; 39min ago
   Main PID: 68291 (neutron-ovn-age)
      Tasks: 30 (limit: 9444)
     Memory: 199.2M (peak: 558.3M swap: 460.6M swap peak: 461.2M zswap: 107.9M)
        CPU: 33.339s
     CGroup: /system.slice/system-devstack.slice/devstack@q-ovn-agent.service
             ├─68291 "neutron-ovn-agent: master process [/opt/stack/data/venv/bin/neutron-ovn-agent --config-file /etc/neutron/plugins/ml2/ovn_agent.ini]"
             ├─69566 "neutron-ovn-agent: ServiceWrapper worker(0)"
             ├─69991 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.namespace_cmd --privsep_sock_path /tmp/tmp6pg930cl/privsep.sock
             ├─72437 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.default --privsep_sock_path /tmp/tmpoexj_vsa/privsep.sock
             ├─87902 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.link_cmd --privsep_sock_path /tmp/tmpdh3dhj4v/privsep.sock
             ├─87989 sudo /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
             └─87990 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf

Jul 29 17:32:00 np0000031958 neutron-ovn-agent[69566]: DEBUG oslo.privsep.daemon [[00;36m-] [01;35mprivsep: reply[377d4dff-f8d2-4152-9100-3d9cb371ac88]: (4, True)[00m [00;33m{{(pid=72437) _call_back /opt/stack/data/venv/lib/python3.12/site-packages/oslo_privsep/daemon.py:512}}[00m
Jul 29 17:32:00 np0000031958 neutron-ovn-agent[69566]: DEBUG oslo.privsep.daemon [[00;36m-] [01;35mprivsep: reply[77c3e2d3-7507-434e-9684-2edca530f25f]: (4, [{'family': 0, '__align': (), 'ifi_type': 772, 'index': 1, 'flags': 65609, 'change': 0, 'attrs': [['IFLA_IFNAME', 'lo'], ['IFLA_TXQLEN', 1000], ['IFLA_OPERSTATE', 'UNKNOWN'], ['IFLA_LINKMODE', 0], ['IFLA_MTU', 65536], ['IFLA_MIN_MTU', 0], ['IFLA_MAX_MTU', 0], ['IFLA_GROUP', 0], ['IFLA_PROMISCUITY', 0], ['UNKNOWN', {'header': {'length': 8, 'type': 61}}], ['IFLA_NUM_TX_QUEUES', 1], ['IFLA_GSO_MAX_SEGS', 65535], ['IFLA_GSO_MAX_SIZE', 65536], ['IFLA_GRO_MAX_SIZE', 65536], ['UNKNOWN', {'header': {'length': 8, 'type': 63}}], ['UNKNOWN', {'header': {'length': 8, 'type': 64}}], ['IFLA_TSO_MAX_SIZE', 524280], ['IFLA_TSO_MAX_SEGS', 65535], ['IFLA_NUM_RX_QUEUES', 1], ['IFLA_CARRIER', 1], ['IFLA_QDISC', 'noqueue'], ['IFLA_CARRIER_CHANGES', 0], ['IFLA_CARRIER_UP_COUNT', 0], ['IFLA_CARRIER_DOWN_COUNT', 0], ['IFLA_PROTO_DOWN', 0], ['IFLA_MAP', {'mem_start': 0, 'mem_end': 0, 'base_addr': 0, 'irq': 0, 'dma': 0, 'port': 0}], ['IFLA_ADDRESS', '00:00:00:00:00:00'], ['IFLA_BROADCAST', '00:00:00:00:00:00'], ['IFLA_STATS64', {'rx_packets': 0, 'tx_packets': 0, 'rx_bytes': 0, 'tx_bytes': 0, 'rx_errors': 0, 'tx_errors': 0, 'rx_dropped': 0, 'tx_dropped': 0, 'multicast': 0, 'collisions': 0, 'rx_length_errors': 0, 'rx_over_errors': 0, 'rx_crc_errors': 0, 'rx_frame_errors': 0, 'rx_fifo_errors': 0, 'rx_missed_errors': 0, 'tx_aborted_errors': 0, 'tx_carrier_errors': 0, 'tx_fifo_errors': 0, 'tx_heartbeat_errors': 0, 'tx_window_errors': 0, 'rx_compressed': 0, 'tx_compressed': 0}], ['IFLA_STATS', {'rx_packets': 0, 'tx_packets': 0, 'rx_bytes': 0, 'tx_bytes': 0, 'rx_errors': 0, 'tx_errors': 0, 'rx_dropped': 0, 'tx_dropped': 0, 'multicast': 0, 'collisions': 0, 'rx_length_errors': 0, 'rx_over_errors': 0, 'rx_crc_errors': 0, 'rx_frame_errors': 0, 'rx_fifo_errors': 0, 'rx_missed_errors': 0, 'tx_aborted_errors': 0, 'tx_carrier_errors': 0, 'tx_fifo_errors': 0, 'tx_heartbeat_errors': 0, 'tx_window_errors': 0, 'rx_compressed': 0, 'tx_compressed': 0}], ['IFLA_XDP', {'attrs': [['IFLA_XDP_ATTACHED', None]]}], ['IFLA_AF_SPEC', {'attrs': [['UNKNOWN', {'header': {'length': 12, 'type': 45}}], ['AF_INET', {'dummy': 65672, 'forwarding': 1, 'mc_forwarding': 0, 'proxy_arp': 0, 'accept_redirects': 1, 'secure_redirects': 1, 'send_redirects': 1, 'shared_media': 1, 'rp_filter': 2, 'accept_source_route': 1, 'bootp_relay': 0, 'log_martians': 0, 'tag': 0, 'arpfilter': 0, 'medium_id': 0, 'noxfrm': 1, 'nopolicy': 1, 'force_igmp_version': 0, 'arp_announce': 0, 'arp_ignore': 0, 'promote_secondaries': 0, 'arp_accept': 0, 'arp_notify': 0, 'accept_local': 0, 'src_vmark': 0, 'proxy_arp_pvlan': 0, 'route_localnet': 0, 'igmpv2_unsolicited_report_interval': 10000, 'igmpv3_unsolicited_report_interval': 1000}], ['AF_INET6', {'attrs': [['IFLA_INET6_FLAGS', 2147483648], ['IFLA_INET6_CACHEINFO', {'max_reasm_len': 65535, 'tstamp': 1059297, 'reachable_time': 18599, 'retrans_time': 1000}], ['IFLA_INET6_CONF', {'forwarding': 0, 'hop_limit': 64, 'mtu': 65536, 'accept_ra': 1, 'accept_redirects': 1, 'autoconf': 1, 'dad_transmits': 1, 'router_solicitations': 4294967295, 'router_solicitation_interval': 4000, 'router_solicitation_delay': 1000, 'use_tempaddr': 4294967295, 'temp_valid_lft': 604800, 'temp_preferred_lft': 86400, 'regen_max_retry': 3, 'max_desync_factor': 600, 'max_addresses': 16, 'force_mld_version': 0, 'accept_ra_defrtr': 1, 'accept_ra_pinfo': 1, 'accept_ra_rtr_pref': 1, 'router_probe_interval': 60000, 'accept_ra_rt_info_max_plen': 0, 'proxy_ndp': 0, 'optimistic_dad': 0, 'accept_source_route': 0, 'mc_forwarding': 0, 'disable_ipv6': 0, 'accept_dad': 4294967295, 'force_tllao': 0, 'ndisc_notify': 0}], ['IFLA_INET6_STATS', {'num': 38, 'inpkts': 0, 'inoctets': 0, 'indelivers': 0, 'outforwdatagrams': 0, 'outpkts': 0, 'outoctets': 0, 'inhdrerrors': 0, 'intoobigerrors': 0, 'innoroutes': 0, 'inaddrerrors': 0, 'inunknownprotos': 0, 'intruncatedpkts': 0, 'indiscards': 0, 'outdiscards': 0, 'outnoroutes': 0, 'reasmtimeout': 0, 'reasmreqds': 0, 'reasmoks': 0, 'reasmfails': 0, 'fragoks': 0, 'fragfails': 0, 'fragcreates': 0, 'inmcastpkts': 0, 'outmcastpkts': 0, 'inbcastpkts': 0, 'outbcastpkts': 0, 'inmcastoctets': 0, 'outmcastoctets': 0, 'inbcastoctets': 0, 'outbcastoctets': 0, 'csumerrors': 0, 'noectpkts': 0, 'ect1pkts': 0, 'ect0pkts': 0, 'cepkts': 0}], ['IFLA_INET6_ICMP6STATS', {'num': 7, 'inmsgs': 0, 'inerrors': 0, 'outmsgs': 0, 'outerrors': 0, 'csumerrors': 0}], ['IFLA_INET6_TOKEN', '::'], ['IFLA_INET6_ADDR_GEN_MODE', 0]]}]]}], ['UNKNOWN', {'header': {'length': 4, 'type': 32830}}], ['UNKNOWN', {'header': {'length': 4, 'type': 32833}}]], 'header': {'length': 1444, 'type': 16, 'flags': 2, 'sequence_number': 255, 'pid': 131892, 'error': None, 'target': 'ovnmeta-0656be21-9f8e-413a-861a-be5cee277270', 'stats': (0, 0, 0)}, 'state': 'up', 'event': 'RTM_NEWLINK'}])[00m [00;33m{{(pid=72437) _call_back /opt/stack/data/venv/lib/python3.12/site-packages/oslo_privsep/daemon.py:512}}[00m
Jul 29 17:32:00 np0000031958 neutron-ovn-agent[69566]: DEBUG neutron.privileged.agent.linux.ip_lib [[00;36m-] [01;35mNamespace ovnmeta-0656be21-9f8e-413a-861a-be5cee277270 deleted.[00m [00;33m{{(pid=69991) remove_netns /opt/stack/neutron/neutron/privileged/agent/linux/ip_lib.py:603}}[00m
Jul 29 17:32:00 np0000031958 neutron-ovn-agent[69566]: DEBUG oslo.privsep.daemon [[00;36m-] [01;35mprivsep: reply[80b4ebd1-1002-4f6d-9426-b406ea186b5f]: (4, None)[00m [00;33m{{(pid=69991) _call_back /opt/stack/data/venv/lib/python3.12/site-packages/oslo_privsep/daemon.py:512}}[00m
Jul 29 17:32:56 np0000031958 neutron-ovn-agent[68291]: DEBUG oslo_concurrency.lockutils [[00;36m-] [01;35mAcquiring lock "_check_child_processes" by "neutron.agent.linux.external_process.ProcessMonitor._check_child_processes"[00m [00;33m{{(pid=68291) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:405}}[00m
Jul 29 17:32:56 np0000031958 neutron-ovn-agent[68291]: DEBUG oslo_concurrency.lockutils [[00;36m-] [01;35mAcquiring lock "_check_child_processes" by "neutron.agent.linux.external_process.ProcessMonitor._check_child_processes"[00m [00;33m{{(pid=68291) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:405}}[00m
Jul 29 17:32:56 np0000031958 neutron-ovn-agent[68291]: DEBUG oslo_concurrency.lockutils [[00;36m-] [01;35mLock "_check_child_processes" acquired by "neutron.agent.linux.external_process.ProcessMonitor._check_child_processes" :: waited 0.000s[00m [00;33m{{(pid=68291) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:410}}[00m
Jul 29 17:32:56 np0000031958 neutron-ovn-agent[68291]: DEBUG oslo_concurrency.lockutils [[00;36m-] [01;35mLock "_check_child_processes" "released" by "neutron.agent.linux.external_process.ProcessMonitor._check_child_processes" :: held 0.000s[00m [00;33m{{(pid=68291) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:424}}[00m
Jul 29 17:32:56 np0000031958 neutron-ovn-agent[68291]: DEBUG oslo_concurrency.lockutils [[00;36m-] [01;35mLock "_check_child_processes" acquired by "neutron.agent.linux.external_process.ProcessMonitor._check_child_processes" :: waited 0.000s[00m [00;33m{{(pid=68291) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:410}}[00m
Jul 29 17:32:56 np0000031958 neutron-ovn-agent[68291]: DEBUG oslo_concurrency.lockutils [[00;36m-] [01;35mLock "_check_child_processes" "released" by "neutron.agent.linux.external_process.ProcessMonitor._check_child_processes" :: held 0.000s[00m [00;33m{{(pid=68291) inner /opt/stack/data/venv/lib/python3.12/site-packages/oslo_concurrency/lockutils.py:424}}[00m

○ dm-event.service - Device-mapper event daemon
     Loaded: loaded (/usr/lib/systemd/system/dm-event.service; static)
     Active: inactive (dead)
TriggeredBy: ● dm-event.socket
       Docs: man:dmeventd(8)

○ dmesg.service - Save initial kernel messages after boot
     Loaded: loaded (/usr/lib/systemd/system/dmesg.service; enabled; preset: enabled)
     Active: inactive (dead) since Tue 2025-07-29 14:32:58 UTC; 3h 0min ago
   Duration: 5.033s
   Main PID: 957 (code=exited, status=0/SUCCESS)
        CPU: 30ms

Jul 29 14:32:53 ubuntu systemd[1]: Started dmesg.service - Save initial kernel messages after boot.
Jul 29 14:32:58 np0000031958 systemd[1]: dmesg.service: Deactivated successfully.

○ dpkg-db-backup.service - Daily dpkg database backup service
     Loaded: loaded (/usr/lib/systemd/system/dpkg-db-backup.service; static)
     Active: inactive (dead)
TriggeredBy: ● dpkg-db-backup.timer
       Docs: man:dpkg(1)

○ e2scrub_all.service - Online ext4 Metadata Check for All Filesystems
     Loaded: loaded (/usr/lib/systemd/system/e2scrub_all.service; static)
     Active: inactive (dead)
TriggeredBy: ● e2scrub_all.timer
       Docs: man:e2scrub_all(8)

○ e2scrub_reap.service - Remove Stale Online ext4 Metadata Check Snapshots
     Loaded: loaded (/usr/lib/systemd/system/e2scrub_reap.service; enabled; preset: enabled)
     Active: inactive (dead) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:e2scrub_all(8)
   Main PID: 523 (code=exited, status=0/SUCCESS)
        CPU: 11ms

Jul 29 14:32:53 ubuntu systemd[1]: Starting e2scrub_reap.service - Remove Stale Online ext4 Metadata Check Snapshots...
Jul 29 14:32:53 ubuntu systemd[1]: e2scrub_reap.service: Deactivated successfully.
Jul 29 14:32:53 ubuntu systemd[1]: Finished e2scrub_reap.service - Remove Stale Online ext4 Metadata Check Snapshots.

○ emergency.service - Emergency Shell
     Loaded: loaded (/usr/lib/systemd/system/emergency.service; static)
     Active: inactive (dead)
       Docs: man:sulogin(8)

● epmd.service - Erlang Port Mapper Daemon
     Loaded: loaded (/usr/lib/systemd/system/epmd.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:43:55 UTC; 49min ago
TriggeredBy: ● epmd.socket
   Main PID: 17674 (epmd)
      Tasks: 1 (limit: 9444)
     Memory: 412.0K (peak: 1.5M swap: 168.0K swap peak: 168.0K zswap: 41.1K)
        CPU: 27ms
     CGroup: /system.slice/epmd.service
             └─17674 /usr/bin/epmd -systemd

Jul 29 16:43:55 np0000031958 systemd[1]: Started epmd.service - Erlang Port Mapper Daemon.

○ fstrim.service - Discard unused blocks on filesystems from /etc/fstab
     Loaded: loaded (/usr/lib/systemd/system/fstrim.service; static)
     Active: inactive (dead)
TriggeredBy: ● fstrim.timer
       Docs: man:fstrim(8)

○ getty-static.service - getty on tty2-tty6 if dbus and logind are not available
     Loaded: loaded (/usr/lib/systemd/system/getty-static.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:53 UTC; 3h 0min ago

Jul 29 14:32:53 ubuntu systemd[1]: getty-static.service - getty on tty2-tty6 if dbus and logind are not available was skipped because of an unmet condition check (ConditionPathExists=!/usr/bin/dbus-daemon).

● getty@tty1.service - Getty on tty1
     Loaded: loaded (/usr/lib/systemd/system/getty@.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:agetty(8)
             man:systemd-getty-generator(8)
             https://0pointer.de/blog/projects/serial-console.html
   Main PID: 1015 (agetty)
      Tasks: 1 (limit: 9444)
     Memory: 320.0K (peak: 1.8M)
        CPU: 5ms
     CGroup: /system.slice/system-getty.slice/getty@tty1.service
             └─1015 /sbin/agetty -o "-p -- \\u" --noclear - linux

Jul 29 14:34:55 np0000031958 systemd[1]: Started getty@tty1.service - Getty on tty1.

● glean-early.service - Early glean execution
     Loaded: loaded (/usr/lib/systemd/system/glean-early.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Main PID: 524 (code=exited, status=0/SUCCESS)
        CPU: 77ms

Jul 29 14:32:53 ubuntu glean-early.sh[581]: DEBUG:glean:Detected distro : ubuntu
Jul 29 14:32:53 ubuntu glean-early.sh[581]: DEBUG:glean:Configuring without NetworkManager
Jul 29 14:32:53 ubuntu glean-early.sh[581]: DEBUG:glean:metadata loaded from: /mnt/config/openstack/latest/meta_data.json
Jul 29 14:32:53 ubuntu glean-early.sh[581]: DEBUG:glean:Writing output files
Jul 29 14:32:53 ubuntu glean-early.sh[581]: DEBUG:glean:Writing output file : /root/.ssh/authorized_keys
Jul 29 14:32:53 ubuntu glean-early.sh[581]: DEBUG:glean: ... done
Jul 29 14:32:53 ubuntu glean-early.sh[581]: DEBUG:glean:Got hostname from meta_data.json : np0000031958
Jul 29 14:32:53 np0000031958 glean-early.sh[581]: DEBUG:glean:Found network_info file /mnt/config/openstack/latest/network_data.json
Jul 29 14:32:53 np0000031958 glean-early.sh[581]: DEBUG:glean:Done!
Jul 29 14:32:53 np0000031958 systemd[1]: Finished glean-early.service - Early glean execution.

● glean@enp3s0.service - Glean for interface enp3s0
     Loaded: loaded (/usr/lib/systemd/system/glean@.service; disabled; preset: enabled)
    Drop-In: /etc/systemd/system/glean@.service.d
             └─override.conf
     Active: active (exited) since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
   Main PID: 678 (code=exited, status=0/SUCCESS)
      Tasks: 1 (limit: 9444)
     Memory: 1.4M (peak: 9.4M)
        CPU: 123ms
     CGroup: /system.slice/system-glean.slice/glean@enp3s0.service
             └─704 dhclient -1 -4 -v -i -pf /run/dhclient.enp3s0.pid -lf /var/lib/dhcp/dhclient.enp3s0.leases -I -df /var/lib/dhcp/dhclient6.enp3s0.leases enp3s0

Jul 29 14:32:54 np0000031958 dhclient[704]: DHCPACK of 10.241.128.124 from 10.241.128.1 (xid=0xde017161)
Jul 29 14:32:54 np0000031958 ifup[704]: DHCPACK of 10.241.128.124 from 10.241.128.1 (xid=0xde017161)
Jul 29 14:32:54 np0000031958 ifup[704]: suspect value in domain_search option - discarded
Jul 29 14:32:54 np0000031958 dhclient[704]: suspect value in domain_search option - discarded
Jul 29 14:32:55 np0000031958 ifup[794]: Setting LLMNR support level "yes" for "2", but the global support level is "no".
Jul 29 14:32:55 np0000031958 dhclient[704]: Error printing text.
Jul 29 14:32:55 np0000031958 ifup[704]: Error printing text.
Jul 29 14:32:55 np0000031958 dhclient[704]: bound to 10.241.128.124 -- renewal in 18632 seconds.
Jul 29 14:32:55 np0000031958 ifup[704]: bound to 10.241.128.124 -- renewal in 18632 seconds.
Jul 29 14:32:55 np0000031958 systemd[1]: Finished glean@enp3s0.service - Glean for interface enp3s0.

● glean@enp4s0.service - Glean for interface enp4s0
     Loaded: loaded (/usr/lib/systemd/system/glean@.service; disabled; preset: enabled)
    Drop-In: /etc/systemd/system/glean@.service.d
             └─override.conf
     Active: active (exited) since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
   Main PID: 680 (code=exited, status=0/SUCCESS)
      Tasks: 1 (limit: 9444)
     Memory: 1.3M (peak: 9.9M)
        CPU: 123ms
     CGroup: /system.slice/system-glean.slice/glean@enp4s0.service
             └─703 dhclient -1 -4 -v -i -pf /run/dhclient.enp4s0.pid -lf /var/lib/dhcp/dhclient.enp4s0.leases -I -df /var/lib/dhcp/dhclient6.enp4s0.leases enp4s0

Jul 29 14:32:54 np0000031958 ifup[703]: suspect value in domain_search option - discarded
Jul 29 14:32:54 np0000031958 dhclient[703]: DHCPACK of 192.168.1.104 from 192.168.1.100 (xid=0xde017161)
Jul 29 14:32:54 np0000031958 dhclient[703]: suspect value in domain_search option - discarded
Jul 29 14:32:55 np0000031958 ifup[795]: Setting LLMNR support level "yes" for "3", but the global support level is "no".
Jul 29 14:32:55 np0000031958 root[807]: /etc/dhcp/dhclient-exit-hooks.d/rfc3442-classless-routes returned non-zero exit status 2
Jul 29 14:32:55 np0000031958 dhclient[703]: Error printing text.
Jul 29 14:32:55 np0000031958 ifup[703]: Error printing text.
Jul 29 14:32:55 np0000031958 dhclient[703]: bound to 192.168.1.104 -- renewal in 18632 seconds.
Jul 29 14:32:55 np0000031958 ifup[703]: bound to 192.168.1.104 -- renewal in 18632 seconds.
Jul 29 14:32:55 np0000031958 systemd[1]: Finished glean@enp4s0.service - Glean for interface enp4s0.

● glean@lo.service - Glean for interface lo
     Loaded: loaded (/usr/lib/systemd/system/glean@.service; disabled; preset: enabled)
    Drop-In: /etc/systemd/system/glean@.service.d
             └─override.conf
     Active: active (exited) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Main PID: 677 (code=exited, status=0/SUCCESS)
        CPU: 61ms

Jul 29 14:32:53 np0000031958 systemd[1]: Starting glean@lo.service - Glean for interface lo...
Jul 29 14:32:53 np0000031958 systemd[1]: Finished glean@lo.service - Glean for interface lo.

● growroot.service - Grow root partition
     Loaded: loaded (/usr/lib/systemd/system/growroot.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Main PID: 525 (code=exited, status=0/SUCCESS)
        CPU: 91ms

Jul 29 14:32:53 ubuntu growroot[525]: + set +e
Jul 29 14:32:53 ubuntu growroot[525]: + growpart /dev/vda 1
Jul 29 14:32:53 np0000031958 growroot[560]: CHANGED: partition=1 start=2048 old: size=39844224 end=39846271 new: size=209713119 end=209715166
Jul 29 14:32:53 np0000031958 growroot[525]: + '[' 0 -le 1 ']'
Jul 29 14:32:53 np0000031958 growroot[525]: + resize2fs /dev/vda1
Jul 29 14:32:53 np0000031958 growroot[747]: resize2fs 1.47.0 (5-Feb-2023)
Jul 29 14:32:53 np0000031958 growroot[747]: Filesystem at /dev/vda1 is mounted on /; on-line resizing required
Jul 29 14:32:53 np0000031958 growroot[747]: old_desc_blocks = 3, new_desc_blocks = 13
Jul 29 14:32:53 np0000031958 growroot[747]: The filesystem on /dev/vda1 is now 26214139 (4k) blocks long.
Jul 29 14:32:53 np0000031958 systemd[1]: Finished growroot.service - Grow root partition.

○ grub-common.service - Record successful boot for GRUB
     Loaded: loaded (/usr/lib/systemd/system/grub-common.service; enabled; preset: enabled)
     Active: inactive (dead) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Main PID: 547 (code=exited, status=0/SUCCESS)
        CPU: 17ms

Jul 29 14:32:53 ubuntu systemd[1]: Starting grub-common.service - Record successful boot for GRUB...
Jul 29 14:32:53 ubuntu systemd[1]: grub-common.service: Deactivated successfully.
Jul 29 14:32:53 ubuntu systemd[1]: Finished grub-common.service - Record successful boot for GRUB.

○ grub-initrd-fallback.service - GRUB failed boot detection
     Loaded: loaded (/usr/lib/systemd/system/grub-initrd-fallback.service; enabled; preset: enabled)
     Active: inactive (dead) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Main PID: 586 (code=exited, status=0/SUCCESS)
        CPU: 9ms

Jul 29 14:32:53 ubuntu systemd[1]: Starting grub-initrd-fallback.service - GRUB failed boot detection...
Jul 29 14:32:53 ubuntu systemd[1]: grub-initrd-fallback.service: Deactivated successfully.
Jul 29 14:32:53 ubuntu systemd[1]: Finished grub-initrd-fallback.service - GRUB failed boot detection.

● haproxy.service - HAProxy Load Balancer
     Loaded: loaded (/usr/lib/systemd/system/haproxy.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:43:12 UTC; 50min ago
       Docs: man:haproxy(1)
             file:/usr/share/doc/haproxy/configuration.txt.gz
   Main PID: 11224 (haproxy)
     Status: "Ready."
      Tasks: 9 (limit: 9444)
     Memory: 15.8M (peak: 43.3M swap: 26.5M swap peak: 26.5M zswap: 1.3M)
        CPU: 90ms
     CGroup: /system.slice/haproxy.service
             ├─11224 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
             └─11226 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock

Jul 29 16:43:11 np0000031958 systemd[1]: Starting haproxy.service - HAProxy Load Balancer...
Jul 29 16:43:12 np0000031958 haproxy[11224]: [NOTICE]   (11224) : New worker (11226) forked
Jul 29 16:43:12 np0000031958 haproxy[11224]: [NOTICE]   (11224) : Loading success.
Jul 29 16:43:12 np0000031958 systemd[1]: Started haproxy.service - HAProxy Load Balancer.

● haveged.service - Entropy Daemon based on the HAVEGE algorithm
     Loaded: loaded (/usr/lib/systemd/system/haveged.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:haveged(8)
             http://www.issihosts.com/haveged/
   Main PID: 403 (haveged)
      Tasks: 1 (limit: 9444)
     Memory: 3.2M (peak: 4.4M swap: 832.0K swap peak: 832.0K zswap: 549.1K)
        CPU: 360ms
     CGroup: /system.slice/haveged.service
             └─403 /usr/sbin/haveged --Foreground --verbose=1

Jul 29 14:32:52 ubuntu systemd[1]: Started haveged.service - Entropy Daemon based on the HAVEGE algorithm.
Jul 29 14:32:52 ubuntu (haveged)[403]: haveged.service: Referenced but unset environment variable evaluates to an empty string: DAEMON_ARGS
Jul 29 14:32:52 ubuntu haveged[403]: haveged: command socket is listening at fd 3
Jul 29 14:32:52 ubuntu haveged[403]: haveged starting up
Jul 29 14:32:52 ubuntu haveged[403]: haveged: ver: 1.9.14; arch: x86; vend: GenuineIntel; build: (gcc 13.2.0 ITV); collect: 128K
Jul 29 14:32:52 ubuntu haveged[403]: haveged: cpu: (L4 VC); data: 32K (L2 L4 V); inst: 32K (L2 L4 V); idx: 23/40; sz: 31312/55191
Jul 29 14:32:52 ubuntu haveged[403]: haveged: tot tests(BA8): A:1/1 B:1/1 continuous tests(B):  last entropy estimate 7.99751
Jul 29 14:32:52 ubuntu haveged[403]: haveged: fills: 0, generated: 0

● ifupdown-pre.service - Helper to synchronize boot up for ifupdown
     Loaded: loaded (/usr/lib/systemd/system/ifupdown-pre.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Main PID: 368 (code=exited, status=0/SUCCESS)
        CPU: 4ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting ifupdown-pre.service - Helper to synchronize boot up for ifupdown...
Jul 29 14:32:52 ubuntu systemd[1]: Finished ifupdown-pre.service - Helper to synchronize boot up for ifupdown.

× initialize-urandom.service - Quickly initialize the nonblocking kernel random number generator at boot.
     Loaded: loaded (/usr/lib/systemd/system/initialize-urandom.service; enabled; preset: enabled)
     Active: failed (Result: exit-code) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Main PID: 527 (code=exited, status=127)
        CPU: 3ms

Jul 29 14:32:53 ubuntu systemd[1]: Starting initialize-urandom.service - Quickly initialize the nonblocking kernel random number generator at boot....
Jul 29 14:32:53 ubuntu initialize-urandom.py[527]: /usr/bin/env: ‘python’: No such file or directory
Jul 29 14:32:53 ubuntu systemd[1]: initialize-urandom.service: Main process exited, code=exited, status=127/n/a
Jul 29 14:32:53 ubuntu systemd[1]: initialize-urandom.service: Failed with result 'exit-code'.
Jul 29 14:32:53 ubuntu systemd[1]: Failed to start initialize-urandom.service - Quickly initialize the nonblocking kernel random number generator at boot..

○ initrd-cleanup.service - Cleaning Up and Shutting Down Daemons
     Loaded: loaded (/usr/lib/systemd/system/initrd-cleanup.service; static)
     Active: inactive (dead)

○ initrd-parse-etc.service - Mountpoints Configured in the Real Root
     Loaded: loaded (/usr/lib/systemd/system/initrd-parse-etc.service; static)
     Active: inactive (dead)

○ initrd-switch-root.service - Switch Root
     Loaded: loaded (/usr/lib/systemd/system/initrd-switch-root.service; static)
     Active: inactive (dead)

○ initrd-udevadm-cleanup-db.service - Cleanup udev Database
     Loaded: loaded (/usr/lib/systemd/system/initrd-udevadm-cleanup-db.service; static)
     Active: inactive (dead)

● iscsid.service - iSCSI initiator daemon (iscsid)
     Loaded: loaded (/usr/lib/systemd/system/iscsid.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:54 UTC; 41min ago
TriggeredBy: ● iscsid.socket
       Docs: man:iscsid(8)
   Main PID: 36014 (iscsid)
      Tasks: 2 (limit: 9444)
     Memory: 3.4M (peak: 7.0M swap: 156.0K swap peak: 156.0K zswap: 38.8K)
        CPU: 254ms
     CGroup: /system.slice/iscsid.service
             ├─36013 /usr/sbin/iscsid
             └─36014 /usr/sbin/iscsid

Jul 29 17:28:40 np0000031958 iscsid[36013]: Connection56:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.74,3260] through [iface: default] is shutdown.
Jul 29 17:28:40 np0000031958 iscsid[36013]: Connection59:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.75,3260] through [iface: default] is shutdown.
Jul 29 17:29:19 np0000031958 iscsid[36013]: Connection60:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.64,3260] through [iface: default] is operational now
Jul 29 17:29:19 np0000031958 iscsid[36013]: Connection61:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.75,3260] through [iface: default] is operational now
Jul 29 17:29:19 np0000031958 iscsid[36013]: Connection62:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.74,3260] through [iface: default] is operational now
Jul 29 17:29:19 np0000031958 iscsid[36013]: Connection63:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.65,3260] through [iface: default] is operational now
Jul 29 17:32:01 np0000031958 iscsid[36013]: Connection60:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.64,3260] through [iface: default] is shutdown.
Jul 29 17:32:01 np0000031958 iscsid[36013]: Connection63:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.65,3260] through [iface: default] is shutdown.
Jul 29 17:32:01 np0000031958 iscsid[36013]: Connection62:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.74,3260] through [iface: default] is shutdown.
Jul 29 17:32:01 np0000031958 iscsid[36013]: Connection61:0 to [target: iqn.2010-06.com.purestorage:flasharray.4118da8397e32fc7, portal: 192.168.1.75,3260] through [iface: default] is shutdown.

● kmod-static-nodes.service - Create List of Static Device Nodes
     Loaded: loaded (/usr/lib/systemd/system/kmod-static-nodes.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Main PID: 312 (code=exited, status=0/SUCCESS)
        CPU: 3ms

Notice: journal has been rotated since unit was started, output may be incomplete.

● ksm.service - Kernel Samepage Merging
     Loaded: loaded (/usr/lib/systemd/system/ksm.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:42:28 UTC; 50min ago
   Main PID: 5734 (code=exited, status=0/SUCCESS)
        CPU: 1ms

Jul 29 16:42:28 np0000031958 systemd[1]: Starting ksm.service - Kernel Samepage Merging...
Jul 29 16:42:28 np0000031958 systemd[1]: Finished ksm.service - Kernel Samepage Merging.

● ksmtuned.service - Kernel Samepage Merging (KSM) Tuning Daemon
     Loaded: loaded (/usr/lib/systemd/system/ksmtuned.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:42:28 UTC; 50min ago
   Main PID: 5739 (ksmtuned)
      Tasks: 2 (limit: 9444)
     Memory: 1.6M (peak: 3.9M swap: 492.0K swap peak: 492.0K zswap: 18.5K)
        CPU: 1.089s
     CGroup: /system.slice/ksmtuned.service
             ├─  5739 /bin/bash /usr/sbin/ksmtuned
             └─132319 sleep 60

Jul 29 16:42:28 np0000031958 systemd[1]: Starting ksmtuned.service - Kernel Samepage Merging (KSM) Tuning Daemon...
Jul 29 16:42:28 np0000031958 systemd[1]: Started ksmtuned.service - Kernel Samepage Merging (KSM) Tuning Daemon.

● ldconfig.service - Rebuild Dynamic Linker Cache
     Loaded: loaded (/usr/lib/systemd/system/ldconfig.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:ldconfig(8)
   Main PID: 388 (code=exited, status=0/SUCCESS)
        CPU: 28ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting ldconfig.service - Rebuild Dynamic Linker Cache...
Jul 29 14:32:52 ubuntu systemd[1]: Finished ldconfig.service - Rebuild Dynamic Linker Cache.

● libvirt-guests.service - libvirt guests suspend/resume service
     Loaded: loaded (/usr/lib/systemd/system/libvirt-guests.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:51:27 UTC; 41min ago
       Docs: man:libvirt-guests(8)
             https://libvirt.org/
   Main PID: 34167 (code=exited, status=0/SUCCESS)
        CPU: 6ms

Jul 29 16:51:27 np0000031958 systemd[1]: Starting libvirt-guests.service - libvirt guests suspend/resume service...
Jul 29 16:51:27 np0000031958 systemd[1]: Finished libvirt-guests.service - libvirt guests suspend/resume service.

● libvirtd.service - libvirt legacy monolithic daemon
     Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled; preset: enabled)
    Drop-In: /etc/systemd/system/libvirtd.service.d
             └─coredump.conf
     Active: active (running) since Tue 2025-07-29 16:54:21 UTC; 38min ago
TriggeredBy: ● libvirtd.socket
             ● libvirtd-ro.socket
             ● libvirtd-admin.socket
       Docs: man:libvirtd(8)
             https://libvirt.org/
   Main PID: 78152 (libvirtd)
      Tasks: 23 (limit: 32768)
     Memory: 46.9M (peak: 102.6M swap: 6.4M swap peak: 6.6M zswap: 1.1M)
        CPU: 15.064s
     CGroup: /system.slice/libvirtd.service
             ├─34056 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
             ├─34057 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
             └─78152 /usr/sbin/libvirtd --timeout 120

Jul 29 16:54:21 np0000031958 systemd[1]: Starting libvirtd.service - libvirt legacy monolithic daemon...
Jul 29 16:54:21 np0000031958 libvirtd[78152]: 2025-07-29 16:54:21.570+0000: 78152: info : libvirt version: 10.0.0, package: 10.0.0-2ubuntu8.8 (Ubuntu)
Jul 29 16:54:21 np0000031958 libvirtd[78152]: 2025-07-29 16:54:21.570+0000: 78152: info : hostname: np0000031958
Jul 29 16:54:21 np0000031958 libvirtd[78152]: 2025-07-29 16:54:21.570+0000: 78152: debug : virLogParseOutputs:1638 : outputs=1:file:/var/log/libvirt/libvirtd.log
Jul 29 16:54:21 np0000031958 libvirtd[78152]: 2025-07-29 16:54:21.570+0000: 78152: debug : virLogParseOutput:1485 : output=1:file:/var/log/libvirt/libvirtd.log
Jul 29 16:54:21 np0000031958 systemd[1]: Started libvirtd.service - libvirt legacy monolithic daemon.
Jul 29 16:54:21 np0000031958 dnsmasq[34056]: read /etc/hosts - 14 names
Jul 29 16:54:21 np0000031958 dnsmasq[34056]: read /var/lib/libvirt/dnsmasq/default.addnhosts - 0 names
Jul 29 16:54:21 np0000031958 dnsmasq-dhcp[34056]: read /var/lib/libvirt/dnsmasq/default.hostsfile

○ logrotate.service - Rotate log files
     Loaded: loaded (/usr/lib/systemd/system/logrotate.service; static)
     Active: inactive (dead)
TriggeredBy: ● logrotate.timer
       Docs: man:logrotate(8)
             man:logrotate.conf(5)

○ lvm2-lvmpolld.service - LVM2 poll daemon
     Loaded: loaded (/usr/lib/systemd/system/lvm2-lvmpolld.service; static)
     Active: inactive (dead)
TriggeredBy: ● lvm2-lvmpolld.socket
       Docs: man:lvmpolld(8)

● lvm2-monitor.service - Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
     Loaded: loaded (/usr/lib/systemd/system/lvm2-monitor.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:43:19 UTC; 49min ago
       Docs: man:dmeventd(8)
             man:lvcreate(8)
             man:lvchange(8)
             man:vgchange(8)
   Main PID: 12381 (code=exited, status=0/SUCCESS)
        CPU: 6ms

Jul 29 16:43:19 np0000031958 systemd[1]: Starting lvm2-monitor.service - Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling...
Jul 29 16:43:19 np0000031958 systemd[1]: Finished lvm2-monitor.service - Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling.

○ man-db.service - Daily man-db regeneration
     Loaded: loaded (/usr/lib/systemd/system/man-db.service; static)
     Active: inactive (dead)
TriggeredBy: ● man-db.timer
       Docs: man:mandb(8)

● memcached.service - memcached daemon
     Loaded: loaded (/usr/lib/systemd/system/memcached.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:52:29 UTC; 40min ago
       Docs: man:memcached(1)
   Main PID: 47620 (memcached)
      Tasks: 10 (limit: 9444)
     Memory: 16.3M (peak: 19.3M swap: 3.4M swap peak: 3.6M zswap: 143.5K)
        CPU: 3.430s
     CGroup: /system.slice/memcached.service
             └─47620 /usr/bin/memcached -m 64 -p 11211 -u memcache -l 127.0.0.1 -l ::1 -P /var/run/memcached/memcached.pid

Jul 29 16:52:29 np0000031958 systemd[1]: Started memcached.service - memcached daemon.

○ modprobe@configfs.service - Load Kernel Module configfs
     Loaded: loaded (/usr/lib/systemd/system/modprobe@.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:modprobe(8)
   Main PID: 313 (code=exited, status=0/SUCCESS)
        CPU: 4ms

Notice: journal has been rotated since unit was started, output may be incomplete.

○ modprobe@dm_mod.service - Load Kernel Module dm_mod
     Loaded: loaded (/usr/lib/systemd/system/modprobe@.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:modprobe(8)
   Main PID: 495 (code=exited, status=0/SUCCESS)
        CPU: 2ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting modprobe@dm_mod.service - Load Kernel Module dm_mod...
Jul 29 14:32:52 ubuntu systemd[1]: modprobe@dm_mod.service: Deactivated successfully.
Jul 29 14:32:52 ubuntu systemd[1]: Finished modprobe@dm_mod.service - Load Kernel Module dm_mod.

○ modprobe@drm.service - Load Kernel Module drm
     Loaded: loaded (/usr/lib/systemd/system/modprobe@.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:modprobe(8)
   Main PID: 315 (code=exited, status=0/SUCCESS)
        CPU: 3ms

Notice: journal has been rotated since unit was started, output may be incomplete.

○ modprobe@efi_pstore.service - Load Kernel Module efi_pstore
     Loaded: loaded (/usr/lib/systemd/system/modprobe@.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:modprobe(8)
   Main PID: 496 (code=exited, status=0/SUCCESS)
        CPU: 6ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting modprobe@efi_pstore.service - Load Kernel Module efi_pstore...
Jul 29 14:32:52 ubuntu systemd[1]: modprobe@efi_pstore.service: Deactivated successfully.
Jul 29 14:32:52 ubuntu systemd[1]: Finished modprobe@efi_pstore.service - Load Kernel Module efi_pstore.

○ modprobe@fuse.service - Load Kernel Module fuse
     Loaded: loaded (/usr/lib/systemd/system/modprobe@.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:modprobe(8)
   Main PID: 317 (code=exited, status=0/SUCCESS)
        CPU: 3ms

Jul 29 14:32:52 ubuntu systemd[1]: modprobe@fuse.service: Deactivated successfully.
Jul 29 14:32:52 ubuntu systemd[1]: Finished modprobe@fuse.service - Load Kernel Module fuse.
Notice: journal has been rotated since unit was started, output may be incomplete.

○ modprobe@loop.service - Load Kernel Module loop
     Loaded: loaded (/usr/lib/systemd/system/modprobe@.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:modprobe(8)
   Main PID: 497 (code=exited, status=0/SUCCESS)
        CPU: 4ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting modprobe@loop.service - Load Kernel Module loop...
Jul 29 14:32:52 ubuntu systemd[1]: modprobe@loop.service: Deactivated successfully.
Jul 29 14:32:52 ubuntu systemd[1]: Finished modprobe@loop.service - Load Kernel Module loop.

○ modprobe@nvme_fabrics.service - Load Kernel Module nvme_fabrics
     Loaded: loaded (/usr/lib/systemd/system/modprobe@.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:35:05 UTC; 2h 58min ago
       Docs: man:modprobe(8)
   Main PID: 1535 (code=exited, status=0/SUCCESS)
        CPU: 9ms

Jul 29 14:35:05 np0000031958 systemd[1]: Starting modprobe@nvme_fabrics.service - Load Kernel Module nvme_fabrics...
Jul 29 14:35:05 np0000031958 systemd[1]: modprobe@nvme_fabrics.service: Deactivated successfully.
Jul 29 14:35:05 np0000031958 systemd[1]: Finished modprobe@nvme_fabrics.service - Load Kernel Module nvme_fabrics.

○ motd-news.service - Message of the Day
     Loaded: loaded (/usr/lib/systemd/system/motd-news.service; static)
     Active: inactive (dead) since Tue 2025-07-29 16:43:07 UTC; 50min ago
TriggeredBy: ● motd-news.timer
       Docs: man:update-motd(8)
   Main PID: 9894 (code=exited, status=0/SUCCESS)
        CPU: 803us

Jul 29 16:43:07 np0000031958 systemd[1]: Starting motd-news.service - Message of the Day...
Jul 29 16:43:07 np0000031958 systemd[1]: motd-news.service: Deactivated successfully.
Jul 29 16:43:07 np0000031958 systemd[1]: Finished motd-news.service - Message of the Day.

● multipathd.service - Device-Mapper Multipath Device Controller
     Loaded: loaded (/usr/lib/systemd/system/multipathd.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
TriggeredBy: ● multipathd.socket
   Main PID: 363 (multipathd)
     Status: "up"
      Tasks: 7
     Memory: 24.9M (peak: 25.9M)
        CPU: 2.448s
     CGroup: /system.slice/multipathd.service
             └─363 /sbin/multipathd -d -s

Jul 29 17:32:00 np0000031958 multipathd[363]: 3624a9370730e7fa1d6f242bb001c8a87: map flushed
Jul 29 17:32:00 np0000031958 multipathd[363]: dm-0: devmap not registered, can't remove
Jul 29 17:32:00 np0000031958 multipathd[363]: sdd: remove path (operator)
Jul 29 17:32:00 np0000031958 multipathd[363]: sdd: path already removed
Jul 29 17:32:00 np0000031958 multipathd[363]: sda: remove path (operator)
Jul 29 17:32:00 np0000031958 multipathd[363]: sda: path already removed
Jul 29 17:32:00 np0000031958 multipathd[363]: sdc: remove path (operator)
Jul 29 17:32:00 np0000031958 multipathd[363]: sdc: path already removed
Jul 29 17:32:00 np0000031958 multipathd[363]: sdb: remove path (operator)
Jul 29 17:32:00 np0000031958 multipathd[363]: sdb: path already removed

● mysql.service - MySQL Community Server
     Loaded: loaded (/usr/lib/systemd/system/mysql.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:52:14 UTC; 41min ago
   Main PID: 44158 (mysqld)
     Status: "Server is operational"
      Tasks: 173 (limit: 9444)
     Memory: 469.0M (peak: 902.0M swap: 444.4M swap peak: 449.0M zswap: 50.7M)
        CPU: 2min 42.635s
     CGroup: /system.slice/mysql.service
             └─44158 /usr/sbin/mysqld

Jul 29 16:52:13 np0000031958 systemd[1]: Starting mysql.service - MySQL Community Server...
Jul 29 16:52:14 np0000031958 systemd[1]: Started mysql.service - MySQL Community Server.

● netfilter-persistent.service - netfilter persistent configuration
     Loaded: loaded (/usr/lib/systemd/system/netfilter-persistent.service; enabled; preset: enabled)
    Drop-In: /usr/lib/systemd/system/netfilter-persistent.service.d
             └─iptables.conf
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:netfilter-persistent(8)
   Main PID: 389 (code=exited, status=0/SUCCESS)
        CPU: 17ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting netfilter-persistent.service - netfilter persistent configuration...
Jul 29 14:32:52 ubuntu netfilter-persistent[394]: run-parts: executing /usr/share/netfilter-persistent/plugins.d/15-ip4tables start
Jul 29 14:32:52 ubuntu netfilter-persistent[394]: run-parts: executing /usr/share/netfilter-persistent/plugins.d/25-ip6tables start
Jul 29 14:32:52 ubuntu systemd[1]: Finished netfilter-persistent.service - netfilter persistent configuration.

○ networkd-dispatcher.service - Dispatcher daemon for systemd-networkd
     Loaded: loaded (/usr/lib/systemd/system/networkd-dispatcher.service; enabled; preset: enabled)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:53 UTC; 3h 0min ago

Jul 29 14:32:53 ubuntu systemd[1]: networkd-dispatcher.service - Dispatcher daemon for systemd-networkd was skipped because no trigger condition checks were met.

● networking.service - Raise network interfaces
     Loaded: loaded (/usr/lib/systemd/system/networking.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
       Docs: man:interfaces(5)
   Main PID: 850 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 14:32:55 np0000031958 systemd[1]: Starting networking.service - Raise network interfaces...
Jul 29 14:32:55 np0000031958 systemd[1]: Finished networking.service - Raise network interfaces.

○ nvmefc-boot-connections.service - Auto-connect to subsystems on FC-NVME devices found during boot
     Loaded: loaded (/usr/lib/systemd/system/nvmefc-boot-connections.service; enabled; preset: enabled)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:35:05 UTC; 2h 58min ago

Jul 29 14:35:05 np0000031958 systemd[1]: nvmefc-boot-connections.service - Auto-connect to subsystems on FC-NVME devices found during boot was skipped because of an unmet condition check (ConditionPathExists=/sys/class/fc/fc_udev_device/nvme_discovery).

○ nvmf-autoconnect.service - Connect NVMe-oF subsystems automatically during boot
     Loaded: loaded (/usr/lib/systemd/system/nvmf-autoconnect.service; enabled; preset: enabled)
     Active: inactive (dead) since Tue 2025-07-29 14:35:06 UTC; 2h 58min ago
   Main PID: 1545 (code=exited, status=0/SUCCESS)
        CPU: 4ms

Jul 29 14:35:05 np0000031958 systemd[1]: Starting nvmf-autoconnect.service - Connect NVMe-oF subsystems automatically during boot...
Jul 29 14:35:06 np0000031958 systemd[1]: nvmf-autoconnect.service: Deactivated successfully.
Jul 29 14:35:06 np0000031958 systemd[1]: Finished nvmf-autoconnect.service - Connect NVMe-oF subsystems automatically during boot.

○ open-iscsi.service - Login to default iSCSI targets
     Loaded: loaded (/usr/lib/systemd/system/open-iscsi.service; enabled; preset: enabled)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:iscsiadm(8)
             man:iscsid(8)

Jul 29 14:34:55 np0000031958 systemd[1]: open-iscsi.service - Login to default iSCSI targets was skipped because no trigger condition checks were met.

● openvswitch-switch.service - Open vSwitch
     Loaded: loaded (/usr/lib/systemd/system/openvswitch-switch.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:53:51 UTC; 39min ago
   Main PID: 67098 (code=exited, status=0/SUCCESS)
        CPU: 742us

Jul 29 16:53:51 np0000031958 systemd[1]: Starting openvswitch-switch.service - Open vSwitch...
Jul 29 16:53:51 np0000031958 systemd[1]: Finished openvswitch-switch.service - Open vSwitch.

● ovn-central.service - Open Virtual Network central components
     Loaded: loaded (/usr/lib/systemd/system/ovn-central.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:53:52 UTC; 39min ago
   Main PID: 67405 (code=exited, status=0/SUCCESS)
        CPU: 3ms

Jul 29 16:53:52 np0000031958 systemd[1]: Starting ovn-central.service - Open Virtual Network central components...
Jul 29 16:53:52 np0000031958 systemd[1]: Finished ovn-central.service - Open Virtual Network central components.

● ovn-controller-vtep.service - Open Virtual Network VTEP gateway controller daemon
     Loaded: loaded (/usr/lib/systemd/system/ovn-controller-vtep.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:51 UTC; 39min ago
   Main PID: 67159 (ovn-controller-)
      Tasks: 1 (limit: 9444)
     Memory: 732.0K (peak: 3.2M swap: 180.0K swap peak: 180.0K zswap: 40.2K)
        CPU: 32ms
     CGroup: /system.slice/ovn-controller-vtep.service
             └─67159 ovn-controller-vtep -vconsole:emer -vsyslog:err -vfile:info --vtep-db=/var/run/openvswitch/db.sock --ovnsb-db=/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-controller-vtep.log --pidfile=/var/run/ovn/ovn-controller-vtep.pid --detach

Jul 29 16:53:51 np0000031958 systemd[1]: Starting ovn-controller-vtep.service - Open Virtual Network VTEP gateway controller daemon...
Jul 29 16:53:51 np0000031958 (ovn-ctl)[67116]: ovn-controller-vtep.service: Referenced but unset environment variable evaluates to an empty string: OVN_CTL_OPTS
Jul 29 16:53:51 np0000031958 ovn-ctl[67116]:  * Starting ovn-controller-vtep
Jul 29 16:53:51 np0000031958 systemd[1]: Started ovn-controller-vtep.service - Open Virtual Network VTEP gateway controller daemon.

● ovn-controller.service - Open Virtual Network host control daemon
     Loaded: loaded (/usr/lib/systemd/system/ovn-controller.service; static)
     Active: active (running) since Tue 2025-07-29 16:53:54 UTC; 39min ago
   Main PID: 67808 (ovn-controller)
      Tasks: 5 (limit: 9444)
     Memory: 7.1M (peak: 13.8M swap: 712.0K swap peak: 712.0K zswap: 188.9K)
        CPU: 4.818s
     CGroup: /system.slice/ovn-controller.service
             └─67808 ovn-controller unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --no-chdir --log-file=/var/log/ovn/ovn-controller.log --pidfile=/var/run/ovn/ovn-controller.pid --detach

Jul 29 16:53:54 np0000031958 systemd[1]: Starting ovn-controller.service - Open Virtual Network host control daemon...
Jul 29 16:53:54 np0000031958 (ovn-ctl)[67779]: ovn-controller.service: Referenced but unset environment variable evaluates to an empty string: OVN_CTL_OPTS
Jul 29 16:53:54 np0000031958 ovn-ctl[67779]:  * Starting ovn-controller
Jul 29 16:53:54 np0000031958 systemd[1]: Started ovn-controller.service - Open Virtual Network host control daemon.

● ovn-host.service - Open Virtual Network host components
     Loaded: loaded (/usr/lib/systemd/system/ovn-host.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:46:32 UTC; 46min ago
   Main PID: 31881 (code=exited, status=0/SUCCESS)
        CPU: 3ms

Jul 29 16:46:32 np0000031958 systemd[1]: Starting ovn-host.service - Open Virtual Network host components...
Jul 29 16:46:32 np0000031958 systemd[1]: Finished ovn-host.service - Open Virtual Network host components.

● ovn-northd.service - Open Virtual Network central control daemon
     Loaded: loaded (/usr/lib/systemd/system/ovn-northd.service; static)
     Active: active (running) since Tue 2025-07-29 16:53:52 UTC; 39min ago
   Main PID: 67551 (ovn-northd)
      Tasks: 3 (limit: 9444)
     Memory: 4.8M (peak: 6.8M swap: 28.0K swap peak: 28.0K zswap: 6.8K)
        CPU: 7.839s
     CGroup: /system.slice/ovn-northd.service
             └─67551 ovn-northd -vconsole:emer -vsyslog:err -vfile:info --ovnnb-db=unix:/var/run/ovn/ovnnb_db.sock --ovnsb-db=unix:/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-northd.log --pidfile=/var/run/ovn/ovn-northd.pid --detach

Jul 29 16:53:52 np0000031958 systemd[1]: Starting ovn-northd.service - Open Virtual Network central control daemon...
Jul 29 16:53:52 np0000031958 (ovn-ctl)[67483]: ovn-northd.service: Referenced but unset environment variable evaluates to an empty string: OVN_CTL_OPTS
Jul 29 16:53:52 np0000031958 ovn-ctl[67483]:  * Starting ovn-northd
Jul 29 16:53:52 np0000031958 systemd[1]: Started ovn-northd.service - Open Virtual Network central control daemon.

● ovn-ovsdb-server-nb.service - Open vSwitch database server for OVN Northbound database
     Loaded: loaded (/usr/lib/systemd/system/ovn-ovsdb-server-nb.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:52 UTC; 39min ago
   Main PID: 67478 (ovsdb-server)
      Tasks: 1 (limit: 9444)
     Memory: 16.3M (peak: 16.8M)
        CPU: 5.543s
     CGroup: /system.slice/ovn-ovsdb-server-nb.service
             └─67478 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-nb.log --remote=punix:/var/run/ovn/ovnnb_db.sock --pidfile=/var/run/ovn/ovnnb_db.pid --unixctl=/var/run/ovn/ovnnb_db.ctl --remote=db:OVN_Northbound,NB_Global,connections --private-key=db:OVN_Northbound,SSL,private_key --certificate=db:OVN_Northbound,SSL,certificate --ca-cert=db:OVN_Northbound,SSL,ca_cert --ssl-protocols=db:OVN_Northbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Northbound,SSL,ssl_ciphers /var/lib/ovn/ovnnb_db.db

Jul 29 17:33:00 np0000031958 ovsdb-server[67478]: ovs|73522|stream_ssl|DBG|server7<--ssl:192.168.1.104:41272 type 257 (1 bytes)
Jul 29 17:33:00 np0000031958 ovsdb-server[67478]: ovs|73523|jsonrpc|DBG|ssl:192.168.1.104:41272: received reply, result=[], id="echo"
Jul 29 17:33:00 np0000031958 ovsdb-server[67478]: ovs|73524|reconnect|DBG|ssl:192.168.1.104:41272: entering ACTIVE
Jul 29 17:33:00 np0000031958 ovsdb-server[67478]: ovs|73525|poll_loop|DBG|wakeup due to 0-ms timeout at ../lib/stream-ssl.c:844
Jul 29 17:33:02 np0000031958 ovsdb-server[67478]: ovs|73526|poll_loop|DBG|wakeup due to 1902-ms timeout at ../ovsdb/ovsdb-server.c:400
Jul 29 17:33:05 np0000031958 ovsdb-server[67478]: ovs|73527|poll_loop|DBG|wakeup due to 2503-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)
Jul 29 17:33:07 np0000031958 ovsdb-server[67478]: ovs|73528|poll_loop|DBG|wakeup due to 2510-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)
Jul 29 17:33:10 np0000031958 ovsdb-server[67478]: ovs|73529|poll_loop|DBG|wakeup due to 2503-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)
Jul 29 17:33:12 np0000031958 ovsdb-server[67478]: ovs|73530|poll_loop|DBG|wakeup due to 2511-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)
Jul 29 17:33:15 np0000031958 ovsdb-server[67478]: ovs|73531|poll_loop|DBG|wakeup due to 2502-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)

● ovn-ovsdb-server-sb.service - Open vSwitch database server for OVN Southbound database
     Loaded: loaded (/usr/lib/systemd/system/ovn-ovsdb-server-sb.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:53:52 UTC; 39min ago
   Main PID: 67479 (ovsdb-server)
      Tasks: 1 (limit: 9444)
     Memory: 27.4M (peak: 27.9M)
        CPU: 5.668s
     CGroup: /system.slice/ovn-ovsdb-server-sb.service
             └─67479 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-sb.log --remote=punix:/var/run/ovn/ovnsb_db.sock --pidfile=/var/run/ovn/ovnsb_db.pid --unixctl=/var/run/ovn/ovnsb_db.ctl --remote=db:OVN_Southbound,SB_Global,connections --private-key=db:OVN_Southbound,SSL,private_key --certificate=db:OVN_Southbound,SSL,certificate --ca-cert=db:OVN_Southbound,SSL,ca_cert --ssl-protocols=db:OVN_Southbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Southbound,SSL,ssl_ciphers /var/lib/ovn/ovnsb_db.db

Jul 29 17:33:12 np0000031958 ovsdb-server[67479]: ovs|70239|poll_loop|DBG|wakeup due to 2512-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70240|poll_loop|DBG|wakeup due to [POLLIN] on fd 22 (192.168.1.104:6642<->192.168.1.104:36552) at ../lib/stream-ssl.c:842 (0% CPU usage)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70241|stream_ssl|DBG|server0<--ssl:192.168.1.104:36552 type 256 (5 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70242|stream_ssl|DBG|server0<--ssl:192.168.1.104:36552 type 257 (1 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70243|jsonrpc|DBG|ssl:192.168.1.104:36552: received request, method="echo", params=[], id="echo"
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70244|jsonrpc|DBG|ssl:192.168.1.104:36552: send reply, result=[], id="echo"
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70245|stream_ssl|DBG|server0-->ssl:192.168.1.104:36552 type 256 (5 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70246|stream_ssl|DBG|server0-->ssl:192.168.1.104:36552 type 257 (1 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70247|poll_loop|DBG|wakeup due to 0-ms timeout at ../lib/stream-ssl.c:844 (0% CPU usage)
Jul 29 17:33:15 np0000031958 ovsdb-server[67479]: ovs|70248|poll_loop|DBG|wakeup due to 2028-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)

● ovs-record-hostname.service - Open vSwitch Record Hostname
     Loaded: loaded (/usr/lib/systemd/system/ovs-record-hostname.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:53:51 UTC; 39min ago
   Main PID: 67112 (code=exited, status=0/SUCCESS)
        CPU: 13ms

Jul 29 16:53:51 np0000031958 systemd[1]: Starting ovs-record-hostname.service - Open vSwitch Record Hostname...
Jul 29 16:53:51 np0000031958 ovs-vsctl[67139]: ovs|00001|vsctl|INFO|Called as ovs-vsctl --no-wait add Open_vSwitch . external-ids hostname=localhost
Jul 29 16:53:51 np0000031958 systemd[1]: Finished ovs-record-hostname.service - Open vSwitch Record Hostname.

● ovs-vswitchd.service - Open vSwitch Forwarding Unit
     Loaded: loaded (/usr/lib/systemd/system/ovs-vswitchd.service; static)
     Active: active (running) since Tue 2025-07-29 16:53:51 UTC; 39min ago
   Main PID: 67077 (ovs-vswitchd)
      Tasks: 13 (limit: 9444)
     Memory: 106.1M (peak: 106.7M)
        CPU: 14.003s
     CGroup: /system.slice/ovs-vswitchd.service
             └─67077 ovs-vswitchd unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --mlockall --no-chdir --log-file=/var/log/openvswitch/ovs-vswitchd.log --pidfile=/var/run/openvswitch/ovs-vswitchd.pid --detach

Jul 29 16:53:51 np0000031958 systemd[1]: Starting ovs-vswitchd.service - Open vSwitch Forwarding Unit...
Jul 29 16:53:51 np0000031958 (ovs-ctl)[67039]: ovs-vswitchd.service: Referenced but unset environment variable evaluates to an empty string: OVS_CTL_OPTS
Jul 29 16:53:51 np0000031958 ovs-ctl[67039]:  * Starting ovs-vswitchd
Jul 29 16:53:51 np0000031958 ovs-ctl[67039]:  * Enabling remote OVSDB managers
Jul 29 16:53:51 np0000031958 systemd[1]: Started ovs-vswitchd.service - Open vSwitch Forwarding Unit.

● ovsdb-server.service - Open vSwitch Database Unit
     Loaded: loaded (/usr/lib/systemd/system/ovsdb-server.service; static)
     Active: active (running) since Tue 2025-07-29 16:53:51 UTC; 39min ago
   Main PID: 66880 (ovsdb-server)
      Tasks: 1 (limit: 9444)
     Memory: 2.3M (peak: 5.7M swap: 772.0K swap peak: 772.0K zswap: 228.8K)
        CPU: 4.677s
     CGroup: /system.slice/ovsdb-server.service
             └─66880 ovsdb-server /etc/openvswitch/conf.db -vconsole:emer -vsyslog:err -vfile:info --remote=punix:/var/run/openvswitch/db.sock --private-key=db:Open_vSwitch,SSL,private_key --certificate=db:Open_vSwitch,SSL,certificate --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert --no-chdir --log-file=/var/log/openvswitch/ovsdb-server.log --pidfile=/var/run/openvswitch/ovsdb-server.pid --detach

Jul 29 16:53:51 np0000031958 systemd[1]: Starting ovsdb-server.service - Open vSwitch Database Unit...
Jul 29 16:53:51 np0000031958 (ovs-ctl)[66846]: ovsdb-server.service: Referenced but unset environment variable evaluates to an empty string: OVS_CTL_OPTS
Jul 29 16:53:51 np0000031958 ovs-ctl[66846]:  * Starting ovsdb-server
Jul 29 16:53:51 np0000031958 ovs-vsctl[66881]: ovs|00001|vsctl|INFO|Called as ovs-vsctl --no-wait -- init -- set Open_vSwitch . db-version=8.5.0
Jul 29 16:53:51 np0000031958 ovs-vsctl[66886]: ovs|00001|vsctl|INFO|Called as ovs-vsctl --no-wait set Open_vSwitch . ovs-version=3.3.0 "external-ids:system-id=\"e85adeac-1b6d-431c-aac7-bc8b30a63079\"" "external-ids:rundir=\"/var/run/openvswitch\"" "system-type=\"ubuntu\"" "system-version=\"24.04\""
Jul 29 16:53:51 np0000031958 ovs-ctl[66846]:  * Configuring Open vSwitch system IDs
Jul 29 16:53:51 np0000031958 ovs-ctl[66846]:  * Enabling remote OVSDB managers
Jul 29 16:53:51 np0000031958 systemd[1]: Started ovsdb-server.service - Open vSwitch Database Unit.

● polkit.service - Authorization Manager
     Loaded: loaded (/usr/lib/systemd/system/polkit.service; static)
     Active: active (running) since Tue 2025-07-29 14:35:00 UTC; 2h 58min ago
       Docs: man:polkit(8)
   Main PID: 1336 (polkitd)
      Tasks: 4 (limit: 9444)
     Memory: 1.8M (peak: 2.9M)
        CPU: 230ms
     CGroup: /system.slice/polkit.service
             └─1336 /usr/lib/polkit-1/polkitd --no-debug

Jul 29 16:51:21 np0000031958 polkitd[1336]: Reloading rules
Jul 29 16:51:21 np0000031958 polkitd[1336]: Collecting garbage unconditionally...
Jul 29 16:51:21 np0000031958 polkitd[1336]: Loading rules from directory /etc/polkit-1/rules.d
Jul 29 16:51:21 np0000031958 polkitd[1336]: Loading rules from directory /usr/share/polkit-1/rules.d
Jul 29 16:51:21 np0000031958 polkitd[1336]: Finished loading, compiling and executing 5 rules
Jul 29 16:51:21 np0000031958 polkitd[1336]: Reloading rules
Jul 29 16:51:21 np0000031958 polkitd[1336]: Collecting garbage unconditionally...
Jul 29 16:51:21 np0000031958 polkitd[1336]: Loading rules from directory /etc/polkit-1/rules.d
Jul 29 16:51:21 np0000031958 polkitd[1336]: Loading rules from directory /usr/share/polkit-1/rules.d
Jul 29 16:51:21 np0000031958 polkitd[1336]: Finished loading, compiling and executing 5 rules

● postgresql.service - PostgreSQL RDBMS
     Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:43:12 UTC; 50min ago
   Main PID: 11549 (code=exited, status=0/SUCCESS)
        CPU: 709us

Jul 29 16:43:12 np0000031958 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...
Jul 29 16:43:12 np0000031958 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.

● pure-boot.service - Run Pure scripts after network is reachable
     Loaded: loaded (/etc/systemd/system/pure-boot.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
   Main PID: 1091 (code=exited, status=0/SUCCESS)
      Tasks: 1 (limit: 9444)
     Memory: 17.7M (peak: 350.6M swap: 272.0K swap peak: 272.0K zswap: 18.5K)
        CPU: 4.897s
     CGroup: /system.slice/pure-boot.service
             └─988 dhclient

Jul 29 14:35:06 np0000031958 on-boot.sh[1091]: NVME TCP VM: loading nvme-tcp module
Jul 29 14:35:06 np0000031958 on-boot.sh[1091]: + sudo modprobe nvme-tcp
Jul 29 14:35:06 np0000031958 sudo[1563]:     root : PWD=/ ; USER=root ; COMMAND=/usr/sbin/modprobe nvme-tcp
Jul 29 14:35:06 np0000031958 sudo[1563]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jul 29 14:35:06 np0000031958 sudo[1563]: pam_unix(sudo:session): session closed for user root
Jul 29 14:35:06 np0000031958 on-boot.sh[1091]: + '[' false = true ']'
Jul 29 14:35:06 np0000031958 on-boot.sh[1091]: + sudo systemctl start multipathd
Jul 29 14:35:06 np0000031958 sudo[1566]:     root : PWD=/ ; USER=root ; COMMAND=/usr/bin/systemctl start multipathd
Jul 29 14:35:06 np0000031958 sudo[1566]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jul 29 14:35:06 np0000031958 sudo[1566]: pam_unix(sudo:session): session closed for user root

● qemu-kvm.service - QEMU KVM preparation - module, ksm, hugepages
     Loaded: loaded (/usr/lib/systemd/system/qemu-kvm.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:51:25 UTC; 41min ago
   Main PID: 33638 (code=exited, status=0/SUCCESS)
        CPU: 8ms

Jul 29 16:51:25 np0000031958 systemd[1]: Starting qemu-kvm.service - QEMU KVM preparation - module, ksm, hugepages...
Jul 29 16:51:25 np0000031958 systemd[1]: Finished qemu-kvm.service - QEMU KVM preparation - module, ksm, hugepages.

● rabbitmq-server.service - RabbitMQ Messaging Server
     Loaded: loaded (/usr/lib/systemd/system/rabbitmq-server.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:43:59 UTC; 49min ago
   Main PID: 17789 (beam.smp)
      Tasks: 36 (limit: 9444)
     Memory: 64.1M (peak: 140.8M swap: 83.2M swap peak: 83.4M zswap: 26.1M)
        CPU: 25.187s
     CGroup: /system.slice/rabbitmq-server.service
             ├─17789 /usr/lib/erlang/erts-13.2.2.5/bin/beam.smp -W w -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -pc unicode -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -sbwt none -sbwtdcpu none -sbwtdio none -- -root /usr/lib/erlang -bindir /usr/lib/erlang/erts-13.2.2.5/bin -progname erl -- -home /var/lib/rabbitmq -- -pa "" -noshell -noinput -s rabbit boot -boot start_sasl -syslog logger "[]" -syslog syslog_error_logger false -kernel prevent_overlapping_partitions false -enable-feature maybe_expr
             ├─17799 erl_child_setup 65536
             ├─17875 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
             ├─17876 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
             └─17879 /bin/sh -s rabbit_disk_monitor

Jul 29 16:43:56 np0000031958 systemd[1]: Starting rabbitmq-server.service - RabbitMQ Messaging Server...
Jul 29 16:43:59 np0000031958 systemd[1]: Started rabbitmq-server.service - RabbitMQ Messaging Server.

● rc-local.service - /etc/rc.local Compatibility
     Loaded: loaded (/usr/lib/systemd/system/rc-local.service; enabled-runtime; preset: enabled)
    Drop-In: /usr/lib/systemd/system/rc-local.service.d
             └─debian.conf
     Active: active (exited) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd-rc-local-generator(8)
        CPU: 6ms

Jul 29 14:34:55 np0000031958 systemd[1]: Starting rc-local.service - /etc/rc.local Compatibility...
Jul 29 14:34:55 np0000031958 rc.local[983]: + set +e
Jul 29 14:34:55 np0000031958 rc.local[983]: + sed -i -e 's/^\(DNS[0-9]*=[.0-9]\+\)/#\1/g' '/etc/sysconfig/network-scripts/ifcfg-*'
Jul 29 14:34:55 np0000031958 rc.local[990]: sed: can't read /etc/sysconfig/network-scripts/ifcfg-*: No such file or directory
Jul 29 14:34:55 np0000031958 rc.local[983]: + sed -i -e 's/^NETCONFIG_DNS_POLICY=.*/NETCONFIG_DNS_POLICY=""/g' /etc/sysconfig/network/config
Jul 29 14:34:55 np0000031958 rc.local[992]: sed: can't read /etc/sysconfig/network/config: No such file or directory
Jul 29 14:34:55 np0000031958 systemd[1]: Started rc-local.service - /etc/rc.local Compatibility.
Jul 29 14:34:55 np0000031958 rc.local[983]: + set -e
Jul 29 14:34:55 np0000031958 rc.local[983]: + echo 'nameserver 8.8.8.8'
Jul 29 14:34:55 np0000031958 rc.local[983]: + exit 0

○ rescue.service - Rescue Shell
     Loaded: loaded (/usr/lib/systemd/system/rescue.service; static)
     Active: inactive (dead)
       Docs: man:sulogin(8)

● rsyslog.service - System Logging Service
     Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:43:26 UTC; 49min ago
TriggeredBy: ● syslog.socket
       Docs: man:rsyslogd(8)
             man:rsyslog.conf(5)
             https://www.rsyslog.com/doc/
   Main PID: 15219 (rsyslogd)
      Tasks: 4 (limit: 9444)
     Memory: 74.5M (peak: 74.8M)
        CPU: 10.681s
     CGroup: /system.slice/rsyslog.service
             └─15219 /usr/sbin/rsyslogd -n -iNONE

Jul 29 16:43:26 np0000031958 systemd[1]: Starting rsyslog.service - System Logging Service...
Jul 29 16:43:26 np0000031958 rsyslogd[15219]: imuxsock: Acquired UNIX socket '/run/systemd/journal/syslog' (fd 3) from systemd.  [v8.2312.0]
Jul 29 16:43:26 np0000031958 rsyslogd[15219]: rsyslogd's groupid changed to 104
Jul 29 16:43:26 np0000031958 systemd[1]: Started rsyslog.service - System Logging Service.
Jul 29 16:43:26 np0000031958 rsyslogd[15219]: rsyslogd's userid changed to 104
Jul 29 16:43:26 np0000031958 rsyslogd[15219]: [origin software="rsyslogd" swVersion="8.2312.0" x-pid="15219" x-info="https://www.rsyslog.com"] start

● rtslib-fb-targetctl.service - Restore LIO kernel target configuration
     Loaded: loaded (/usr/lib/systemd/system/rtslib-fb-targetctl.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:46:01 UTC; 47min ago
   Main PID: 27755 (code=exited, status=0/SUCCESS)
        CPU: 61ms

Jul 29 16:46:01 np0000031958 systemd[1]: Starting rtslib-fb-targetctl.service - Restore LIO kernel target configuration...
Jul 29 16:46:01 np0000031958 target[27755]: No saved config file at /etc/rtslib-fb-target/saveconfig.json, ok, exiting
Jul 29 16:46:01 np0000031958 systemd[1]: Finished rtslib-fb-targetctl.service - Restore LIO kernel target configuration.

● serial-getty@ttyS0.service - Serial Getty on ttyS0
     Loaded: loaded (/usr/lib/systemd/system/serial-getty@.service; enabled-runtime; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:agetty(8)
             man:systemd-getty-generator(8)
             https://0pointer.de/blog/projects/serial-console.html
   Main PID: 1016 (agetty)
      Tasks: 1 (limit: 9444)
     Memory: 236.0K (peak: 1.8M)
        CPU: 4ms
     CGroup: /system.slice/system-serial\x2dgetty.slice/serial-getty@ttyS0.service
             └─1016 /sbin/agetty -o "-p -- \\u" --keep-baud 115200,57600,38400,9600 - vt220

Jul 29 14:34:55 np0000031958 systemd[1]: Started serial-getty@ttyS0.service - Serial Getty on ttyS0.

● ssh-keygen.service - OpenSSH Server Key Generation
     Loaded: loaded (/usr/lib/systemd/system/ssh-keygen.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Main PID: 530 (code=exited, status=0/SUCCESS)
        CPU: 337ms

Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: |        o   . * o|
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: |         o o + o+|
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: |      o S = . +.=|
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: |     o o o o.o.+.|
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: |      . o .+Eo .o|
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: |       + +o.o.. +|
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: |        + ++.  ++|
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[598]: +----[SHA256]-----+
Jul 29 14:32:53 np0000031958 runtime-ssh-host-keys.sh[597]: /usr/bin/yes: standard output: Broken pipe
Jul 29 14:32:53 np0000031958 systemd[1]: Finished ssh-keygen.service - OpenSSH Server Key Generation.

● ssh.service - OpenBSD Secure Shell server
     Loaded: loaded (/usr/lib/systemd/system/ssh.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
TriggeredBy: ● ssh.socket
       Docs: man:sshd(8)
             man:sshd_config(5)
   Main PID: 860 (sshd)
      Tasks: 1 (limit: 9444)
     Memory: 4.2M (peak: 13.4M)
        CPU: 232ms
     CGroup: /system.slice/ssh.service
             └─860 "sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups"

Jul 29 16:39:46 np0000031958 sshd[1944]: Accepted publickey for zuul from 192.168.1.141 port 40680 ssh2: RSA SHA256:UilYVuW3m4ivJpmHhdrPrsY6ATAJ1yin97smnZVtxEQ
Jul 29 16:39:46 np0000031958 sshd[1944]: pam_unix(sshd:session): session opened for user zuul(uid=1000) by zuul(uid=0)
Jul 29 16:40:28 np0000031958 sshd[2370]: Accepted publickey for zuul from 192.168.1.141 port 52186 ssh2: RSA SHA256:UilYVuW3m4ivJpmHhdrPrsY6ATAJ1yin97smnZVtxEQ
Jul 29 16:40:28 np0000031958 sshd[2370]: pam_unix(sshd:session): session opened for user zuul(uid=1000) by zuul(uid=0)
Jul 29 16:42:21 np0000031958 sshd[2798]: Accepted publickey for zuul from 192.168.1.141 port 56112 ssh2: RSA SHA256:UilYVuW3m4ivJpmHhdrPrsY6ATAJ1yin97smnZVtxEQ
Jul 29 16:42:21 np0000031958 sshd[2798]: pam_unix(sshd:session): session opened for user zuul(uid=1000) by zuul(uid=0)
Jul 29 17:32:20 np0000031958 sshd[132091]: Accepted publickey for zuul from 192.168.1.141 port 35068 ssh2: RSA SHA256:UilYVuW3m4ivJpmHhdrPrsY6ATAJ1yin97smnZVtxEQ
Jul 29 17:32:20 np0000031958 sshd[132091]: pam_unix(sshd:session): session opened for user zuul(uid=1000) by zuul(uid=0)
Jul 29 17:32:47 np0000031958 sshd[132488]: Accepted publickey for zuul from 192.168.1.141 port 52162 ssh2: RSA SHA256:UilYVuW3m4ivJpmHhdrPrsY6ATAJ1yin97smnZVtxEQ
Jul 29 17:32:47 np0000031958 sshd[132488]: pam_unix(sshd:session): session opened for user zuul(uid=1000) by zuul(uid=0)

○ ssl-cert.service - Generate snakeoil SSL keypair
     Loaded: loaded (/usr/lib/systemd/system/ssl-cert.service; enabled; preset: enabled)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 16:43:10 UTC; 50min ago

Jul 29 16:43:10 np0000031958 systemd[1]: ssl-cert.service - Generate snakeoil SSL keypair was skipped because of an unmet condition check (ConditionPathExists=!/etc/ssl/private/ssl-cert-snakeoil.key).

● sysfsutils.service - Apply sysfs variables
     Loaded: loaded (/usr/lib/systemd/system/sysfsutils.service; enabled; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 16:43:07 UTC; 50min ago
       Docs: man:sysfs.conf(5)
             man:systool(1)
   Main PID: 10009 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 16:43:07 np0000031958 systemd[1]: Starting sysfsutils.service - Apply sysfs variables...
Jul 29 16:43:07 np0000031958 sysfsutils[10009]:  * Setting sysfs variables......
Jul 29 16:43:07 np0000031958 sysfsutils[10009]:    ...done.
Jul 29 16:43:07 np0000031958 systemd[1]: Finished sysfsutils.service - Apply sysfs variables.

○ systemd-ask-password-console.service - Dispatch Password Requests to Console
     Loaded: loaded (/usr/lib/systemd/system/systemd-ask-password-console.service; static)
     Active: inactive (dead)
TriggeredBy: ● systemd-ask-password-console.path
       Docs: man:systemd-ask-password-console.service(8)

○ systemd-ask-password-wall.service - Forward Password Requests to Wall
     Loaded: loaded (/usr/lib/systemd/system/systemd-ask-password-wall.service; static)
     Active: inactive (dead)
TriggeredBy: ● systemd-ask-password-wall.path
       Docs: man:systemd-ask-password-wall.service(8)

○ systemd-battery-check.service - Check battery level during early boot
     Loaded: loaded (/usr/lib/systemd/system/systemd-battery-check.service; static)
     Active: inactive (dead)
       Docs: man:systemd-battery-check.service(8)

● systemd-binfmt.service - Set Up Additional Binary Formats
     Loaded: loaded (/usr/lib/systemd/system/systemd-binfmt.service; static)
     Active: active (exited) since Tue 2025-07-29 16:43:26 UTC; 49min ago
       Docs: man:systemd-binfmt.service(8)
             man:binfmt.d(5)
             https://docs.kernel.org/admin-guide/binfmt-misc.html
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
   Main PID: 15227 (code=exited, status=0/SUCCESS)
        CPU: 4ms

Jul 29 16:43:26 np0000031958 systemd[1]: Starting systemd-binfmt.service - Set Up Additional Binary Formats...
Jul 29 16:43:26 np0000031958 systemd[1]: Finished systemd-binfmt.service - Set Up Additional Binary Formats.

○ systemd-bsod.service - Displays emergency message in full screen.
     Loaded: loaded (/usr/lib/systemd/system/systemd-bsod.service; static)
     Active: inactive (dead)
       Docs: man:systemd-bsod.service(8)

● systemd-firstboot.service - First Boot Wizard
     Loaded: loaded (/usr/lib/systemd/system/systemd-firstboot.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-firstboot(1)
   Main PID: 404 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-firstboot.service - First Boot Wizard...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-firstboot.service - First Boot Wizard.

● systemd-fsck-root.service - File System Check on Root Device
     Loaded: loaded (/usr/lib/systemd/system/systemd-fsck-root.service; enabled-runtime; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-fsck-root.service(8)
   Main PID: 319 (code=exited, status=0/SUCCESS)
        CPU: 10ms

Jul 29 14:32:52 ubuntu systemd-fsck[323]: cloudimg-rootfs: clean, 684580/4980736 files, 3394162/4980528 blocks
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-fsck-root.service - File System Check on Root Device.

○ systemd-fsckd.service - File System Check Daemon to report status
     Loaded: loaded (/usr/lib/systemd/system/systemd-fsckd.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:33:22 UTC; 2h 59min ago
   Duration: 30.039s
TriggeredBy: ● systemd-fsckd.socket
       Docs: man:systemd-fsckd.service(8)
   Main PID: 345 (code=exited, status=0/SUCCESS)
        CPU: 8ms

Jul 29 14:32:52 ubuntu systemd[1]: Started systemd-fsckd.service - File System Check Daemon to report status.
Jul 29 14:33:22 np0000031958 systemd[1]: systemd-fsckd.service: Deactivated successfully.

○ systemd-hibernate-resume.service - Resume from hibernation
     Loaded: loaded (/usr/lib/systemd/system/systemd-hibernate-resume.service; static)
     Active: inactive (dead)
       Docs: man:systemd-hibernate-resume.service(8)

○ systemd-hibernate.service - System Hibernate
     Loaded: loaded (/usr/lib/systemd/system/systemd-hibernate.service; static)
     Active: inactive (dead)
       Docs: man:systemd-hibernate.service(8)

○ systemd-hwdb-update.service - Rebuild Hardware Database
     Loaded: loaded (/usr/lib/systemd/system/systemd-hwdb-update.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:hwdb(7)
             man:systemd-hwdb(8)

Jul 29 14:32:52 ubuntu systemd[1]: systemd-hwdb-update.service - Rebuild Hardware Database was skipped because no trigger condition checks were met.
Jul 29 14:32:52 ubuntu systemd[1]: systemd-hwdb-update.service - Rebuild Hardware Database was skipped because no trigger condition checks were met.
Jul 29 14:32:52 ubuntu systemd[1]: systemd-hwdb-update.service - Rebuild Hardware Database was skipped because no trigger condition checks were met.

○ systemd-hybrid-sleep.service - System Hybrid Suspend+Hibernate
     Loaded: loaded (/usr/lib/systemd/system/systemd-hybrid-sleep.service; static)
     Active: inactive (dead)
       Docs: man:systemd-hybrid-sleep.service(8)

○ systemd-initctl.service - initctl Compatibility Daemon
     Loaded: loaded (/usr/lib/systemd/system/systemd-initctl.service; static)
     Active: inactive (dead)
TriggeredBy: ● systemd-initctl.socket
       Docs: man:systemd-initctl.service(8)

● systemd-journal-catalog-update.service - Rebuild Journal Catalog
     Loaded: loaded (/usr/lib/systemd/system/systemd-journal-catalog-update.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-journald.service(8)
             man:journald.conf(5)
   Main PID: 405 (code=exited, status=0/SUCCESS)
        CPU: 16ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-journal-catalog-update.service - Rebuild Journal Catalog...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-journal-catalog-update.service - Rebuild Journal Catalog.

● systemd-journal-flush.service - Flush Journal to Persistent Storage
     Loaded: loaded (/usr/lib/systemd/system/systemd-journal-flush.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-journald.service(8)
             man:journald.conf(5)
   Main PID: 360 (code=exited, status=0/SUCCESS)
        CPU: 5ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-journal-flush.service - Flush Journal to Persistent Storage...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-journal-flush.service - Flush Journal to Persistent Storage.

● systemd-journald.service - Journal Service
     Loaded: loaded (/usr/lib/systemd/system/systemd-journald.service; static)
    Drop-In: /usr/lib/systemd/system/systemd-journald.service.d
             └─nice.conf
     Active: active (running) since Tue 2025-07-29 16:43:35 UTC; 49min ago
TriggeredBy: ● systemd-journald.socket
             ○ systemd-journald-audit.socket
             ● systemd-journald-dev-log.socket
       Docs: man:systemd-journald.service(8)
             man:journald.conf(5)
   Main PID: 16765 (systemd-journal)
     Status: "Processing requests..."
      Tasks: 1 (limit: 9444)
   FD Store: 44 (limit: 4224)
     Memory: 268.1M (peak: 268.4M swap: 1.3M swap peak: 1.3M zswap: 310.0K)
        CPU: 26.836s
     CGroup: /system.slice/systemd-journald.service
             └─16765 /usr/lib/systemd/systemd-journald

Jul 29 16:43:35 np0000031958 systemd-journald[16765]: Collecting audit messages is disabled.
Jul 29 16:43:35 np0000031958 systemd-journald[16765]: Journal started
Jul 29 16:43:35 np0000031958 systemd-journald[16765]: System Journal (/var/log/journal/6ed2f04a9973481a94636b333c6df2ea) is 24.0M, max 4.0G, 3.9G free.

● systemd-logind.service - User Login Management
     Loaded: loaded (/usr/lib/systemd/system/systemd-logind.service; static)
    Drop-In: /usr/lib/systemd/system/systemd-logind.service.d
             └─dbus.conf
     Active: active (running) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:sd-login(3)
             man:systemd-logind.service(8)
             man:logind.conf(5)
             man:org.freedesktop.login1(5)
   Main PID: 531 (systemd-logind)
     Status: "Processing requests..."
      Tasks: 1 (limit: 9444)
   FD Store: 0 (limit: 512)
     Memory: 2.4M (peak: 2.7M swap: 12.0K swap peak: 12.0K zswap: 853B)
        CPU: 1.022s
     CGroup: /system.slice/systemd-logind.service
             └─531 /usr/lib/systemd/systemd-logind

Jul 29 16:40:28 np0000031958 systemd-logind[531]: New session 8 of user zuul.
Jul 29 16:42:20 np0000031958 systemd-logind[531]: Session 8 logged out. Waiting for processes to exit.
Jul 29 16:42:20 np0000031958 systemd-logind[531]: Removed session 8.
Jul 29 16:42:21 np0000031958 systemd-logind[531]: New session 9 of user zuul.
Jul 29 17:32:19 np0000031958 systemd-logind[531]: Session 9 logged out. Waiting for processes to exit.
Jul 29 17:32:19 np0000031958 systemd-logind[531]: Removed session 9.
Jul 29 17:32:20 np0000031958 systemd-logind[531]: New session 11 of user zuul.
Jul 29 17:32:47 np0000031958 systemd-logind[531]: Session 11 logged out. Waiting for processes to exit.
Jul 29 17:32:47 np0000031958 systemd-logind[531]: Removed session 11.
Jul 29 17:32:47 np0000031958 systemd-logind[531]: New session 12 of user zuul.

● systemd-machine-id-commit.service - Commit a transient machine-id on disk
     Loaded: loaded (/usr/lib/systemd/system/systemd-machine-id-commit.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-machine-id-commit.service(8)
   Main PID: 444 (code=exited, status=0/SUCCESS)
        CPU: 3ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-machine-id-commit.service - Commit a transient machine-id on disk...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-machine-id-commit.service - Commit a transient machine-id on disk.

● systemd-machined.service - Virtual Machine and Container Registration Service
     Loaded: loaded (/usr/lib/systemd/system/systemd-machined.service; static)
     Active: active (running) since Tue 2025-07-29 16:51:26 UTC; 41min ago
       Docs: man:systemd-machined.service(8)
             man:org.freedesktop.machine1(5)
   Main PID: 33939 (systemd-machine)
     Status: "Processing requests..."
      Tasks: 1 (limit: 9444)
     Memory: 856.0K (peak: 1.8M swap: 704.0K swap peak: 708.0K zswap: 186.3K)
        CPU: 704ms
     CGroup: /system.slice/systemd-machined.service
             └─33939 /usr/lib/systemd/systemd-machined

Jul 29 17:26:05 np0000031958 systemd-machined[33939]: New machine qemu-77-instance-00000035.
Jul 29 17:27:27 np0000031958 systemd-machined[33939]: New machine qemu-78-instance-00000036.
Jul 29 17:28:43 np0000031958 systemd-machined[33939]: Machine qemu-78-instance-00000036 terminated.
Jul 29 17:28:53 np0000031958 systemd-machined[33939]: Machine qemu-77-instance-00000035 terminated.
Jul 29 17:29:24 np0000031958 systemd-machined[33939]: New machine qemu-79-instance-00000037.
Jul 29 17:30:08 np0000031958 systemd-machined[33939]: New machine qemu-80-instance-00000038.
Jul 29 17:31:02 np0000031958 systemd-machined[33939]: New machine qemu-81-instance-00000039.
Jul 29 17:31:42 np0000031958 systemd-machined[33939]: Machine qemu-81-instance-00000039 terminated.
Jul 29 17:31:51 np0000031958 systemd-machined[33939]: Machine qemu-80-instance-00000038 terminated.
Jul 29 17:32:00 np0000031958 systemd-machined[33939]: Machine qemu-79-instance-00000037 terminated.

● systemd-modules-load.service - Load Kernel Modules
     Loaded: loaded (/usr/lib/systemd/system/systemd-modules-load.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-modules-load.service(8)
             man:modules-load.d(5)
   Main PID: 320 (code=exited, status=0/SUCCESS)
        CPU: 21ms

Jul 29 14:32:52 ubuntu systemd-modules-load[320]: Inserted module '8021q'
Jul 29 14:32:52 ubuntu systemd-modules-load[320]: Inserted module 'dm_multipath'
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-modules-load.service - Load Kernel Modules.

× systemd-networkd-wait-online.service - Wait for Network to be Configured
     Loaded: loaded (/usr/lib/systemd/system/systemd-networkd-wait-online.service; enabled; preset: enabled)
     Active: failed (Result: exit-code) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd-networkd-wait-online.service(8)
   Main PID: 856 (code=exited, status=1/FAILURE)
        CPU: 6ms

Jul 29 14:32:55 np0000031958 systemd[1]: Starting systemd-networkd-wait-online.service - Wait for Network to be Configured...
Jul 29 14:34:55 np0000031958 systemd-networkd-wait-online[856]: Timeout occurred while waiting for network connectivity.
Jul 29 14:34:55 np0000031958 systemd[1]: systemd-networkd-wait-online.service: Main process exited, code=exited, status=1/FAILURE
Jul 29 14:34:55 np0000031958 systemd[1]: systemd-networkd-wait-online.service: Failed with result 'exit-code'.
Jul 29 14:34:55 np0000031958 systemd[1]: Failed to start systemd-networkd-wait-online.service - Wait for Network to be Configured.

● systemd-networkd.service - Network Configuration
     Loaded: loaded (/usr/lib/systemd/system/systemd-networkd.service; disabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
TriggeredBy: ● systemd-networkd.socket
       Docs: man:systemd-networkd.service(8)
             man:org.freedesktop.network1(5)
   Main PID: 845 (systemd-network)
     Status: "Processing requests..."
      Tasks: 1 (limit: 9444)
   FD Store: 0 (limit: 512)
     Memory: 2.1M (peak: 3.7M swap: 12.0K swap peak: 12.0K zswap: 433B)
        CPU: 417ms
     CGroup: /system.slice/systemd-networkd.service
             └─845 /usr/lib/systemd/systemd-networkd

Jul 29 17:31:02 np0000031958 systemd-networkd[845]: tapac8c8dec-d3: Gained carrier
Jul 29 17:31:03 np0000031958 systemd-networkd[845]: tapac8c8dec-d3: Gained IPv6LL
Jul 29 17:31:42 np0000031958 systemd-networkd[845]: tapac8c8dec-d3: Link DOWN
Jul 29 17:31:42 np0000031958 systemd-networkd[845]: tapac8c8dec-d3: Lost carrier
Jul 29 17:31:51 np0000031958 systemd-networkd[845]: tap94d2fa1f-9f: Link DOWN
Jul 29 17:31:51 np0000031958 systemd-networkd[845]: tap94d2fa1f-9f: Lost carrier
Jul 29 17:31:59 np0000031958 systemd-networkd[845]: tap97833380-f1: Link DOWN
Jul 29 17:31:59 np0000031958 systemd-networkd[845]: tap97833380-f1: Lost carrier
Jul 29 17:32:00 np0000031958 systemd-networkd[845]: tap0656be21-90: Link DOWN
Jul 29 17:32:00 np0000031958 systemd-networkd[845]: tap0656be21-90: Lost carrier

○ systemd-pcrmachine.service - TPM2 PCR Machine ID Measurement
     Loaded: loaded (/usr/lib/systemd/system/systemd-pcrmachine.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-pcrmachine.service(8)

Jul 29 14:32:52 ubuntu systemd[1]: systemd-pcrmachine.service - TPM2 PCR Machine ID Measurement was skipped because of an unmet condition check (ConditionSecurity=measured-uki).
Jul 29 14:32:52 ubuntu systemd[1]: systemd-pcrmachine.service - TPM2 PCR Machine ID Measurement was skipped because of an unmet condition check (ConditionSecurity=measured-uki).

○ systemd-pcrphase-initrd.service - TPM2 PCR Barrier (initrd)
     Loaded: loaded (/usr/lib/systemd/system/systemd-pcrphase-initrd.service; static)
     Active: inactive (dead)
       Docs: man:systemd-pcrphase-initrd.service(8)

○ systemd-pcrphase-sysinit.service - TPM2 PCR Barrier (Initialization)
     Loaded: loaded (/usr/lib/systemd/system/systemd-pcrphase-sysinit.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:systemd-pcrphase-sysinit.service(8)

Jul 29 14:32:53 ubuntu systemd[1]: systemd-pcrphase-sysinit.service - TPM2 PCR Barrier (Initialization) was skipped because of an unmet condition check (ConditionSecurity=measured-uki).

○ systemd-pcrphase.service - TPM2 PCR Barrier (User)
     Loaded: loaded (/usr/lib/systemd/system/systemd-pcrphase.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd-pcrphase.service(8)

Jul 29 14:34:55 np0000031958 systemd[1]: systemd-pcrphase.service - TPM2 PCR Barrier (User) was skipped because of an unmet condition check (ConditionSecurity=measured-uki).

○ systemd-pstore.service - Platform Persistent Storage Archival
     Loaded: loaded (/usr/lib/systemd/system/systemd-pstore.service; enabled; preset: enabled)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-pstore(8)

Jul 29 14:32:52 ubuntu systemd[1]: systemd-pstore.service - Platform Persistent Storage Archival was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore).
Jul 29 14:32:52 ubuntu systemd[1]: systemd-pstore.service - Platform Persistent Storage Archival was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore).

● systemd-random-seed.service - Load/Save OS Random Seed
     Loaded: loaded (/usr/lib/systemd/system/systemd-random-seed.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-random-seed.service(8)
             man:random(4)
   Main PID: 361 (code=exited, status=0/SUCCESS)
        CPU: 5ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-random-seed.service - Load/Save OS Random Seed...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-random-seed.service - Load/Save OS Random Seed.

● systemd-remount-fs.service - Remount Root and Kernel File Systems
     Loaded: loaded (/usr/lib/systemd/system/systemd-remount-fs.service; enabled-runtime; preset: enabled)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-remount-fs.service(8)
             https://www.freedesktop.org/wiki/Software/systemd/APIFileSystems
   Main PID: 346 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-remount-fs.service - Remount Root and Kernel File Systems...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-remount-fs.service - Remount Root and Kernel File Systems.

○ systemd-repart.service - Repartition Root Disk
     Loaded: loaded (/usr/lib/systemd/system/systemd-repart.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-repart.service(8)

Jul 29 14:32:52 ubuntu systemd[1]: systemd-repart.service - Repartition Root Disk was skipped because no trigger condition checks were met.
Jul 29 14:32:52 ubuntu systemd[1]: systemd-repart.service - Repartition Root Disk was skipped because no trigger condition checks were met.

● systemd-resolved.service - Network Name Resolution
     Loaded: loaded (/usr/lib/systemd/system/systemd-resolved.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-resolved.service(8)
             man:org.freedesktop.resolve1(5)
             https://www.freedesktop.org/wiki/Software/systemd/writing-network-configuration-managers
             https://www.freedesktop.org/wiki/Software/systemd/writing-resolver-clients
   Main PID: 408 (systemd-resolve)
     Status: "Processing requests..."
      Tasks: 1 (limit: 9444)
     Memory: 6.0M (peak: 7.2M swap: 16.0K swap peak: 16.0K zswap: 5.0K)
        CPU: 332ms
     CGroup: /system.slice/systemd-resolved.service
             └─408 /usr/lib/systemd/systemd-resolved

Jul 29 14:32:52 ubuntu systemd-resolved[408]: . IN DS 20326 8 2 e06d44b80b8f1d39a95c0b0d7c65d08458e880409bbc683457104237c7f8ec8d
Jul 29 14:32:52 ubuntu systemd-resolved[408]: Negative trust anchors: home.arpa 10.in-addr.arpa 16.172.in-addr.arpa 17.172.in-addr.arpa 18.172.in-addr.arpa 19.172.in-addr.arpa 20.172.in-addr.arpa 21.172.in-addr.arpa 22.172.in-addr.arpa 23.172.in-addr.arpa 24.172.in-addr.arpa 25.172.in-addr.arpa 26.172.in-addr.arpa 27.172.in-addr.arpa 28.172.in-addr.arpa 29.172.in-addr.arpa 30.172.in-addr.arpa 31.172.in-addr.arpa 170.0.0.192.in-addr.arpa 171.0.0.192.in-addr.arpa 168.192.in-addr.arpa d.f.ip6.arpa ipv4only.arpa corp home internal intranet lan local private test
Jul 29 14:32:52 ubuntu systemd-resolved[408]: Using system hostname 'ubuntu'.
Jul 29 14:32:52 ubuntu systemd[1]: Started systemd-resolved.service - Network Name Resolution.
Jul 29 14:32:53 np0000031958 systemd-resolved[408]: System hostname changed to 'np0000031958'.
Jul 29 14:32:55 np0000031958 systemd-resolved[408]: enp4s0: Bus client set MulticastDNS setting: no
Jul 29 14:32:55 np0000031958 systemd-resolved[408]: enp3s0: Bus client set MulticastDNS setting: no
Jul 29 14:32:55 np0000031958 systemd-resolved[408]: enp3s0: Bus client set DNS server list to: 127.0.0.1
Jul 29 14:32:55 np0000031958 systemd-resolved[408]: enp4s0: Bus client set DNS server list to: 127.0.0.1
Jul 29 14:34:56 np0000031958 systemd-resolved[408]: Clock change detected. Flushing caches.

○ systemd-rfkill.service - Load/Save RF Kill Switch Status
     Loaded: loaded (/usr/lib/systemd/system/systemd-rfkill.service; static)
     Active: inactive (dead)
TriggeredBy: ● systemd-rfkill.socket
       Docs: man:systemd-rfkill.service(8)

○ systemd-soft-reboot.service - Reboot System Userspace
     Loaded: loaded (/usr/lib/systemd/system/systemd-soft-reboot.service; static)
     Active: inactive (dead)
       Docs: man:systemd-soft-reboot.service(8)

○ systemd-suspend-then-hibernate.service - System Suspend then Hibernate
     Loaded: loaded (/usr/lib/systemd/system/systemd-suspend-then-hibernate.service; static)
     Active: inactive (dead)
       Docs: man:systemd-suspend-then-hibernate.service(8)

○ systemd-suspend.service - System Suspend
     Loaded: loaded (/usr/lib/systemd/system/systemd-suspend.service; static)
     Active: inactive (dead)
       Docs: man:systemd-suspend.service(8)

● systemd-sysctl.service - Apply Kernel Variables
     Loaded: loaded (/usr/lib/systemd/system/systemd-sysctl.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-sysctl.service(8)
             man:sysctl.d(5)
   Main PID: 347 (code=exited, status=0/SUCCESS)
        CPU: 6ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-sysctl.service - Apply Kernel Variables...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-sysctl.service - Apply Kernel Variables.

○ systemd-sysext.service - Merge System Extension Images into /usr/ and /opt/
     Loaded: loaded (/usr/lib/systemd/system/systemd-sysext.service; disabled; preset: enabled)
     Active: inactive (dead)
       Docs: man:systemd-sysext.service(8)

● systemd-sysusers.service - Create System Users
     Loaded: loaded (/usr/lib/systemd/system/systemd-sysusers.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:sysusers.d(5)
             man:systemd-sysusers.service(8)
   Main PID: 362 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-sysusers.service - Create System Users...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-sysusers.service - Create System Users.

● systemd-timesyncd.service - Network Time Synchronization
     Loaded: loaded (/usr/lib/systemd/system/systemd-timesyncd.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-timesyncd.service(8)
   Main PID: 409 (systemd-timesyn)
     Status: "Contacted time server 91.189.91.157:123 (ntp.ubuntu.com)."
      Tasks: 2 (limit: 9444)
     Memory: 1.1M (peak: 2.2M swap: 456.0K swap peak: 456.0K zswap: 123.4K)
        CPU: 136ms
     CGroup: /system.slice/systemd-timesyncd.service
             └─409 /usr/lib/systemd/systemd-timesyncd

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-timesyncd.service - Network Time Synchronization...
Jul 29 14:32:52 ubuntu systemd[1]: Started systemd-timesyncd.service - Network Time Synchronization.
Jul 29 14:32:55 np0000031958 systemd-timesyncd[409]: Network configuration changed, trying to establish connection.
Jul 29 14:32:55 np0000031958 systemd-timesyncd[409]: Network configuration changed, trying to establish connection.
Jul 29 14:32:55 np0000031958 systemd-timesyncd[409]: Network configuration changed, trying to establish connection.
Jul 29 14:32:55 np0000031958 systemd-timesyncd[409]: Network configuration changed, trying to establish connection.
Jul 29 14:32:55 np0000031958 systemd-timesyncd[409]: Network configuration changed, trying to establish connection.
Jul 29 14:34:56 np0000031958 systemd-timesyncd[409]: Contacted time server 91.189.91.157:123 (ntp.ubuntu.com).
Jul 29 14:34:56 np0000031958 systemd-timesyncd[409]: Initial clock synchronization to Tue 2025-07-29 14:34:56.811690 UTC.

○ systemd-tmpfiles-clean.service - Cleanup of Temporary Directories
     Loaded: loaded (/usr/lib/systemd/system/systemd-tmpfiles-clean.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:47:51 UTC; 2h 45min ago
TriggeredBy: ● systemd-tmpfiles-clean.timer
       Docs: man:tmpfiles.d(5)
             man:systemd-tmpfiles(8)
   Main PID: 1578 (code=exited, status=0/SUCCESS)
        CPU: 6ms

Jul 29 14:47:51 np0000031958 systemd[1]: Starting systemd-tmpfiles-clean.service - Cleanup of Temporary Directories...
Jul 29 14:47:51 np0000031958 systemd[1]: systemd-tmpfiles-clean.service: Deactivated successfully.
Jul 29 14:47:51 np0000031958 systemd[1]: Finished systemd-tmpfiles-clean.service - Cleanup of Temporary Directories.

● systemd-tmpfiles-setup-dev-early.service - Create Static Device Nodes in /dev gracefully
     Loaded: loaded (/usr/lib/systemd/system/systemd-tmpfiles-setup-dev-early.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:tmpfiles.d(5)
             man:systemd-tmpfiles(8)
   Main PID: 348 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-tmpfiles-setup-dev-early.service - Create Static Device Nodes in /dev gracefully...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-tmpfiles-setup-dev-early.service - Create Static Device Nodes in /dev gracefully.

● systemd-tmpfiles-setup-dev.service - Create Static Device Nodes in /dev
     Loaded: loaded (/usr/lib/systemd/system/systemd-tmpfiles-setup-dev.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:tmpfiles.d(5)
             man:systemd-tmpfiles(8)
   Main PID: 375 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-tmpfiles-setup-dev.service - Create Static Device Nodes in /dev...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-tmpfiles-setup-dev.service - Create Static Device Nodes in /dev.

● systemd-tmpfiles-setup.service - Create Volatile Files and Directories
     Loaded: loaded (/usr/lib/systemd/system/systemd-tmpfiles-setup.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:tmpfiles.d(5)
             man:systemd-tmpfiles(8)
   Main PID: 391 (code=exited, status=0/SUCCESS)
        CPU: 11ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-tmpfiles-setup.service - Create Volatile Files and Directories...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-tmpfiles-setup.service - Create Volatile Files and Directories.

○ systemd-tpm2-setup-early.service - TPM2 SRK Setup (Early)
     Loaded: loaded (/usr/lib/systemd/system/systemd-tpm2-setup-early.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-tpm2-setup.service(8)

Jul 29 14:32:52 ubuntu systemd[1]: systemd-tpm2-setup-early.service - TPM2 SRK Setup (Early) was skipped because of an unmet condition check (ConditionSecurity=measured-uki).
Jul 29 14:32:52 ubuntu systemd[1]: systemd-tpm2-setup-early.service - TPM2 SRK Setup (Early) was skipped because of an unmet condition check (ConditionSecurity=measured-uki).

○ systemd-tpm2-setup.service - TPM2 SRK Setup
     Loaded: loaded (/usr/lib/systemd/system/systemd-tpm2-setup.service; static)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-tpm2-setup.service(8)

Jul 29 14:32:52 ubuntu systemd[1]: systemd-tpm2-setup.service - TPM2 SRK Setup was skipped because of an unmet condition check (ConditionSecurity=measured-uki).
Jul 29 14:32:52 ubuntu systemd[1]: systemd-tpm2-setup.service - TPM2 SRK Setup was skipped because of an unmet condition check (ConditionSecurity=measured-uki).
Jul 29 14:32:52 ubuntu systemd[1]: systemd-tpm2-setup.service - TPM2 SRK Setup was skipped because of an unmet condition check (ConditionSecurity=measured-uki).

● systemd-udev-settle.service - Wait for udev To Complete Device Initialization
     Loaded: loaded (/usr/lib/systemd/system/systemd-udev-settle.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:systemd-udev-settle.service(8)
   Main PID: 370 (code=exited, status=0/SUCCESS)
        CPU: 7ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-udev-settle.service - Wait for udev To Complete Device Initialization...
Jul 29 14:32:52 ubuntu udevadm[370]: systemd-udev-settle.service is deprecated. Please fix growroot.service not to pull it in.
Jul 29 14:32:53 ubuntu systemd[1]: Finished systemd-udev-settle.service - Wait for udev To Complete Device Initialization.

● systemd-udev-trigger.service - Coldplug All udev Devices
     Loaded: loaded (/usr/lib/systemd/system/systemd-udev-trigger.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:udev(7)
             man:systemd-udevd.service(8)
   Main PID: 322 (code=exited, status=0/SUCCESS)
        CPU: 63ms

Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-udev-trigger.service - Coldplug All udev Devices.

● systemd-udevd.service - Rule-based Manager for Device Events and Files
     Loaded: loaded (/usr/lib/systemd/system/systemd-udevd.service; static)
    Drop-In: /usr/lib/systemd/system/systemd-udevd.service.d
             └─syscall-architecture.conf
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
TriggeredBy: ● systemd-udevd-kernel.socket
             ● systemd-udevd-control.socket
       Docs: man:systemd-udevd.service(8)
             man:udev(7)
   Main PID: 378 (systemd-udevd)
     Status: "Processing with 32 children at max"
      Tasks: 1
     Memory: 7.1M (peak: 47.9M swap: 448.0K swap peak: 468.0K zswap: 15.1K)
        CPU: 31.500s
     CGroup: /system.slice/systemd-udevd.service
             └─udev
               └─378 /usr/lib/systemd/systemd-udevd

Jul 29 17:31:51 np0000031958 (udev-worker)[131701]: dm-5: /usr/lib/udev/rules.d/99-pure-storage.rules:5 Failed to write ATTR{/sys/devices/virtual/block/dm-5/queue/scheduler}, ignoring: No such file or directory
Jul 29 17:31:51 np0000031958 (udev-worker)[131701]: dm-5: /usr/lib/udev/rules.d/99-pure-storage.rules:11 Failed to write ATTR{/sys/devices/virtual/block/dm-5/queue/rq_affinity}, ignoring: No such file or directory
Jul 29 17:32:00 np0000031958 (udev-worker)[131850]: sdd: /usr/lib/udev/rules.d/99-pure-storage.rules:3 Failed to write ATTR{/sys/devices/platform/host8/session62/target8:0:0/8:0:0:1/block/sdd/queue/scheduler}, ignoring: Invalid argument
Jul 29 17:32:00 np0000031958 (udev-worker)[131850]: sda: /usr/lib/udev/rules.d/99-pure-storage.rules:3 Failed to write ATTR{/sys/devices/platform/host6/session60/target6:0:0/6:0:0:1/block/sda/queue/scheduler}, ignoring: Invalid argument
Jul 29 17:32:00 np0000031958 (udev-worker)[131938]: sdb: /usr/lib/udev/rules.d/99-pure-storage.rules:3 Failed to write ATTR{/sys/devices/platform/host7/session61/target7:0:0/7:0:0:1/block/sdb/queue/scheduler}, ignoring: Invalid argument
Jul 29 17:32:00 np0000031958 (udev-worker)[131863]: sdc: /usr/lib/udev/rules.d/99-pure-storage.rules:3 Failed to write ATTR{/sys/devices/platform/host9/session63/target9:0:0/9:0:0:1/block/sdc/queue/scheduler}, ignoring: Invalid argument
Jul 29 17:32:00 np0000031958 (udev-worker)[131938]: dm-2: /usr/lib/udev/rules.d/99-pure-storage.rules:5 Failed to write ATTR{/sys/devices/virtual/block/dm-2/queue/scheduler}, ignoring: No such file or directory
Jul 29 17:32:00 np0000031958 (udev-worker)[131938]: dm-2: /usr/lib/udev/rules.d/99-pure-storage.rules:11 Failed to write ATTR{/sys/devices/virtual/block/dm-2/queue/rq_affinity}, ignoring: No such file or directory
Jul 29 17:32:00 np0000031958 (udev-worker)[131863]: dm-3: /usr/lib/udev/rules.d/99-pure-storage.rules:5 Failed to write ATTR{/sys/devices/virtual/block/dm-3/queue/scheduler}, ignoring: No such file or directory
Jul 29 17:32:00 np0000031958 (udev-worker)[131863]: dm-3: /usr/lib/udev/rules.d/99-pure-storage.rules:11 Failed to write ATTR{/sys/devices/virtual/block/dm-3/queue/rq_affinity}, ignoring: No such file or directory

● systemd-update-done.service - Update is Completed
     Loaded: loaded (/usr/lib/systemd/system/systemd-update-done.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-update-done.service(8)
   Main PID: 498 (code=exited, status=0/SUCCESS)
        CPU: 4ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-update-done.service - Update is Completed...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-update-done.service - Update is Completed.

○ systemd-update-utmp-runlevel.service - Record Runlevel Change in UTMP
     Loaded: loaded (/usr/lib/systemd/system/systemd-update-utmp-runlevel.service; static)
     Active: inactive (dead) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd-update-utmp-runlevel.service(8)
             man:utmp(5)
   Main PID: 1093 (code=exited, status=0/SUCCESS)
        CPU: 6ms

Jul 29 14:34:55 np0000031958 systemd[1]: Starting systemd-update-utmp-runlevel.service - Record Runlevel Change in UTMP...
Jul 29 14:34:55 np0000031958 systemd[1]: systemd-update-utmp-runlevel.service: Deactivated successfully.
Jul 29 14:34:55 np0000031958 systemd[1]: Finished systemd-update-utmp-runlevel.service - Record Runlevel Change in UTMP.

● systemd-update-utmp.service - Record System Boot/Shutdown in UTMP
     Loaded: loaded (/usr/lib/systemd/system/systemd-update-utmp.service; static)
     Active: active (exited) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-update-utmp.service(8)
             man:utmp(5)
   Main PID: 411 (code=exited, status=0/SUCCESS)
        CPU: 5ms

Jul 29 14:32:52 ubuntu systemd[1]: Starting systemd-update-utmp.service - Record System Boot/Shutdown in UTMP...
Jul 29 14:32:52 ubuntu systemd[1]: Finished systemd-update-utmp.service - Record System Boot/Shutdown in UTMP.

● systemd-user-sessions.service - Permit User Sessions
     Loaded: loaded (/usr/lib/systemd/system/systemd-user-sessions.service; static)
     Active: active (exited) since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd-user-sessions.service(8)
   Main PID: 1006 (code=exited, status=0/SUCCESS)
        CPU: 5ms

Jul 29 14:34:55 np0000031958 systemd[1]: Starting systemd-user-sessions.service - Permit User Sessions...
Jul 29 14:34:55 np0000031958 systemd[1]: Finished systemd-user-sessions.service - Permit User Sessions.

× unbound-resolvconf.service - Unbound asyncronous resolvconf update helper
     Loaded: loaded (/usr/lib/systemd/system/unbound-resolvconf.service; enabled; preset: enabled)
     Active: failed (Result: exit-code) since Tue 2025-07-29 14:32:56 UTC; 3h 0min ago
   Duration: 11ms
   Main PID: 946 (code=exited, status=1/FAILURE)
        CPU: 11ms

Jul 29 14:32:56 np0000031958 systemd[1]: Started unbound-resolvconf.service - Unbound asyncronous resolvconf update helper.
Jul 29 14:32:56 np0000031958 resolvconf[950]: Dropped protocol specifier '.unbound' from 'lo.unbound'. Using 'lo' (ifindex=1).
Jul 29 14:32:56 np0000031958 resolvconf[950]: Failed to set DNS configuration: Link lo is loopback device.
Jul 29 14:32:56 np0000031958 systemd[1]: unbound-resolvconf.service: Main process exited, code=exited, status=1/FAILURE
Jul 29 14:32:56 np0000031958 systemd[1]: unbound-resolvconf.service: Failed with result 'exit-code'.
Jul 29 14:32:56 np0000031958 systemd[1]: unbound-resolvconf.service: Start request repeated too quickly.
Jul 29 14:32:56 np0000031958 systemd[1]: unbound-resolvconf.service: Failed with result 'exit-code'.
Jul 29 14:32:56 np0000031958 systemd[1]: Failed to start unbound-resolvconf.service - Unbound asyncronous resolvconf update helper.

× unbound.service - Unbound DNS server
     Loaded: loaded (/usr/lib/systemd/system/unbound.service; enabled; preset: enabled)
     Active: failed (Result: exit-code) since Tue 2025-07-29 14:32:56 UTC; 3h 0min ago
       Docs: man:unbound(8)
   Main PID: 941 (code=exited, status=1/FAILURE)
        CPU: 25ms

Jul 29 14:32:56 np0000031958 systemd[1]: unbound.service: Scheduled restart job, restart counter is at 5.
Jul 29 14:32:56 np0000031958 systemd[1]: unbound.service: Start request repeated too quickly.
Jul 29 14:32:56 np0000031958 systemd[1]: unbound.service: Failed with result 'exit-code'.
Jul 29 14:32:56 np0000031958 systemd[1]: Failed to start unbound.service - Unbound DNS server.

● user-runtime-dir@1000.service - User Runtime Directory /run/user/1000
     Loaded: loaded (/usr/lib/systemd/system/user-runtime-dir@.service; static)
     Active: active (exited) since Tue 2025-07-29 16:38:24 UTC; 54min ago
       Docs: man:user@.service(5)
   Main PID: 1602 (code=exited, status=0/SUCCESS)
        CPU: 6ms

Jul 29 16:38:24 np0000031958 systemd[1]: Starting user-runtime-dir@1000.service - User Runtime Directory /run/user/1000...
Jul 29 16:38:24 np0000031958 systemd[1]: Finished user-runtime-dir@1000.service - User Runtime Directory /run/user/1000.

● user@1000.service - User Manager for UID 1000
     Loaded: loaded (/usr/lib/systemd/system/user@.service; static)
    Drop-In: /usr/lib/systemd/system/user@.service.d
             └─10-login-barrier.conf, timeout.conf
     Active: active (running) since Tue 2025-07-29 16:38:24 UTC; 54min ago
       Docs: man:user@.service(5)
   Main PID: 1605 (systemd)
     Status: "Ready."
      Tasks: 2
     Memory: 3.8M (peak: 7.6M swap: 420.0K swap peak: 420.0K zswap: 93.2K)
        CPU: 3.440s
     CGroup: /user.slice/user-1000.slice/user@1000.service
             └─init.scope
               ├─1605 /usr/lib/systemd/systemd --user
               └─1606 "(sd-pam)"

Jul 29 16:38:24 np0000031958 systemd[1605]: Listening on keyboxd.socket - GnuPG public key management service.
Jul 29 16:38:24 np0000031958 systemd[1605]: Listening on pk-debconf-helper.socket - debconf communication socket.
Jul 29 16:38:24 np0000031958 systemd[1605]: Listening on dbus.socket - D-Bus User Message Bus Socket.
Jul 29 16:38:24 np0000031958 systemd[1605]: Listening on gpg-agent-ssh.socket - GnuPG cryptographic agent (ssh-agent emulation).
Jul 29 16:38:24 np0000031958 systemd[1605]: Reached target sockets.target - Sockets.
Jul 29 16:38:24 np0000031958 systemd[1605]: Reached target basic.target - Basic System.
Jul 29 16:38:24 np0000031958 systemd[1605]: Reached target default.target - Main User Target.
Jul 29 16:38:24 np0000031958 systemd[1605]: Startup finished in 89ms.
Jul 29 16:38:24 np0000031958 systemd[1]: Started user@1000.service - User Manager for UID 1000.
Jul 29 16:43:51 np0000031958 systemd[1605]: launchpadlib-cache-clean.service - Clean up old files in the Launchpadlib cache was skipped because of an unmet condition check (ConditionPathExists=/home/zuul/.launchpadlib/api.launchpad.net/cache).

○ uuidd.service - Daemon for generating UUIDs
     Loaded: loaded (/usr/lib/systemd/system/uuidd.service; indirect; preset: enabled)
     Active: inactive (dead)
TriggeredBy: ● uuidd.socket
       Docs: man:uuidd(8)

● uwsgi.service - LSB: Start/stop uWSGI server instance(s)
     Loaded: loaded (/etc/init.d/uwsgi; generated)
     Active: active (exited) since Tue 2025-07-29 16:45:08 UTC; 48min ago
       Docs: man:systemd-sysv-generator(8)
        CPU: 21ms

Jul 29 16:45:08 np0000031958 systemd[1]: Starting uwsgi.service - LSB: Start/stop uWSGI server instance(s)...
Jul 29 16:45:08 np0000031958 uwsgi[22036]:  * Starting app server(s) uwsgi
Jul 29 16:45:08 np0000031958 uwsgi[22036]:    ...done.
Jul 29 16:45:08 np0000031958 systemd[1]: Started uwsgi.service - LSB: Start/stop uWSGI server instance(s).

● virtlockd.service - libvirt locking daemon
     Loaded: loaded (/usr/lib/systemd/system/virtlockd.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:27 UTC; 41min ago
TriggeredBy: ● virtlockd-admin.socket
             ● virtlockd.socket
       Docs: man:virtlockd(8)
             https://libvirt.org/
   Main PID: 34172 (virtlockd)
      Tasks: 1 (limit: 9444)
     Memory: 916.0K (peak: 2.4M swap: 1.6M swap peak: 1.6M zswap: 455.9K)
        CPU: 9ms
     CGroup: /system.slice/virtlockd.service
             └─34172 /usr/sbin/virtlockd

Jul 29 16:51:27 np0000031958 systemd[1]: Starting virtlockd.service - libvirt locking daemon...
Jul 29 16:51:27 np0000031958 systemd[1]: Started virtlockd.service - libvirt locking daemon.

● virtlogd.service - libvirt logging daemon
     Loaded: loaded (/usr/lib/systemd/system/virtlogd.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:58 UTC; 41min ago
TriggeredBy: ● virtlogd.socket
             ● virtlogd-admin.socket
       Docs: man:virtlogd(8)
             https://libvirt.org/
   Main PID: 40311 (virtlogd)
      Tasks: 1 (limit: 9444)
     Memory: 2.3M (peak: 3.4M swap: 712.0K swap peak: 712.0K zswap: 209.5K)
        CPU: 3.347s
     CGroup: /system.slice/virtlogd.service
             └─40311 /usr/sbin/virtlogd

Jul 29 16:51:58 np0000031958 systemd[1]: Starting virtlogd.service - libvirt logging daemon...
Jul 29 16:51:58 np0000031958 systemd[1]: Started virtlogd.service - libvirt logging daemon.

● -.slice - Root Slice
     Loaded: loaded
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)
      Tasks: 1010
     Memory: 5.0G ()
        CPU: 1h 15min 5.840s
     CGroup: /
             ├─init.scope
             │ └─1 /sbin/init nofb
             ├─system.slice
             │ ├─apache-htcacheclean.service
             │ │ └─12079 /usr/bin/htcacheclean -d 120 -p /var/cache/apache2/mod_cache_disk -l 300M -n
             │ ├─apache2.service
             │ │ ├─60135 /usr/sbin/apache2 -k start
             │ │ ├─60141 /usr/sbin/apache2 -k start
             │ │ └─60142 /usr/sbin/apache2 -k start
             │ ├─atd.service
             │ │ └─1007 /usr/sbin/atd -f
             │ ├─cron.service
             │ │ └─1005 /usr/sbin/cron -f -P
             │ ├─dbus.service
             │ │ └─521 @dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only
             │ ├─epmd.service
             │ │ └─17674 /usr/bin/epmd -systemd
             │ ├─haproxy.service
             │ │ ├─11224 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
             │ │ └─11226 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
             │ ├─haveged.service
             │ │ └─403 /usr/sbin/haveged --Foreground --verbose=1
             │ ├─iscsid.service
             │ │ ├─36013 /usr/sbin/iscsid
             │ │ └─36014 /usr/sbin/iscsid
             │ ├─ksmtuned.service
             │ │ ├─  5739 /bin/bash /usr/sbin/ksmtuned
             │ │ └─132319 sleep 60
             │ ├─libvirtd.service
             │ │ ├─34056 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
             │ │ ├─34057 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
             │ │ └─78152 /usr/sbin/libvirtd --timeout 120
             │ ├─memcached.service
             │ │ └─47620 /usr/bin/memcached -m 64 -p 11211 -u memcache -l 127.0.0.1 -l ::1 -P /var/run/memcached/memcached.pid
             │ ├─multipathd.service
             │ │ └─363 /sbin/multipathd -d -s
             │ ├─mysql.service
             │ │ └─44158 /usr/sbin/mysqld
             │ ├─ovn-controller-vtep.service
             │ │ └─67159 ovn-controller-vtep -vconsole:emer -vsyslog:err -vfile:info --vtep-db=/var/run/openvswitch/db.sock --ovnsb-db=/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-controller-vtep.log --pidfile=/var/run/ovn/ovn-controller-vtep.pid --detach
             │ ├─ovn-controller.service
             │ │ └─67808 ovn-controller unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --no-chdir --log-file=/var/log/ovn/ovn-controller.log --pidfile=/var/run/ovn/ovn-controller.pid --detach
             │ ├─ovn-northd.service
             │ │ └─67551 ovn-northd -vconsole:emer -vsyslog:err -vfile:info --ovnnb-db=unix:/var/run/ovn/ovnnb_db.sock --ovnsb-db=unix:/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-northd.log --pidfile=/var/run/ovn/ovn-northd.pid --detach
             │ ├─ovn-ovsdb-server-nb.service
             │ │ └─67478 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-nb.log --remote=punix:/var/run/ovn/ovnnb_db.sock --pidfile=/var/run/ovn/ovnnb_db.pid --unixctl=/var/run/ovn/ovnnb_db.ctl --remote=db:OVN_Northbound,NB_Global,connections --private-key=db:OVN_Northbound,SSL,private_key --certificate=db:OVN_Northbound,SSL,certificate --ca-cert=db:OVN_Northbound,SSL,ca_cert --ssl-protocols=db:OVN_Northbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Northbound,SSL,ssl_ciphers /var/lib/ovn/ovnnb_db.db
             │ ├─ovn-ovsdb-server-sb.service
             │ │ └─67479 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-sb.log --remote=punix:/var/run/ovn/ovnsb_db.sock --pidfile=/var/run/ovn/ovnsb_db.pid --unixctl=/var/run/ovn/ovnsb_db.ctl --remote=db:OVN_Southbound,SB_Global,connections --private-key=db:OVN_Southbound,SSL,private_key --certificate=db:OVN_Southbound,SSL,certificate --ca-cert=db:OVN_Southbound,SSL,ca_cert --ssl-protocols=db:OVN_Southbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Southbound,SSL,ssl_ciphers /var/lib/ovn/ovnsb_db.db
             │ ├─ovs-vswitchd.service
             │ │ └─67077 ovs-vswitchd unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --mlockall --no-chdir --log-file=/var/log/openvswitch/ovs-vswitchd.log --pidfile=/var/run/openvswitch/ovs-vswitchd.pid --detach
             │ ├─ovsdb-server.service
             │ │ └─66880 ovsdb-server /etc/openvswitch/conf.db -vconsole:emer -vsyslog:err -vfile:info --remote=punix:/var/run/openvswitch/db.sock --private-key=db:Open_vSwitch,SSL,private_key --certificate=db:Open_vSwitch,SSL,certificate --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert --no-chdir --log-file=/var/log/openvswitch/ovsdb-server.log --pidfile=/var/run/openvswitch/ovsdb-server.pid --detach
             │ ├─polkit.service
             │ │ └─1336 /usr/lib/polkit-1/polkitd --no-debug
             │ ├─pure-boot.service
             │ │ └─988 dhclient
             │ ├─rabbitmq-server.service
             │ │ ├─17789 /usr/lib/erlang/erts-13.2.2.5/bin/beam.smp -W w -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -pc unicode -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -sbwt none -sbwtdcpu none -sbwtdio none -- -root /usr/lib/erlang -bindir /usr/lib/erlang/erts-13.2.2.5/bin -progname erl -- -home /var/lib/rabbitmq -- -pa "" -noshell -noinput -s rabbit boot -boot start_sasl -syslog logger "[]" -syslog syslog_error_logger false -kernel prevent_overlapping_partitions false -enable-feature maybe_expr
             │ │ ├─17799 erl_child_setup 65536
             │ │ ├─17875 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
             │ │ ├─17876 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
             │ │ └─17879 /bin/sh -s rabbit_disk_monitor
             │ ├─rsyslog.service
             │ │ └─15219 /usr/sbin/rsyslogd -n -iNONE
             │ ├─ssh.service
             │ │ └─860 "sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups"
             │ ├─system-devstack.slice
             │ │ ├─devstack@c-api.service
             │ │ │ ├─78016 "cinder-apiuWSGI master"
             │ │ │ ├─78022 "cinder-apiuWSGI worker 1"
             │ │ │ └─78023 "cinder-apiuWSGI worker 2"
             │ │ ├─devstack@c-sch.service
             │ │ │ └─78804 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf
             │ │ ├─devstack@c-vol.service
             │ │ │ ├─79416 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             │ │ │ ├─80100 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             │ │ │ ├─91425 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context cinder.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmpk5wqr2on/privsep.sock
             │ │ │ └─91489 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmpohtseool/privsep.sock
             │ │ ├─devstack@etcd.service
             │ │ │ └─45936 /opt/stack/bin/etcd --name np0000031958 --data-dir /opt/stack/data/etcd --initial-cluster-state new --initial-cluster-token etcd-cluster-01 --initial-cluster np0000031958=http://192.168.1.104:2380 --initial-advertise-peer-urls http://192.168.1.104:2380 --advertise-client-urls http://192.168.1.104:2379 --listen-peer-urls http://0.0.0.0:2380 --listen-client-urls http://192.168.1.104:2379 --log-level=debug
             │ │ ├─devstack@file_tracker.service
             │ │ │ ├─ 45281 /bin/bash /opt/stack/devstack/tools/file_tracker.sh
             │ │ │ └─134026 sleep 20
             │ │ ├─devstack@g-api.service
             │ │ │ ├─80178 "glance-apiuWSGI master"
             │ │ │ ├─80179 "glance-apiuWSGI worker 1"
             │ │ │ └─80180 "glance-apiuWSGI worker 2"
             │ │ ├─devstack@keystone.service
             │ │ │ ├─47211 "keystoneuWSGI master"
             │ │ │ ├─47212 "keystoneuWSGI worker 1"
             │ │ │ └─47213 "keystoneuWSGI worker 2"
             │ │ ├─devstack@memory_tracker.service
             │ │ │ ├─ 44799 /bin/bash /opt/stack/devstack/tools/memory_tracker.sh
             │ │ │ └─132658 sleep 20
             │ │ ├─devstack@n-api-meta.service
             │ │ │ ├─74275 "nova-api-metauWSGI master"
             │ │ │ ├─74276 "nova-api-metauWSGI worker 1"
             │ │ │ ├─74277 "nova-api-metauWSGI worker 2"
             │ │ │ └─74278 "nova-api-metauWSGI http 1"
             │ │ ├─devstack@n-api.service
             │ │ │ ├─66388 "nova-apiuWSGI master"
             │ │ │ ├─66389 "nova-apiuWSGI worker 1"
             │ │ │ └─66390 "nova-apiuWSGI worker 2"
             │ │ ├─devstack@n-cond-cell1.service
             │ │ │ ├─76172 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ │ │ ├─77282 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ │ │ └─77283 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ │ ├─devstack@n-cpu.service
             │ │ │ ├─77223 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-compute --config-file /etc/nova/nova-cpu.conf
             │ │ │ ├─87718 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context nova.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmps6_q_fui/privsep.sock
             │ │ │ ├─87756 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context vif_plug_ovs.privsep.vif_plug --privsep_sock_path /tmp/tmprul1wut5/privsep.sock
             │ │ │ └─88388 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmp9ppv4ep2/privsep.sock
             │ │ ├─devstack@n-novnc-cell1.service
             │ │ │ └─74890 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-novncproxy --config-file /etc/nova/nova_cell1.conf --web /usr/share/novnc
             │ │ ├─devstack@n-sch.service
             │ │ │ ├─73694 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ │ │ ├─74771 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ │ │ └─74773 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ │ ├─devstack@n-super-cond.service
             │ │ │ ├─75663 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ │ │ ├─77004 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ │ │ └─77006 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ │ ├─devstack@neutron-api.service
             │ │ │ ├─69264 "neutron-apiuWSGI master"
             │ │ │ ├─69265 "neutron-apiuWSGI worker 1"
             │ │ │ └─69266 "neutron-apiuWSGI worker 2"
             │ │ ├─devstack@neutron-ovn-maintenance-worker.service
             │ │ │ ├─70814 "neutron-ovn-maintenance-worker: master process [/opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ │ │ └─71478 "neutron-server: maintenance worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ ├─devstack@neutron-periodic-workers.service
             │ │ │ ├─70339 "neutron-periodic-workers: master process [/opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ │ │ ├─70924 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ │ ├─70940 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ │ ├─70960 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ │ └─70970 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ ├─devstack@neutron-rpc-server.service
             │ │ │ ├─69866 "neutron-rpc-server: master process [/opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ │ │ └─71411 "neutron-server: rpc worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ ├─devstack@openstack-cli-server.service
             │ │ │ └─43414 /opt/stack/data/venv/bin/python3 /opt/stack/devstack/files/openstack-cli-server/openstack-cli-server
             │ │ ├─devstack@placement-api.service
             │ │ │ ├─71602 "placementuWSGI master"
             │ │ │ ├─71603 "placementuWSGI worker 1"
             │ │ │ └─71604 "placementuWSGI worker 2"
             │ │ └─devstack@q-ovn-agent.service
             │ │   ├─68291 "neutron-ovn-agent: master process [/opt/stack/data/venv/bin/neutron-ovn-agent --config-file /etc/neutron/plugins/ml2/ovn_agent.ini]"
             │ │   ├─69566 "neutron-ovn-agent: ServiceWrapper worker(0)"
             │ │   ├─69991 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.namespace_cmd --privsep_sock_path /tmp/tmp6pg930cl/privsep.sock
             │ │   ├─72437 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.default --privsep_sock_path /tmp/tmpoexj_vsa/privsep.sock
             │ │   ├─87902 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.link_cmd --privsep_sock_path /tmp/tmpdh3dhj4v/privsep.sock
             │ │   ├─87989 sudo /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
             │ │   └─87990 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
             │ ├─system-getty.slice
             │ │ └─getty@tty1.service
             │ │   └─1015 /sbin/agetty -o "-p -- \\u" --noclear - linux
             │ ├─system-glean.slice
             │ │ ├─glean@enp3s0.service
             │ │ │ └─704 dhclient -1 -4 -v -i -pf /run/dhclient.enp3s0.pid -lf /var/lib/dhcp/dhclient.enp3s0.leases -I -df /var/lib/dhcp/dhclient6.enp3s0.leases enp3s0
             │ │ └─glean@enp4s0.service
             │ │   └─703 dhclient -1 -4 -v -i -pf /run/dhclient.enp4s0.pid -lf /var/lib/dhcp/dhclient.enp4s0.leases -I -df /var/lib/dhcp/dhclient6.enp4s0.leases enp4s0
             │ ├─system-serial\x2dgetty.slice
             │ │ └─serial-getty@ttyS0.service
             │ │   └─1016 /sbin/agetty -o "-p -- \\u" --keep-baud 115200,57600,38400,9600 - vt220
             │ ├─systemd-journald.service
             │ │ └─16765 /usr/lib/systemd/systemd-journald
             │ ├─systemd-logind.service
             │ │ └─531 /usr/lib/systemd/systemd-logind
             │ ├─systemd-machined.service
             │ │ └─33939 /usr/lib/systemd/systemd-machined
             │ ├─systemd-networkd.service
             │ │ └─845 /usr/lib/systemd/systemd-networkd
             │ ├─systemd-resolved.service
             │ │ └─408 /usr/lib/systemd/systemd-resolved
             │ ├─systemd-timesyncd.service
             │ │ └─409 /usr/lib/systemd/systemd-timesyncd
             │ ├─systemd-udevd.service
             │ │ └─udev
             │ │   └─378 /usr/lib/systemd/systemd-udevd
             │ ├─virtlockd.service
             │ │ └─34172 /usr/sbin/virtlockd
             │ └─virtlogd.service
             │   └─40311 /usr/sbin/virtlogd
             └─user.slice
               └─user-1000.slice
                 ├─session-12.scope
                 │ ├─132488 "sshd: zuul [priv]"
                 │ ├─132498 "sshd: zuul@notty"
                 │ ├─134021 /bin/sh -c "sudo -H -S -n  -u root /bin/sh -c 'echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3' && sleep 0"
                 │ ├─134022 sudo -H -S -n -u root /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
                 │ ├─134023 /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
                 │ ├─134024 /usr/bin/python3
                 │ ├─134027 /bin/bash -c "sudo iptables-save > /home/zuul/iptables.txt\ndf -h > /home/zuul/df.txt\n\nfor py_ver in 2 3; do\n    if [[ \`which python\${py_ver}\` ]]; then\n        python\${py_ver} -m pip freeze > /home/zuul/pip\${py_ver}-freeze.txt\n    fi\ndone\n\nif [ \`command -v dpkg\` ]; then\n    dpkg -l> /home/zuul/dpkg-l.txt\nfi\nif [ \`command -v rpm\` ]; then\n    rpm -qa | sort > /home/zuul/rpm-qa.txt\nfi\n\n# Services status\nsudo systemctl status --all > services.txt 2>/dev/null\n\n# NOTE(kchamart) The 'audit.log' can be useful in cases when QEMU\n# failed to start due to denials from SELinux — useful for CentOS\n# and Fedora machines.  For Ubuntu (which runs AppArmor), DevStack\n# already captures the contents of /var/log/kern.log (via\n# \`journalctl -t kernel\` redirected into syslog.txt.gz), which\n# contains AppArmor-related messages.\nif [ -f /var/log/audit/audit.log ] ; then\n    sudo cp /var/log/audit/audit.log /home/zuul/audit.log &&\n    chmod +r /home/zuul/audit.log;\nfi\n\n# gzip and save any coredumps in /var/core\nif [ -d /var/core ]; then\n    sudo gzip -r /var/core\n    sudo cp -r /var/core /home/zuul/\nfi\n\nsudo ss -lntup | grep ':53' > /home/zuul/listen53.txt\n\n# NOTE(andreaf) Service logs are already in logs/ thanks for the\n# export-devstack-journal log. Apache logs are under apache/ thans to the\n# apache-logs-conf role.\ngrep -i deprecat /home/zuul/logs/*.txt /home/zuul/apache/*.log | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}\\.[0-9]{1,3}/ /g' | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}/ /g' | \\\n    sed -r 's/[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}/ /g' |\n    sed -r 's/\\[.*\\]/ /g' | \\\n    sed -r 's/\\s[0-9]+\\s/ /g' | \\\n    awk '{if (\$0 in seen) {seen[\$0]++} else {out[++n]=\$0;seen[\$0]=1}} END { for (i=1; i<=n; i++) print seen[out[i]]\" :: \" out[i] }' > /home/zuul/deprecations.log\n"
                 │ ├─134038 sudo systemctl status --all
                 │ └─134039 systemctl status --all
                 ├─session-3.scope
                 │ └─1747 /usr/bin/python3
                 └─user@1000.service
                   └─init.scope
                     ├─1605 /usr/lib/systemd/systemd --user
                     └─1606 "(sd-pam)"

Jul 29 17:31:51 np0000031958 systemd[1]: machine-qemu\x2d80\x2dinstance\x2d00000038.scope: Consumed 22.288s CPU time.
Jul 29 17:32:00 np0000031958 systemd[1]: machine-qemu\x2d79\x2dinstance\x2d00000037.scope: Deactivated successfully.
Jul 29 17:32:00 np0000031958 systemd[1]: machine-qemu\x2d79\x2dinstance\x2d00000037.scope: Consumed 21.857s CPU time.
Jul 29 17:32:00 np0000031958 systemd[1]: run-netns-ovnmeta\x2d0656be21\x2d9f8e\x2d413a\x2d861a\x2dbe5cee277270.mount: Deactivated successfully.
Jul 29 17:32:19 np0000031958 systemd[1]: session-9.scope: Deactivated successfully.
Jul 29 17:32:19 np0000031958 systemd[1]: session-9.scope: Consumed 6min 46.096s CPU time, 3.8G memory peak, 0B memory swap peak.
Jul 29 17:32:20 np0000031958 systemd[1]: Started session-11.scope - Session 11 of User zuul.
Jul 29 17:32:47 np0000031958 systemd[1]: session-11.scope: Deactivated successfully.
Jul 29 17:32:47 np0000031958 systemd[1]: session-11.scope: Consumed 19.132s CPU time.
Jul 29 17:32:47 np0000031958 systemd[1]: Started session-12.scope - Session 12 of User zuul.

● machine.slice - Virtual Machine and Container Slice
     Loaded: loaded (/usr/lib/systemd/system/machine.slice; static)
     Active: active since Tue 2025-07-29 16:51:26 UTC; 41min ago
       Docs: man:systemd.special(7)
      Tasks: 0
     Memory: 6.7M (peak: 1.6G swap: 0B swap peak: 114.3M)
        CPU: 34min 59.670s
     CGroup: /machine.slice

Jul 29 16:51:26 np0000031958 systemd[1]: Created slice machine.slice - Virtual Machine and Container Slice.

● system-devstack.slice - Slice /system/devstack
     Loaded: loaded
     Active: active since Tue 2025-07-29 16:52:07 UTC; 41min ago
      Tasks: 399
     Memory: 4.3G (peak: 5.0G swap: 2.5G swap peak: 2.5G zswap: 637.8M)
        CPU: 20min 58.111s
     CGroup: /system.slice/system-devstack.slice
             ├─devstack@c-api.service
             │ ├─78016 "cinder-apiuWSGI master"
             │ ├─78022 "cinder-apiuWSGI worker 1"
             │ └─78023 "cinder-apiuWSGI worker 2"
             ├─devstack@c-sch.service
             │ └─78804 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf
             ├─devstack@c-vol.service
             │ ├─79416 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             │ ├─80100 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             │ ├─91425 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context cinder.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmpk5wqr2on/privsep.sock
             │ └─91489 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmpohtseool/privsep.sock
             ├─devstack@etcd.service
             │ └─45936 /opt/stack/bin/etcd --name np0000031958 --data-dir /opt/stack/data/etcd --initial-cluster-state new --initial-cluster-token etcd-cluster-01 --initial-cluster np0000031958=http://192.168.1.104:2380 --initial-advertise-peer-urls http://192.168.1.104:2380 --advertise-client-urls http://192.168.1.104:2379 --listen-peer-urls http://0.0.0.0:2380 --listen-client-urls http://192.168.1.104:2379 --log-level=debug
             ├─devstack@file_tracker.service
             │ ├─ 45281 /bin/bash /opt/stack/devstack/tools/file_tracker.sh
             │ └─134026 sleep 20
             ├─devstack@g-api.service
             │ ├─80178 "glance-apiuWSGI master"
             │ ├─80179 "glance-apiuWSGI worker 1"
             │ └─80180 "glance-apiuWSGI worker 2"
             ├─devstack@keystone.service
             │ ├─47211 "keystoneuWSGI master"
             │ ├─47212 "keystoneuWSGI worker 1"
             │ └─47213 "keystoneuWSGI worker 2"
             ├─devstack@memory_tracker.service
             │ ├─ 44799 /bin/bash /opt/stack/devstack/tools/memory_tracker.sh
             │ └─132658 sleep 20
             ├─devstack@n-api-meta.service
             │ ├─74275 "nova-api-metauWSGI master"
             │ ├─74276 "nova-api-metauWSGI worker 1"
             │ ├─74277 "nova-api-metauWSGI worker 2"
             │ └─74278 "nova-api-metauWSGI http 1"
             ├─devstack@n-api.service
             │ ├─66388 "nova-apiuWSGI master"
             │ ├─66389 "nova-apiuWSGI worker 1"
             │ └─66390 "nova-apiuWSGI worker 2"
             ├─devstack@n-cond-cell1.service
             │ ├─76172 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ ├─77282 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ └─77283 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             ├─devstack@n-cpu.service
             │ ├─77223 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-compute --config-file /etc/nova/nova-cpu.conf
             │ ├─87718 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context nova.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmps6_q_fui/privsep.sock
             │ ├─87756 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context vif_plug_ovs.privsep.vif_plug --privsep_sock_path /tmp/tmprul1wut5/privsep.sock
             │ └─88388 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmp9ppv4ep2/privsep.sock
             ├─devstack@n-novnc-cell1.service
             │ └─74890 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-novncproxy --config-file /etc/nova/nova_cell1.conf --web /usr/share/novnc
             ├─devstack@n-sch.service
             │ ├─73694 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ ├─74771 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ └─74773 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             ├─devstack@n-super-cond.service
             │ ├─75663 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ ├─77004 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ └─77006 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             ├─devstack@neutron-api.service
             │ ├─69264 "neutron-apiuWSGI master"
             │ ├─69265 "neutron-apiuWSGI worker 1"
             │ └─69266 "neutron-apiuWSGI worker 2"
             ├─devstack@neutron-ovn-maintenance-worker.service
             │ ├─70814 "neutron-ovn-maintenance-worker: master process [/opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ └─71478 "neutron-server: maintenance worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             ├─devstack@neutron-periodic-workers.service
             │ ├─70339 "neutron-periodic-workers: master process [/opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ ├─70924 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ ├─70940 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ ├─70960 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ └─70970 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             ├─devstack@neutron-rpc-server.service
             │ ├─69866 "neutron-rpc-server: master process [/opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ └─71411 "neutron-server: rpc worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             ├─devstack@openstack-cli-server.service
             │ └─43414 /opt/stack/data/venv/bin/python3 /opt/stack/devstack/files/openstack-cli-server/openstack-cli-server
             ├─devstack@placement-api.service
             │ ├─71602 "placementuWSGI master"
             │ ├─71603 "placementuWSGI worker 1"
             │ └─71604 "placementuWSGI worker 2"
             └─devstack@q-ovn-agent.service
               ├─68291 "neutron-ovn-agent: master process [/opt/stack/data/venv/bin/neutron-ovn-agent --config-file /etc/neutron/plugins/ml2/ovn_agent.ini]"
               ├─69566 "neutron-ovn-agent: ServiceWrapper worker(0)"
               ├─69991 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.namespace_cmd --privsep_sock_path /tmp/tmp6pg930cl/privsep.sock
               ├─72437 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.default --privsep_sock_path /tmp/tmpoexj_vsa/privsep.sock
               ├─87902 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.link_cmd --privsep_sock_path /tmp/tmpdh3dhj4v/privsep.sock
               ├─87989 sudo /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
               └─87990 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf

Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35mtcp:127.0.0.1:6640: entering ACTIVE[00m [00;33m{{(pid=77223) _transition /opt/stack/data/venv/lib/python3.12/site-packages/ovs/reconnect.py:519}}[00m
Jul 29 17:33:10 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35m[POLLIN] on fd 23[00m [00;33m{{(pid=77223) __log_wakeup /opt/stack/data/venv/lib/python3.12/site-packages/ovs/poller.py:263}}[00m
Jul 29 17:33:10 np0000031958 devstack@neutron-api.service[69266]: DEBUG dbcounter [[00;36m-] [01;35m[69266] Writing DB stats neutron:UPDATE=1,neutron:SELECT=1[00m [00;33m{{(pid=69266) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:12 np0000031958 neutron-periodic-workers[70924]: DEBUG oslo.service.backend.threading.loopingcall [[01;36mNone req-6e6efc9b-335c-4529-b6e4-bb2825d16694 [00;36mNone None] [01;35mFixed interval looping call 'neutron.plugins.ml2.plugin.DhcpAgentSchedulerDbMixin.remove_networks_from_down_agents' sleeping for 37.00 seconds[00m [00;33m{{(pid=70924) _run_loop /opt/stack/data/venv/lib/python3.12/site-packages/oslo_service/backend/threading/loopingcall.py:165}}[00m
Jul 29 17:33:14 np0000031958 nova-conductor[77283]: DEBUG dbcounter [[00;36m-] [01;35m[77283] Writing DB stats nova_cell1:SELECT=1[00m [00;33m{{(pid=77283) stat_writer /opt/stack/data/venv/lib/python3.12/site-packages/dbcounter.py:115}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69265]: DEBUG futurist.periodics [[00;36m-] [01;35mSubmitting periodic callback 'neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance.HashRingHealthCheckPeriodics.touch_hash_ring_node'[00m [00;33m{{(pid=69265) _process_scheduled /opt/stack/data/venv/lib/python3.12/site-packages/futurist/periodics.py:638}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69265]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[00;36m-] [01;35mTouching Hash Ring node "74a6ae93e9d5577a97b6a02e06fd970f" from periodic health check thread[00m [00;33m{{(pid=69265) touch_hash_ring_node /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:1216}}[00m
Jul 29 17:33:15 np0000031958 nova-compute[77223]: DEBUG ovsdbapp.backend.ovs_idl.vlog [[00;36m-] [01;35m[POLLIN] on fd 23[00m [00;33m{{(pid=77223) __log_wakeup /opt/stack/data/venv/lib/python3.12/site-packages/ovs/poller.py:263}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69266]: DEBUG futurist.periodics [[00;36m-] [01;35mSubmitting periodic callback 'neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance.HashRingHealthCheckPeriodics.touch_hash_ring_node'[00m [00;33m{{(pid=69266) _process_scheduled /opt/stack/data/venv/lib/python3.12/site-packages/futurist/periodics.py:638}}[00m
Jul 29 17:33:15 np0000031958 devstack@neutron-api.service[69266]: DEBUG neutron.plugins.ml2.drivers.ovn.mech_driver.ovsdb.maintenance [[00;36m-] [01;35mTouching Hash Ring node "5886061116525e5ca5ebe31d9d6781d4" from periodic health check thread[00m [00;33m{{(pid=69266) touch_hash_ring_node /opt/stack/neutron/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py:1216}}[00m

● system-getty.slice - Slice /system/getty
     Loaded: loaded
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Tasks: 1
     Memory: 340.0K (peak: 1.8M)
        CPU: 5ms
     CGroup: /system.slice/system-getty.slice
             └─getty@tty1.service
               └─1015 /sbin/agetty -o "-p -- \\u" --noclear - linux

Notice: journal has been rotated since unit was started, output may be incomplete.

● system-glean.slice - Slice /system/glean
     Loaded: loaded
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Tasks: 2
     Memory: 2.8M (peak: 27.4M swap: 4.0K swap peak: 4.0K zswap: 29B)
        CPU: 307ms
     CGroup: /system.slice/system-glean.slice
             ├─glean@enp3s0.service
             │ └─704 dhclient -1 -4 -v -i -pf /run/dhclient.enp3s0.pid -lf /var/lib/dhcp/dhclient.enp3s0.leases -I -df /var/lib/dhcp/dhclient6.enp3s0.leases enp3s0
             └─glean@enp4s0.service
               └─703 dhclient -1 -4 -v -i -pf /run/dhclient.enp4s0.pid -lf /var/lib/dhcp/dhclient.enp4s0.leases -I -df /var/lib/dhcp/dhclient6.enp4s0.leases enp4s0

Jul 29 14:32:55 np0000031958 ifup[795]: Setting LLMNR support level "yes" for "3", but the global support level is "no".
Jul 29 14:32:55 np0000031958 dhclient[704]: Error printing text.
Jul 29 14:32:55 np0000031958 ifup[704]: Error printing text.
Jul 29 14:32:55 np0000031958 root[807]: /etc/dhcp/dhclient-exit-hooks.d/rfc3442-classless-routes returned non-zero exit status 2
Jul 29 14:32:55 np0000031958 dhclient[703]: Error printing text.
Jul 29 14:32:55 np0000031958 ifup[703]: Error printing text.
Jul 29 14:32:55 np0000031958 dhclient[704]: bound to 10.241.128.124 -- renewal in 18632 seconds.
Jul 29 14:32:55 np0000031958 ifup[704]: bound to 10.241.128.124 -- renewal in 18632 seconds.
Jul 29 14:32:55 np0000031958 dhclient[703]: bound to 192.168.1.104 -- renewal in 18632 seconds.
Jul 29 14:32:55 np0000031958 ifup[703]: bound to 192.168.1.104 -- renewal in 18632 seconds.

● system-modprobe.slice - Slice /system/modprobe
     Loaded: loaded
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Tasks: 0
     Memory: 24.0K (peak: 3.2M)
        CPU: 56ms
     CGroup: /system.slice/system-modprobe.slice

Notice: journal has been rotated since unit was started, output may be incomplete.

● system-serial\x2dgetty.slice - Slice /system/serial-getty
     Loaded: loaded
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
      Tasks: 1
     Memory: 256.0K (peak: 1.8M)
        CPU: 4ms
     CGroup: /system.slice/system-serial\x2dgetty.slice
             └─serial-getty@ttyS0.service
               └─1016 /sbin/agetty -o "-p -- \\u" --keep-baud 115200,57600,38400,9600 - vt220

Notice: journal has been rotated since unit was started, output may be incomplete.

● system.slice - System Slice
     Loaded: loaded
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)
      Tasks: 785
     Memory: 5.5G (peak: 6.1G swap: 3.1G swap peak: 3.1G zswap: 720.3M)
        CPU: 27min 19.960s
     CGroup: /system.slice
             ├─apache-htcacheclean.service
             │ └─12079 /usr/bin/htcacheclean -d 120 -p /var/cache/apache2/mod_cache_disk -l 300M -n
             ├─apache2.service
             │ ├─60135 /usr/sbin/apache2 -k start
             │ ├─60141 /usr/sbin/apache2 -k start
             │ └─60142 /usr/sbin/apache2 -k start
             ├─atd.service
             │ └─1007 /usr/sbin/atd -f
             ├─cron.service
             │ └─1005 /usr/sbin/cron -f -P
             ├─dbus.service
             │ └─521 @dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only
             ├─epmd.service
             │ └─17674 /usr/bin/epmd -systemd
             ├─haproxy.service
             │ ├─11224 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
             │ └─11226 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
             ├─haveged.service
             │ └─403 /usr/sbin/haveged --Foreground --verbose=1
             ├─iscsid.service
             │ ├─36013 /usr/sbin/iscsid
             │ └─36014 /usr/sbin/iscsid
             ├─ksmtuned.service
             │ ├─  5739 /bin/bash /usr/sbin/ksmtuned
             │ └─132319 sleep 60
             ├─libvirtd.service
             │ ├─34056 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
             │ ├─34057 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
             │ └─78152 /usr/sbin/libvirtd --timeout 120
             ├─memcached.service
             │ └─47620 /usr/bin/memcached -m 64 -p 11211 -u memcache -l 127.0.0.1 -l ::1 -P /var/run/memcached/memcached.pid
             ├─multipathd.service
             │ └─363 /sbin/multipathd -d -s
             ├─mysql.service
             │ └─44158 /usr/sbin/mysqld
             ├─ovn-controller-vtep.service
             │ └─67159 ovn-controller-vtep -vconsole:emer -vsyslog:err -vfile:info --vtep-db=/var/run/openvswitch/db.sock --ovnsb-db=/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-controller-vtep.log --pidfile=/var/run/ovn/ovn-controller-vtep.pid --detach
             ├─ovn-controller.service
             │ └─67808 ovn-controller unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --no-chdir --log-file=/var/log/ovn/ovn-controller.log --pidfile=/var/run/ovn/ovn-controller.pid --detach
             ├─ovn-northd.service
             │ └─67551 ovn-northd -vconsole:emer -vsyslog:err -vfile:info --ovnnb-db=unix:/var/run/ovn/ovnnb_db.sock --ovnsb-db=unix:/var/run/ovn/ovnsb_db.sock --no-chdir --log-file=/var/log/ovn/ovn-northd.log --pidfile=/var/run/ovn/ovn-northd.pid --detach
             ├─ovn-ovsdb-server-nb.service
             │ └─67478 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-nb.log --remote=punix:/var/run/ovn/ovnnb_db.sock --pidfile=/var/run/ovn/ovnnb_db.pid --unixctl=/var/run/ovn/ovnnb_db.ctl --remote=db:OVN_Northbound,NB_Global,connections --private-key=db:OVN_Northbound,SSL,private_key --certificate=db:OVN_Northbound,SSL,certificate --ca-cert=db:OVN_Northbound,SSL,ca_cert --ssl-protocols=db:OVN_Northbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Northbound,SSL,ssl_ciphers /var/lib/ovn/ovnnb_db.db
             ├─ovn-ovsdb-server-sb.service
             │ └─67479 ovsdb-server -vconsole:off -vfile:info --log-file=/var/log/ovn/ovsdb-server-sb.log --remote=punix:/var/run/ovn/ovnsb_db.sock --pidfile=/var/run/ovn/ovnsb_db.pid --unixctl=/var/run/ovn/ovnsb_db.ctl --remote=db:OVN_Southbound,SB_Global,connections --private-key=db:OVN_Southbound,SSL,private_key --certificate=db:OVN_Southbound,SSL,certificate --ca-cert=db:OVN_Southbound,SSL,ca_cert --ssl-protocols=db:OVN_Southbound,SSL,ssl_protocols --ssl-ciphers=db:OVN_Southbound,SSL,ssl_ciphers /var/lib/ovn/ovnsb_db.db
             ├─ovs-vswitchd.service
             │ └─67077 ovs-vswitchd unix:/var/run/openvswitch/db.sock -vconsole:emer -vsyslog:err -vfile:info --mlockall --no-chdir --log-file=/var/log/openvswitch/ovs-vswitchd.log --pidfile=/var/run/openvswitch/ovs-vswitchd.pid --detach
             ├─ovsdb-server.service
             │ └─66880 ovsdb-server /etc/openvswitch/conf.db -vconsole:emer -vsyslog:err -vfile:info --remote=punix:/var/run/openvswitch/db.sock --private-key=db:Open_vSwitch,SSL,private_key --certificate=db:Open_vSwitch,SSL,certificate --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert --no-chdir --log-file=/var/log/openvswitch/ovsdb-server.log --pidfile=/var/run/openvswitch/ovsdb-server.pid --detach
             ├─polkit.service
             │ └─1336 /usr/lib/polkit-1/polkitd --no-debug
             ├─pure-boot.service
             │ └─988 dhclient
             ├─rabbitmq-server.service
             │ ├─17789 /usr/lib/erlang/erts-13.2.2.5/bin/beam.smp -W w -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -pc unicode -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -sbwt none -sbwtdcpu none -sbwtdio none -- -root /usr/lib/erlang -bindir /usr/lib/erlang/erts-13.2.2.5/bin -progname erl -- -home /var/lib/rabbitmq -- -pa "" -noshell -noinput -s rabbit boot -boot start_sasl -syslog logger "[]" -syslog syslog_error_logger false -kernel prevent_overlapping_partitions false -enable-feature maybe_expr
             │ ├─17799 erl_child_setup 65536
             │ ├─17875 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
             │ ├─17876 /usr/lib/erlang/erts-13.2.2.5/bin/inet_gethost 4
             │ └─17879 /bin/sh -s rabbit_disk_monitor
             ├─rsyslog.service
             │ └─15219 /usr/sbin/rsyslogd -n -iNONE
             ├─ssh.service
             │ └─860 "sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups"
             ├─system-devstack.slice
             │ ├─devstack@c-api.service
             │ │ ├─78016 "cinder-apiuWSGI master"
             │ │ ├─78022 "cinder-apiuWSGI worker 1"
             │ │ └─78023 "cinder-apiuWSGI worker 2"
             │ ├─devstack@c-sch.service
             │ │ └─78804 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf
             │ ├─devstack@c-vol.service
             │ │ ├─79416 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             │ │ ├─80100 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/cinder-volume --config-file /etc/cinder/cinder.conf
             │ │ ├─91425 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context cinder.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmpk5wqr2on/privsep.sock
             │ │ └─91489 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/cinder/cinder.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmpohtseool/privsep.sock
             │ ├─devstack@etcd.service
             │ │ └─45936 /opt/stack/bin/etcd --name np0000031958 --data-dir /opt/stack/data/etcd --initial-cluster-state new --initial-cluster-token etcd-cluster-01 --initial-cluster np0000031958=http://192.168.1.104:2380 --initial-advertise-peer-urls http://192.168.1.104:2380 --advertise-client-urls http://192.168.1.104:2379 --listen-peer-urls http://0.0.0.0:2380 --listen-client-urls http://192.168.1.104:2379 --log-level=debug
             │ ├─devstack@file_tracker.service
             │ │ ├─ 45281 /bin/bash /opt/stack/devstack/tools/file_tracker.sh
             │ │ └─134026 sleep 20
             │ ├─devstack@g-api.service
             │ │ ├─80178 "glance-apiuWSGI master"
             │ │ ├─80179 "glance-apiuWSGI worker 1"
             │ │ └─80180 "glance-apiuWSGI worker 2"
             │ ├─devstack@keystone.service
             │ │ ├─47211 "keystoneuWSGI master"
             │ │ ├─47212 "keystoneuWSGI worker 1"
             │ │ └─47213 "keystoneuWSGI worker 2"
             │ ├─devstack@memory_tracker.service
             │ │ ├─ 44799 /bin/bash /opt/stack/devstack/tools/memory_tracker.sh
             │ │ └─132658 sleep 20
             │ ├─devstack@n-api-meta.service
             │ │ ├─74275 "nova-api-metauWSGI master"
             │ │ ├─74276 "nova-api-metauWSGI worker 1"
             │ │ ├─74277 "nova-api-metauWSGI worker 2"
             │ │ └─74278 "nova-api-metauWSGI http 1"
             │ ├─devstack@n-api.service
             │ │ ├─66388 "nova-apiuWSGI master"
             │ │ ├─66389 "nova-apiuWSGI worker 1"
             │ │ └─66390 "nova-apiuWSGI worker 2"
             │ ├─devstack@n-cond-cell1.service
             │ │ ├─76172 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ │ ├─77282 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ │ └─77283 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova_cell1.conf
             │ ├─devstack@n-cpu.service
             │ │ ├─77223 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-compute --config-file /etc/nova/nova-cpu.conf
             │ │ ├─87718 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context nova.privsep.sys_admin_pctxt --privsep_sock_path /tmp/tmps6_q_fui/privsep.sock
             │ │ ├─87756 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context vif_plug_ovs.privsep.vif_plug --privsep_sock_path /tmp/tmprul1wut5/privsep.sock
             │ │ └─88388 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/nova/nova-cpu.conf --privsep_context os_brick.privileged.default --privsep_sock_path /tmp/tmp9ppv4ep2/privsep.sock
             │ ├─devstack@n-novnc-cell1.service
             │ │ └─74890 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-novncproxy --config-file /etc/nova/nova_cell1.conf --web /usr/share/novnc
             │ ├─devstack@n-sch.service
             │ │ ├─73694 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ │ ├─74771 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ │ └─74773 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-scheduler --config-file /etc/nova/nova.conf
             │ ├─devstack@n-super-cond.service
             │ │ ├─75663 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ │ ├─77004 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ │ └─77006 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/nova-conductor --config-file /etc/nova/nova.conf
             │ ├─devstack@neutron-api.service
             │ │ ├─69264 "neutron-apiuWSGI master"
             │ │ ├─69265 "neutron-apiuWSGI worker 1"
             │ │ └─69266 "neutron-apiuWSGI worker 2"
             │ ├─devstack@neutron-ovn-maintenance-worker.service
             │ │ ├─70814 "neutron-ovn-maintenance-worker: master process [/opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ │ └─71478 "neutron-server: maintenance worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-ovn-maintenance-worker --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ ├─devstack@neutron-periodic-workers.service
             │ │ ├─70339 "neutron-periodic-workers: master process [/opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ │ ├─70924 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ ├─70940 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ ├─70960 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ │ └─70970 "neutron-server: periodic worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-periodic-workers --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ ├─devstack@neutron-rpc-server.service
             │ │ ├─69866 "neutron-rpc-server: master process [/opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini]"
             │ │ └─71411 "neutron-server: rpc worker (/opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rpc-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini)"
             │ ├─devstack@openstack-cli-server.service
             │ │ └─43414 /opt/stack/data/venv/bin/python3 /opt/stack/devstack/files/openstack-cli-server/openstack-cli-server
             │ ├─devstack@placement-api.service
             │ │ ├─71602 "placementuWSGI master"
             │ │ ├─71603 "placementuWSGI worker 1"
             │ │ └─71604 "placementuWSGI worker 2"
             │ └─devstack@q-ovn-agent.service
             │   ├─68291 "neutron-ovn-agent: master process [/opt/stack/data/venv/bin/neutron-ovn-agent --config-file /etc/neutron/plugins/ml2/ovn_agent.ini]"
             │   ├─69566 "neutron-ovn-agent: ServiceWrapper worker(0)"
             │   ├─69991 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.namespace_cmd --privsep_sock_path /tmp/tmp6pg930cl/privsep.sock
             │   ├─72437 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.default --privsep_sock_path /tmp/tmpoexj_vsa/privsep.sock
             │   ├─87902 /opt/stack/data/venv/bin/python3.12 /usr/local/bin/privsep-helper --config-file /etc/neutron/plugins/ml2/ovn_agent.ini --privsep_context neutron.privileged.link_cmd --privsep_sock_path /tmp/tmpdh3dhj4v/privsep.sock
             │   ├─87989 sudo /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
             │   └─87990 /opt/stack/data/venv/bin/python3.12 /opt/stack/data/venv/bin/neutron-rootwrap-daemon /etc/neutron/rootwrap.conf
             ├─system-getty.slice
             │ └─getty@tty1.service
             │   └─1015 /sbin/agetty -o "-p -- \\u" --noclear - linux
             ├─system-glean.slice
             │ ├─glean@enp3s0.service
             │ │ └─704 dhclient -1 -4 -v -i -pf /run/dhclient.enp3s0.pid -lf /var/lib/dhcp/dhclient.enp3s0.leases -I -df /var/lib/dhcp/dhclient6.enp3s0.leases enp3s0
             │ └─glean@enp4s0.service
             │   └─703 dhclient -1 -4 -v -i -pf /run/dhclient.enp4s0.pid -lf /var/lib/dhcp/dhclient.enp4s0.leases -I -df /var/lib/dhcp/dhclient6.enp4s0.leases enp4s0
             ├─system-serial\x2dgetty.slice
             │ └─serial-getty@ttyS0.service
             │   └─1016 /sbin/agetty -o "-p -- \\u" --keep-baud 115200,57600,38400,9600 - vt220
             ├─systemd-journald.service
             │ └─16765 /usr/lib/systemd/systemd-journald
             ├─systemd-logind.service
             │ └─531 /usr/lib/systemd/systemd-logind
             ├─systemd-machined.service
             │ └─33939 /usr/lib/systemd/systemd-machined
             ├─systemd-networkd.service
             │ └─845 /usr/lib/systemd/systemd-networkd
             ├─systemd-resolved.service
             │ └─408 /usr/lib/systemd/systemd-resolved
             ├─systemd-timesyncd.service
             │ └─409 /usr/lib/systemd/systemd-timesyncd
             ├─systemd-udevd.service
             │ └─udev
             │   └─378 /usr/lib/systemd/systemd-udevd
             ├─virtlockd.service
             │ └─34172 /usr/sbin/virtlockd
             └─virtlogd.service
               └─40311 /usr/sbin/virtlogd

Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70240|poll_loop|DBG|wakeup due to [POLLIN] on fd 22 (192.168.1.104:6642<->192.168.1.104:36552) at ../lib/stream-ssl.c:842 (0% CPU usage)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70241|stream_ssl|DBG|server0<--ssl:192.168.1.104:36552 type 256 (5 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70242|stream_ssl|DBG|server0<--ssl:192.168.1.104:36552 type 257 (1 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70243|jsonrpc|DBG|ssl:192.168.1.104:36552: received request, method="echo", params=[], id="echo"
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70244|jsonrpc|DBG|ssl:192.168.1.104:36552: send reply, result=[], id="echo"
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70245|stream_ssl|DBG|server0-->ssl:192.168.1.104:36552 type 256 (5 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70246|stream_ssl|DBG|server0-->ssl:192.168.1.104:36552 type 257 (1 bytes)
Jul 29 17:33:13 np0000031958 ovsdb-server[67479]: ovs|70247|poll_loop|DBG|wakeup due to 0-ms timeout at ../lib/stream-ssl.c:844 (0% CPU usage)
Jul 29 17:33:15 np0000031958 ovsdb-server[67479]: ovs|70248|poll_loop|DBG|wakeup due to 2028-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)
Jul 29 17:33:15 np0000031958 ovsdb-server[67478]: ovs|73531|poll_loop|DBG|wakeup due to 2502-ms timeout at ../ovsdb/ovsdb-server.c:400 (0% CPU usage)

● user-1000.slice - User Slice of UID 1000
     Loaded: loaded
    Drop-In: /usr/lib/systemd/system/user-.slice.d
             └─10-defaults.conf
     Active: active since Tue 2025-07-29 16:38:24 UTC; 54min ago
       Docs: man:user@.service(5)
      Tasks: 16 (limit: 20778)
     Memory: 857.3M (peak: 7.1G swap: 5.8M swap peak: 128.9M zswap: 1.6M)
        CPU: 12min 54.755s
     CGroup: /user.slice/user-1000.slice
             ├─session-12.scope
             │ ├─132488 "sshd: zuul [priv]"
             │ ├─132498 "sshd: zuul@notty"
             │ ├─134021 /bin/sh -c "sudo -H -S -n  -u root /bin/sh -c 'echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3' && sleep 0"
             │ ├─134022 sudo -H -S -n -u root /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
             │ ├─134023 /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
             │ ├─134024 /usr/bin/python3
             │ ├─134027 /bin/bash -c "sudo iptables-save > /home/zuul/iptables.txt\ndf -h > /home/zuul/df.txt\n\nfor py_ver in 2 3; do\n    if [[ \`which python\${py_ver}\` ]]; then\n        python\${py_ver} -m pip freeze > /home/zuul/pip\${py_ver}-freeze.txt\n    fi\ndone\n\nif [ \`command -v dpkg\` ]; then\n    dpkg -l> /home/zuul/dpkg-l.txt\nfi\nif [ \`command -v rpm\` ]; then\n    rpm -qa | sort > /home/zuul/rpm-qa.txt\nfi\n\n# Services status\nsudo systemctl status --all > services.txt 2>/dev/null\n\n# NOTE(kchamart) The 'audit.log' can be useful in cases when QEMU\n# failed to start due to denials from SELinux — useful for CentOS\n# and Fedora machines.  For Ubuntu (which runs AppArmor), DevStack\n# already captures the contents of /var/log/kern.log (via\n# \`journalctl -t kernel\` redirected into syslog.txt.gz), which\n# contains AppArmor-related messages.\nif [ -f /var/log/audit/audit.log ] ; then\n    sudo cp /var/log/audit/audit.log /home/zuul/audit.log &&\n    chmod +r /home/zuul/audit.log;\nfi\n\n# gzip and save any coredumps in /var/core\nif [ -d /var/core ]; then\n    sudo gzip -r /var/core\n    sudo cp -r /var/core /home/zuul/\nfi\n\nsudo ss -lntup | grep ':53' > /home/zuul/listen53.txt\n\n# NOTE(andreaf) Service logs are already in logs/ thanks for the\n# export-devstack-journal log. Apache logs are under apache/ thans to the\n# apache-logs-conf role.\ngrep -i deprecat /home/zuul/logs/*.txt /home/zuul/apache/*.log | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}\\.[0-9]{1,3}/ /g' | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}/ /g' | \\\n    sed -r 's/[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}/ /g' |\n    sed -r 's/\\[.*\\]/ /g' | \\\n    sed -r 's/\\s[0-9]+\\s/ /g' | \\\n    awk '{if (\$0 in seen) {seen[\$0]++} else {out[++n]=\$0;seen[\$0]=1}} END { for (i=1; i<=n; i++) print seen[out[i]]\" :: \" out[i] }' > /home/zuul/deprecations.log\n"
             │ ├─134038 sudo systemctl status --all
             │ └─134039 systemctl status --all
             ├─session-3.scope
             │ └─1747 /usr/bin/python3
             └─user@1000.service
               └─init.scope
                 ├─1605 /usr/lib/systemd/systemd --user
                 └─1606 "(sd-pam)"

Jul 29 17:33:15 np0000031958 python3[134015]: ansible-ansible.legacy.command Invoked with _raw_params=cp -pRL /etc/openstack /home/zuul/etc/ zuul_log_id=fa163e4d-f4e4-406c-fe2b-00000000002f-1-controller zuul_ansible_split_streams=False _uses_shell=False warn=False stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
Jul 29 17:33:15 np0000031958 sudo[134013]: pam_unix(sudo:session): session closed for user root
Jul 29 17:33:16 np0000031958 sudo[134022]:     zuul : PWD=/home/zuul ; USER=root ; COMMAND=/bin/sh -c 'echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3'
Jul 29 17:33:16 np0000031958 sudo[134022]: pam_unix(sudo:session): session opened for user root(uid=0) by zuul(uid=1000)
Jul 29 17:33:16 np0000031958 python3[134024]: ansible-ansible.legacy.command Invoked with executable=/bin/bash _raw_params=sudo iptables-save > /home/zuul/iptables.txt
                                              df -h > /home/zuul/df.txt
                                              
                                              for py_ver in 2 3; do
                                                  if [[ `which python${py_ver}` ]]; then
                                                      python${py_ver} -m pip freeze > /home/zuul/pip${py_ver}-freeze.txt
                                                  fi
                                              done
                                              
                                              if [ `command -v dpkg` ]; then
                                                  dpkg -l> /home/zuul/dpkg-l.txt
                                              fi
                                              if [ `command -v rpm` ]; then
                                                  rpm -qa | sort > /home/zuul/rpm-qa.txt
                                              fi
                                              
                                              # Services status
                                              sudo systemctl status --all > services.txt 2>/dev/null
                                              
                                              # NOTE(kchamart) The 'audit.log' can be useful in cases when QEMU
                                              # failed to start due to denials from SELinux — useful for CentOS
                                              # and Fedora machines.  For Ubuntu (which runs AppArmor), DevStack
                                              # already captures the contents of /var/log/kern.log (via
                                              # `journalctl -t kernel` redirected into syslog.txt.gz), which
                                              # contains AppArmor-related messages.
                                              if [ -f /var/log/audit/audit.log ] ; then
                                                  sudo cp /var/log/audit/audit.log /home/zuul/audit.log &&
                                                  chmod +r /home/zuul/audit.log;
                                              fi
                                              
                                              # gzip and save any coredumps in /var/core
                                              if [ -d /var/core ]; then
                                                  sudo gzip -r /var/core
                                                  sudo cp -r /var/core /home/zuul/
                                              fi
                                              
                                              sudo ss -lntup | grep ':53' > /home/zuul/listen53.txt
                                              
                                              # NOTE(andreaf) Service logs are already in logs/ thanks for the
                                              # export-devstack-journal log. Apache logs are under apache/ thans to the
                                              # apache-logs-conf role.
                                              grep -i deprecat /home/zuul/logs/*.txt /home/zuul/apache/*.log | \
                                                  sed -r 's/[0-9]{1,2}\:[0-9]{1,2}\:[0-9]{1,2}\.[0-9]{1,3}/ /g' | \
                                                  sed -r 's/[0-9]{1,2}\:[0-9]{1,2}\:[0-9]{1,2}/ /g' | \
                                                  sed -r 's/[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}/ /g' |
                                                  sed -r 's/\[.*\]/ /g' | \
                                                  sed -r 's/\s[0-9]+\s/ /g' | \
                                                  awk '{if ($0 in seen) {seen[$0]++} else {out[++n]=$0;seen[$0]=1}} END { for (i=1; i<=n; i++) print seen[out[i]]" :: " out[i] }' > /home/zuul/deprecations.log
                                               _uses_shell=True zuul_log_id=fa163e4d-f4e4-406c-fe2b-000000000033-1-controller zuul_ansible_split_streams=False warn=False stdin_add_newline=True strip_empty_ends=True argv=None chdir=None creates=None removes=None stdin=None
Jul 29 17:33:16 np0000031958 sudo[134029]:     root : PWD=/home/zuul ; USER=root ; COMMAND=/usr/sbin/iptables-save
Jul 29 17:33:16 np0000031958 sudo[134029]: pam_unix(sudo:session): session opened for user root(uid=0) by zuul(uid=0)
Jul 29 17:33:16 np0000031958 sudo[134029]: pam_unix(sudo:session): session closed for user root
Jul 29 17:33:16 np0000031958 sudo[134038]:     root : PWD=/home/zuul ; USER=root ; COMMAND=/usr/bin/systemctl status --all
Jul 29 17:33:16 np0000031958 sudo[134038]: pam_unix(sudo:session): session opened for user root(uid=0) by zuul(uid=0)

● user.slice - User and Session Slice
     Loaded: loaded (/usr/lib/systemd/system/user.slice; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)
      Tasks: 16
     Memory: 857.6M (peak: 7.1G swap: 5.8M swap peak: 128.9M zswap: 1.6M)
        CPU: 12min 54.760s
     CGroup: /user.slice
             └─user-1000.slice
               ├─session-12.scope
               │ ├─132488 "sshd: zuul [priv]"
               │ ├─132498 "sshd: zuul@notty"
               │ ├─134021 /bin/sh -c "sudo -H -S -n  -u root /bin/sh -c 'echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3' && sleep 0"
               │ ├─134022 sudo -H -S -n -u root /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
               │ ├─134023 /bin/sh -c "echo BECOME-SUCCESS-uhjlaxqjoedulbbqnmnahfjswozazxjx ; /usr/bin/python3"
               │ ├─134024 /usr/bin/python3
               │ ├─134027 /bin/bash -c "sudo iptables-save > /home/zuul/iptables.txt\ndf -h > /home/zuul/df.txt\n\nfor py_ver in 2 3; do\n    if [[ \`which python\${py_ver}\` ]]; then\n        python\${py_ver} -m pip freeze > /home/zuul/pip\${py_ver}-freeze.txt\n    fi\ndone\n\nif [ \`command -v dpkg\` ]; then\n    dpkg -l> /home/zuul/dpkg-l.txt\nfi\nif [ \`command -v rpm\` ]; then\n    rpm -qa | sort > /home/zuul/rpm-qa.txt\nfi\n\n# Services status\nsudo systemctl status --all > services.txt 2>/dev/null\n\n# NOTE(kchamart) The 'audit.log' can be useful in cases when QEMU\n# failed to start due to denials from SELinux — useful for CentOS\n# and Fedora machines.  For Ubuntu (which runs AppArmor), DevStack\n# already captures the contents of /var/log/kern.log (via\n# \`journalctl -t kernel\` redirected into syslog.txt.gz), which\n# contains AppArmor-related messages.\nif [ -f /var/log/audit/audit.log ] ; then\n    sudo cp /var/log/audit/audit.log /home/zuul/audit.log &&\n    chmod +r /home/zuul/audit.log;\nfi\n\n# gzip and save any coredumps in /var/core\nif [ -d /var/core ]; then\n    sudo gzip -r /var/core\n    sudo cp -r /var/core /home/zuul/\nfi\n\nsudo ss -lntup | grep ':53' > /home/zuul/listen53.txt\n\n# NOTE(andreaf) Service logs are already in logs/ thanks for the\n# export-devstack-journal log. Apache logs are under apache/ thans to the\n# apache-logs-conf role.\ngrep -i deprecat /home/zuul/logs/*.txt /home/zuul/apache/*.log | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}\\.[0-9]{1,3}/ /g' | \\\n    sed -r 's/[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}/ /g' | \\\n    sed -r 's/[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}/ /g' |\n    sed -r 's/\\[.*\\]/ /g' | \\\n    sed -r 's/\\s[0-9]+\\s/ /g' | \\\n    awk '{if (\$0 in seen) {seen[\$0]++} else {out[++n]=\$0;seen[\$0]=1}} END { for (i=1; i<=n; i++) print seen[out[i]]\" :: \" out[i] }' > /home/zuul/deprecations.log\n"
               │ ├─134038 sudo systemctl status --all
               │ └─134039 systemctl status --all
               ├─session-3.scope
               │ └─1747 /usr/bin/python3
               └─user@1000.service
                 └─init.scope
                   ├─1605 /usr/lib/systemd/systemd --user
                   └─1606 "(sd-pam)"

Notice: journal has been rotated since unit was started, output may be incomplete.

● acpid.socket - ACPID Listen Socket
     Loaded: loaded (/usr/lib/systemd/system/acpid.socket; enabled; preset: enabled)
     Active: active (listening) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Triggers: ● acpid.service
     Listen: /run/acpid.socket (Stream)
     CGroup: /system.slice/acpid.socket

Jul 29 14:32:53 ubuntu systemd[1]: Listening on acpid.socket - ACPID Listen Socket.

● dbus.socket - D-Bus System Message Bus Socket
     Loaded: loaded (/usr/lib/systemd/system/dbus.socket; static)
     Active: active (running) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Triggers: ● dbus.service
     Listen: /run/dbus/system_bus_socket (Stream)
     CGroup: /system.slice/dbus.socket

Jul 29 14:32:53 ubuntu systemd[1]: Listening on dbus.socket - D-Bus System Message Bus Socket.

● dm-event.socket - Device-mapper event daemon FIFOs
     Loaded: loaded (/usr/lib/systemd/system/dm-event.socket; enabled; preset: enabled)
     Active: active (listening) since Tue 2025-07-29 16:43:18 UTC; 49min ago
   Triggers: ● dm-event.service
       Docs: man:dmeventd(8)
     Listen: /run/dmeventd-server (FIFO)
             /run/dmeventd-client (FIFO)
     CGroup: /system.slice/dm-event.socket

Jul 29 16:43:18 np0000031958 systemd[1]: Listening on dm-event.socket - Device-mapper event daemon FIFOs.

● epmd.socket - Erlang Port Mapper Daemon Activation Socket
     Loaded: loaded (/usr/lib/systemd/system/epmd.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:43:55 UTC; 49min ago
   Triggers: ● epmd.service
     Listen: [::]:4369 (Stream)
      Tasks: 0 (limit: 9444)
     Memory: 8.0K (peak: 256.0K)
        CPU: 256us
     CGroup: /system.slice/epmd.socket

Jul 29 16:43:55 np0000031958 systemd[1]: Listening on epmd.socket - Erlang Port Mapper Daemon Activation Socket.

● iscsid.socket - Open-iSCSI iscsid Socket
     Loaded: loaded (/usr/lib/systemd/system/iscsid.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Triggers: ● iscsid.service
       Docs: man:iscsid(8)
             man:iscsiadm(8)
     Listen: @ISCSIADM_ABSTRACT_NAMESPACE (Stream)
     CGroup: /system.slice/iscsid.socket

Jul 29 14:32:53 ubuntu systemd[1]: Listening on iscsid.socket - Open-iSCSI iscsid Socket.

● libvirtd-admin.socket - libvirt legacy monolithic daemon admin socket
     Loaded: loaded (/usr/lib/systemd/system/libvirtd-admin.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:26 UTC; 41min ago
   Triggers: ● libvirtd.service
     Listen: /run/libvirt/libvirt-admin-sock (Stream)
     CGroup: /system.slice/libvirtd-admin.socket

Jul 29 16:51:26 np0000031958 systemd[1]: Listening on libvirtd-admin.socket - libvirt legacy monolithic daemon admin socket.

● libvirtd-ro.socket - libvirt legacy monolithic daemon read-only socket
     Loaded: loaded (/usr/lib/systemd/system/libvirtd-ro.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:26 UTC; 41min ago
   Triggers: ● libvirtd.service
     Listen: /run/libvirt/libvirt-sock-ro (Stream)
     CGroup: /system.slice/libvirtd-ro.socket

Jul 29 16:51:26 np0000031958 systemd[1]: Listening on libvirtd-ro.socket - libvirt legacy monolithic daemon read-only socket.

● libvirtd.socket - libvirt legacy monolithic daemon socket
     Loaded: loaded (/usr/lib/systemd/system/libvirtd.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:26 UTC; 41min ago
   Triggers: ● libvirtd.service
     Listen: /run/libvirt/libvirt-sock (Stream)
      Tasks: 0 (limit: 9444)
     Memory: 0B (peak: 256.0K)
        CPU: 394us
     CGroup: /system.slice/libvirtd.socket

Jul 29 16:51:26 np0000031958 systemd[1]: Starting libvirtd.socket - libvirt legacy monolithic daemon socket...
Jul 29 16:51:26 np0000031958 systemd[1]: Listening on libvirtd.socket - libvirt legacy monolithic daemon socket.

● lvm2-lvmpolld.socket - LVM2 poll daemon socket
     Loaded: loaded (/usr/lib/systemd/system/lvm2-lvmpolld.socket; enabled; preset: enabled)
     Active: active (listening) since Tue 2025-07-29 16:43:19 UTC; 49min ago
   Triggers: ● lvm2-lvmpolld.service
       Docs: man:lvmpolld(8)
     Listen: /run/lvm/lvmpolld.socket (Stream)
     CGroup: /system.slice/lvm2-lvmpolld.socket

Jul 29 16:43:19 np0000031958 systemd[1]: Listening on lvm2-lvmpolld.socket - LVM2 poll daemon socket.

● multipathd.socket - multipathd control socket
     Loaded: loaded (/usr/lib/systemd/system/multipathd.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● multipathd.service
     Listen: @/org/kernel/linux/storage/multipathd (Stream)
     CGroup: /system.slice/multipathd.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

● ssh.socket - OpenBSD Secure Shell server socket
     Loaded: loaded (/usr/lib/systemd/system/ssh.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Triggers: ● ssh.service
     Listen: 0.0.0.0:22 (Stream)
             [::]:22 (Stream)
      Tasks: 0 (limit: 9444)
     Memory: 12.0K (peak: 264.0K)
        CPU: 638us
     CGroup: /system.slice/ssh.socket

Jul 29 14:32:53 ubuntu systemd[1]: Listening on ssh.socket - OpenBSD Secure Shell server socket.

● syslog.socket - Syslog Socket
     Loaded: loaded (/usr/lib/systemd/system/syslog.socket; static)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● rsyslog.service
       Docs: man:systemd.special(7)
             https://www.freedesktop.org/wiki/Software/systemd/syslog
     Listen: /run/systemd/journal/syslog (Datagram)
     CGroup: /system.slice/syslog.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

● systemd-coredump.socket - Process Core Dump Socket
     Loaded: loaded (/usr/lib/systemd/system/systemd-coredump.socket; static)
     Active: active (listening) since Tue 2025-07-29 16:51:24 UTC; 41min ago
       Docs: man:systemd-coredump(8)
     Listen: /run/systemd/coredump (SequentialPacket)
   Accepted: 0; Connected: 0;
     CGroup: /system.slice/systemd-coredump.socket

Jul 29 16:51:24 np0000031958 systemd[1]: Listening on systemd-coredump.socket - Process Core Dump Socket.

● systemd-fsckd.socket - fsck to fsckd communication Socket
     Loaded: loaded (/usr/lib/systemd/system/systemd-fsckd.socket; static)
     Active: active (listening) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-fsckd.service
       Docs: man:systemd-fsckd.service(8)
             man:systemd-fsck@.service(8)
             man:systemd-fsck-root.service(8)
     Listen: /run/systemd/fsck.progress (Stream)
     CGroup: /system.slice/systemd-fsckd.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

● systemd-initctl.socket - initctl Compatibility Named Pipe
     Loaded: loaded (/usr/lib/systemd/system/systemd-initctl.socket; static)
     Active: active (listening) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-initctl.service
       Docs: man:systemd-initctl.socket(8)
     Listen: /run/initctl (FIFO)
     CGroup: /system.slice/systemd-initctl.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

○ systemd-journald-audit.socket - Journal Audit Socket
     Loaded: loaded (/usr/lib/systemd/system/systemd-journald-audit.socket; disabled; preset: enabled)
     Active: inactive (dead)
   Triggers: ● systemd-journald.service
       Docs: man:systemd-journald.service(8)
             man:journald.conf(5)
     Listen: audit 1 (Netlink)

● systemd-journald-dev-log.socket - Journal Socket (/dev/log)
     Loaded: loaded (/usr/lib/systemd/system/systemd-journald-dev-log.socket; static)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-journald.service
       Docs: man:systemd-journald.service(8)
             man:journald.conf(5)
     Listen: /run/systemd/journal/dev-log (Datagram)
     CGroup: /system.slice/systemd-journald-dev-log.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

● systemd-journald.socket - Journal Socket
     Loaded: loaded (/usr/lib/systemd/system/systemd-journald.socket; static)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-journald.service
       Docs: man:systemd-journald.service(8)
             man:journald.conf(5)
     Listen: /run/systemd/journal/socket (Datagram)
             /run/systemd/journal/stdout (Stream)
     CGroup: /system.slice/systemd-journald.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

● systemd-networkd.socket - Network Service Netlink Socket
     Loaded: loaded (/usr/lib/systemd/system/systemd-networkd.socket; disabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-networkd.service
       Docs: man:systemd-networkd.service(8)
             man:rtnetlink(7)
     Listen: route 1361 (Netlink)
     CGroup: /system.slice/systemd-networkd.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

○ systemd-pcrextend.socket - TPM2 PCR Extension (Varlink)
     Loaded: loaded (/usr/lib/systemd/system/systemd-pcrextend.socket; disabled; preset: enabled)
     Active: inactive (dead)
  Condition: start condition unmet at Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-pcrextend(8)
     Listen: /run/systemd/io.systemd.PCRExtend (Stream)
   Accepted: 0; Connected: 0;

● systemd-rfkill.socket - Load/Save RF Kill Switch Status /dev/rfkill Watch
     Loaded: loaded (/usr/lib/systemd/system/systemd-rfkill.socket; static)
     Active: active (listening) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-rfkill.service
       Docs: man:systemd-rfkill.socket(8)
     Listen: /dev/rfkill (Special)
     CGroup: /system.slice/systemd-rfkill.socket

Jul 29 14:32:52 ubuntu systemd[1]: Listening on systemd-rfkill.socket - Load/Save RF Kill Switch Status /dev/rfkill Watch.

● systemd-sysext.socket - System Extension Image Management (Varlink)
     Loaded: loaded (/usr/lib/systemd/system/systemd-sysext.socket; disabled; preset: enabled)
     Active: active (listening) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd-sysext(8)
     Listen: /run/systemd/io.systemd.sysext (Stream)
   Accepted: 0; Connected: 0;
     CGroup: /system.slice/systemd-sysext.socket

Jul 29 14:32:52 ubuntu systemd[1]: Listening on systemd-sysext.socket - System Extension Image Management (Varlink).

● systemd-udevd-control.socket - udev Control Socket
     Loaded: loaded (/usr/lib/systemd/system/systemd-udevd-control.socket; static)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-udevd.service
       Docs: man:systemd-udevd-control.socket(8)
             man:udev(7)
     Listen: /run/udev/control (SequentialPacket)
     CGroup: /system.slice/systemd-udevd-control.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

● systemd-udevd-kernel.socket - udev Kernel Socket
     Loaded: loaded (/usr/lib/systemd/system/systemd-udevd-kernel.socket; static)
     Active: active (running) since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
   Triggers: ● systemd-udevd.service
       Docs: man:systemd-udevd-kernel.socket(8)
             man:udev(7)
     Listen: kobject-uevent 1 (Netlink)
     CGroup: /system.slice/systemd-udevd-kernel.socket

Notice: journal has been rotated since unit was started, output may be incomplete.

● uuidd.socket - UUID daemon activation socket
     Loaded: loaded (/usr/lib/systemd/system/uuidd.socket; enabled; preset: enabled)
     Active: active (listening) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
   Triggers: ● uuidd.service
     Listen: /run/uuidd/request (Stream)
     CGroup: /system.slice/uuidd.socket

Jul 29 14:32:53 ubuntu systemd[1]: Listening on uuidd.socket - UUID daemon activation socket.

● virtlockd-admin.socket - libvirt locking daemon admin socket
     Loaded: loaded (/usr/lib/systemd/system/virtlockd-admin.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:27 UTC; 41min ago
   Triggers: ● virtlockd.service
     Listen: /run/libvirt/virtlockd-admin-sock (Stream)
     CGroup: /system.slice/virtlockd-admin.socket

Jul 29 16:51:27 np0000031958 systemd[1]: Listening on virtlockd-admin.socket - libvirt locking daemon admin socket.

● virtlockd.socket - libvirt locking daemon socket
     Loaded: loaded (/usr/lib/systemd/system/virtlockd.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:26 UTC; 41min ago
   Triggers: ● virtlockd.service
     Listen: /run/libvirt/virtlockd-sock (Stream)
     CGroup: /system.slice/virtlockd.socket

Jul 29 16:51:26 np0000031958 systemd[1]: Listening on virtlockd.socket - libvirt locking daemon socket.

● virtlogd-admin.socket - libvirt logging daemon admin socket
     Loaded: loaded (/usr/lib/systemd/system/virtlogd-admin.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:27 UTC; 41min ago
   Triggers: ● virtlogd.service
     Listen: /run/libvirt/virtlogd-admin-sock (Stream)
     CGroup: /system.slice/virtlogd-admin.socket

Jul 29 16:51:27 np0000031958 systemd[1]: Listening on virtlogd-admin.socket - libvirt logging daemon admin socket.

● virtlogd.socket - libvirt logging daemon socket
     Loaded: loaded (/usr/lib/systemd/system/virtlogd.socket; enabled; preset: enabled)
     Active: active (running) since Tue 2025-07-29 16:51:26 UTC; 41min ago
   Triggers: ● virtlogd.service
     Listen: /run/libvirt/virtlogd-sock (Stream)
     CGroup: /system.slice/virtlogd.socket

Jul 29 16:51:26 np0000031958 systemd[1]: Listening on virtlogd.socket - libvirt logging daemon socket.

● root-swapfile.swap - /root/swapfile
     Loaded: loaded (/etc/fstab; generated)
     Active: active since Tue 2025-07-29 16:39:59 UTC; 53min ago
       What: /root/swapfile
       Docs: man:fstab(5)
             man:systemd-fstab-generator(8)

● basic.target - Basic System
     Loaded: loaded (/usr/lib/systemd/system/basic.target; static)
     Active: active since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:53 ubuntu systemd[1]: Reached target basic.target - Basic System.

○ blockdev@dev-disk-by\x2dlabel-cloudimg\x2drootfs.target - Block Device Preparation for /dev/disk/by-label/cloudimg-rootfs
     Loaded: loaded (/usr/lib/systemd/system/blockdev@.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ blockdev@dev-sr0.target - Block Device Preparation for /dev/sr0
     Loaded: loaded (/usr/lib/systemd/system/blockdev@.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ cryptsetup-pre.target - Local Encrypted Volumes (Pre)
     Loaded: loaded (/usr/lib/systemd/system/cryptsetup-pre.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● cryptsetup.target - Local Encrypted Volumes
     Loaded: loaded (/usr/lib/systemd/system/cryptsetup.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Notice: journal has been rotated since unit was started, output may be incomplete.

○ emergency.target - Emergency Mode
     Loaded: loaded (/usr/lib/systemd/system/emergency.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ final.target - Late Shutdown Services
     Loaded: loaded (/usr/lib/systemd/system/final.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● first-boot-complete.target - First Boot Complete
     Loaded: loaded (/usr/lib/systemd/system/first-boot-complete.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:52 ubuntu systemd[1]: Reached target first-boot-complete.target - First Boot Complete.

○ getty-pre.target - Preparation for Logins
     Loaded: loaded (/usr/lib/systemd/system/getty-pre.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)
             man:systemd-getty-generator(8)
             https://0pointer.de/blog/projects/serial-console.html

● getty.target - Login Prompts
     Loaded: loaded (/usr/lib/systemd/system/getty.target; static)
     Active: active since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd.special(7)
             man:systemd-getty-generator(8)
             https://0pointer.de/blog/projects/serial-console.html

Jul 29 14:34:55 np0000031958 systemd[1]: Reached target getty.target - Login Prompts.

● graphical.target - Graphical Interface
     Loaded: loaded (/usr/lib/systemd/system/graphical.target; static)
     Active: active since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd.special(7)

Jul 29 14:34:55 np0000031958 systemd[1]: Reached target graphical.target - Graphical Interface.

○ hibernate.target - System Hibernation
     Loaded: loaded (/usr/lib/systemd/system/hibernate.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ hybrid-sleep.target - Hybrid Suspend+Hibernate
     Loaded: loaded (/usr/lib/systemd/system/hybrid-sleep.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ initrd-fs.target - Initrd File Systems
     Loaded: loaded (/usr/lib/systemd/system/initrd-fs.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ initrd-root-device.target - Initrd Root Device
     Loaded: loaded (/usr/lib/systemd/system/initrd-root-device.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ initrd-root-fs.target - Initrd Root File System
     Loaded: loaded (/usr/lib/systemd/system/initrd-root-fs.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ initrd-switch-root.target - Switch Root
     Loaded: loaded (/usr/lib/systemd/system/initrd-switch-root.target; static)
     Active: inactive (dead)

○ initrd-usr-fs.target - Initrd /usr File System
     Loaded: loaded (/usr/lib/systemd/system/initrd-usr-fs.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ initrd.target - Initrd Default Target
     Loaded: loaded (/usr/lib/systemd/system/initrd.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● integritysetup.target - Local Integrity Protected Volumes
     Loaded: loaded (/usr/lib/systemd/system/integritysetup.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Notice: journal has been rotated since unit was started, output may be incomplete.

● local-fs-pre.target - Preparation for Local File Systems
     Loaded: loaded (/usr/lib/systemd/system/local-fs-pre.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:52 ubuntu systemd[1]: Reached target local-fs-pre.target - Preparation for Local File Systems.

● local-fs.target - Local File Systems
     Loaded: loaded (/usr/lib/systemd/system/local-fs.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:52 ubuntu systemd[1]: Reached target local-fs.target - Local File Systems.

● machines.target - Containers
     Loaded: loaded (/usr/lib/systemd/system/machines.target; enabled; preset: enabled)
     Active: active since Tue 2025-07-29 16:51:24 UTC; 41min ago
       Docs: man:systemd.special(7)

Jul 29 16:51:24 np0000031958 systemd[1]: Reached target machines.target - Containers.

● multi-user.target - Multi-User System
     Loaded: loaded (/usr/lib/systemd/system/multi-user.target; static)
     Active: active since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd.special(7)

Jul 29 14:34:55 np0000031958 systemd[1]: Reached target multi-user.target - Multi-User System.

● network-online.target - Network is Online
     Loaded: loaded (/usr/lib/systemd/system/network-online.target; static)
     Active: active since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd.special(7)
             https://systemd.io/NETWORK_ONLINE

Jul 29 14:34:55 np0000031958 systemd[1]: Reached target network-online.target - Network is Online.

● network-pre.target - Preparation for Network
     Loaded: loaded (/usr/lib/systemd/system/network-pre.target; static)
     Active: active since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
       Docs: man:systemd.special(7)
             https://systemd.io/NETWORK_ONLINE

Jul 29 14:32:55 np0000031958 systemd[1]: Reached target network-pre.target - Preparation for Network.

● network.target - Network
     Loaded: loaded (/usr/lib/systemd/system/network.target; static)
     Active: active since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
       Docs: man:systemd.special(7)
             https://systemd.io/NETWORK_ONLINE

Jul 29 14:32:55 np0000031958 systemd[1]: Reached target network.target - Network.

● nss-lookup.target - Host and Network Name Lookups
     Loaded: loaded (/usr/lib/systemd/system/nss-lookup.target; static)
     Active: active since Tue 2025-07-29 14:32:55 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:55 np0000031958 systemd[1]: Reached target nss-lookup.target - Host and Network Name Lookups.

○ nss-user-lookup.target - User and Group Name Lookups
     Loaded: loaded (/usr/lib/systemd/system/nss-user-lookup.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● paths.target - Path Units
     Loaded: loaded (/usr/lib/systemd/system/paths.target; static)
     Active: active since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:53 ubuntu systemd[1]: Reached target paths.target - Path Units.

○ remote-cryptsetup.target - Remote Encrypted Volumes
     Loaded: loaded (/usr/lib/systemd/system/remote-cryptsetup.target; disabled; preset: enabled)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● remote-fs-pre.target - Preparation for Remote File Systems
     Loaded: loaded (/usr/lib/systemd/system/remote-fs-pre.target; static)
     Active: active since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd.special(7)

Jul 29 14:34:55 np0000031958 systemd[1]: Reached target remote-fs-pre.target - Preparation for Remote File Systems.

● remote-fs.target - Remote File Systems
     Loaded: loaded (/usr/lib/systemd/system/remote-fs.target; enabled; preset: enabled)
     Active: active since Tue 2025-07-29 14:34:55 UTC; 2h 58min ago
       Docs: man:systemd.special(7)

Jul 29 14:34:55 np0000031958 systemd[1]: Reached target remote-fs.target - Remote File Systems.

○ remote-veritysetup.target - Remote Verity Protected Volumes
     Loaded: loaded (/usr/lib/systemd/system/remote-veritysetup.target; disabled; preset: enabled)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ rescue.target - Rescue Mode
     Loaded: loaded (/usr/lib/systemd/system/rescue.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ shutdown.target - System Shutdown
     Loaded: loaded (/usr/lib/systemd/system/shutdown.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ sleep.target - Sleep
     Loaded: loaded (/usr/lib/systemd/system/sleep.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● slices.target - Slice Units
     Loaded: loaded (/usr/lib/systemd/system/slices.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Notice: journal has been rotated since unit was started, output may be incomplete.

● sockets.target - Socket Units
     Loaded: loaded (/usr/lib/systemd/system/sockets.target; static)
     Active: active since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:53 ubuntu systemd[1]: Reached target sockets.target - Socket Units.

○ soft-reboot.target - Reboot System Userspace
     Loaded: loaded (/usr/lib/systemd/system/soft-reboot.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ suspend-then-hibernate.target - Suspend; Hibernate if not used for a period of time
     Loaded: loaded (/usr/lib/systemd/system/suspend-then-hibernate.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ suspend.target - Suspend
     Loaded: loaded (/usr/lib/systemd/system/suspend.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● swap.target - Swaps
     Loaded: loaded (/usr/lib/systemd/system/swap.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Notice: journal has been rotated since unit was started, output may be incomplete.

● sysinit.target - System Initialization
     Loaded: loaded (/usr/lib/systemd/system/sysinit.target; static)
     Active: active since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:53 ubuntu systemd[1]: Reached target sysinit.target - System Initialization.

● time-set.target - System Time Set
     Loaded: loaded (/usr/lib/systemd/system/time-set.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:52 ubuntu systemd[1]: Reached target time-set.target - System Time Set.

○ time-sync.target - System Time Synchronized
     Loaded: loaded (/usr/lib/systemd/system/time-sync.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● timers.target - Timer Units
     Loaded: loaded (/usr/lib/systemd/system/timers.target; static)
     Active: active since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Jul 29 14:32:53 ubuntu systemd[1]: Reached target timers.target - Timer Units.

○ umount.target - Unmount All Filesystems
     Loaded: loaded (/usr/lib/systemd/system/umount.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

○ veritysetup-pre.target - Local Verity Protected Volumes (Pre)
     Loaded: loaded (/usr/lib/systemd/system/veritysetup-pre.target; static)
     Active: inactive (dead)
       Docs: man:systemd.special(7)

● veritysetup.target - Local Verity Protected Volumes
     Loaded: loaded (/usr/lib/systemd/system/veritysetup.target; static)
     Active: active since Tue 2025-07-29 14:32:52 UTC; 3h 0min ago
       Docs: man:systemd.special(7)

Notice: journal has been rotated since unit was started, output may be incomplete.

● virt-guest-shutdown.target - libvirt guests shutdown target
     Loaded: loaded (/usr/lib/systemd/system/virt-guest-shutdown.target; static)
     Active: active since Tue 2025-07-29 16:51:27 UTC; 41min ago
       Docs: https://libvirt.org/

Jul 29 16:51:27 np0000031958 systemd[1]: Reached target virt-guest-shutdown.target - libvirt guests shutdown target.

● apt-daily-upgrade.timer - Daily apt upgrade and clean activities
     Loaded: loaded (/usr/lib/systemd/system/apt-daily-upgrade.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
    Trigger: Wed 2025-07-30 06:53:50 UTC; 13h left
   Triggers: ● apt-daily-upgrade.service

Jul 29 14:32:53 ubuntu systemd[1]: Started apt-daily-upgrade.timer - Daily apt upgrade and clean activities.

● apt-daily.timer - Daily apt download activities
     Loaded: loaded (/usr/lib/systemd/system/apt-daily.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
    Trigger: Tue 2025-07-29 21:35:54 UTC; 4h 2min left
   Triggers: ● apt-daily.service

Jul 29 14:32:53 ubuntu systemd[1]: Started apt-daily.timer - Daily apt download activities.

● dpkg-db-backup.timer - Daily dpkg database backup timer
     Loaded: loaded (/usr/lib/systemd/system/dpkg-db-backup.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
    Trigger: Wed 2025-07-30 00:00:00 UTC; 6h left
   Triggers: ● dpkg-db-backup.service
       Docs: man:dpkg(1)

Jul 29 14:32:53 ubuntu systemd[1]: Started dpkg-db-backup.timer - Daily dpkg database backup timer.

● e2scrub_all.timer - Periodic ext4 Online Metadata Check for All Filesystems
     Loaded: loaded (/usr/lib/systemd/system/e2scrub_all.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
    Trigger: Sun 2025-08-03 03:10:15 UTC; 4 days left
   Triggers: ● e2scrub_all.service

Jul 29 14:32:53 ubuntu systemd[1]: Started e2scrub_all.timer - Periodic ext4 Online Metadata Check for All Filesystems.

● fstrim.timer - Discard unused filesystem blocks once a week
     Loaded: loaded (/usr/lib/systemd/system/fstrim.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
    Trigger: Mon 2025-08-04 01:17:17 UTC; 5 days left
   Triggers: ● fstrim.service
       Docs: man:fstrim

Jul 29 14:32:53 ubuntu systemd[1]: Started fstrim.timer - Discard unused filesystem blocks once a week.

● logrotate.timer - Daily rotation of log files
     Loaded: loaded (/usr/lib/systemd/system/logrotate.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 16:43:55 UTC; 49min ago
    Trigger: Wed 2025-07-30 00:00:00 UTC; 6h left
   Triggers: ● logrotate.service
       Docs: man:logrotate(8)
             man:logrotate.conf(5)

Jul 29 16:43:55 np0000031958 systemd[1]: Started logrotate.timer - Daily rotation of log files.

● man-db.timer - Daily man-db regeneration
     Loaded: loaded (/usr/lib/systemd/system/man-db.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 16:43:15 UTC; 50min ago
    Trigger: Wed 2025-07-30 04:41:30 UTC; 11h left
   Triggers: ● man-db.service
       Docs: man:mandb(8)

Jul 29 16:43:15 np0000031958 systemd[1]: Started man-db.timer - Daily man-db regeneration.

● motd-news.timer - Message of the Day
     Loaded: loaded (/usr/lib/systemd/system/motd-news.timer; enabled; preset: enabled)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
    Trigger: Wed 2025-07-30 11:22:27 UTC; 17h left
   Triggers: ● motd-news.service

Jul 29 14:32:53 ubuntu systemd[1]: Started motd-news.timer - Message of the Day.

● systemd-tmpfiles-clean.timer - Daily Cleanup of Temporary Directories
     Loaded: loaded (/usr/lib/systemd/system/systemd-tmpfiles-clean.timer; static)
     Active: active (waiting) since Tue 2025-07-29 14:32:53 UTC; 3h 0min ago
    Trigger: Wed 2025-07-30 14:47:51 UTC; 21h left
   Triggers: ● systemd-tmpfiles-clean.service
       Docs: man:tmpfiles.d(5)
             man:systemd-tmpfiles(8)

Jul 29 14:32:53 ubuntu systemd[1]: Started systemd-tmpfiles-clean.timer - Daily Cleanup of Temporary Directories.
